{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from itertools import combinations \n",
    "from sklearn import model_selection\n",
    "import copy \n",
    "from statistics import mean,mode,stdev\n",
    "from itertools import combinations  \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../60s_window_wrist_chest.csv',index_col=0)\n",
    "df=df[df['label']<2]\n",
    "\n",
    "features=df.columns.tolist()\n",
    "features\n",
    "\n",
    "removed = ['label']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "features_with_sub=[]\n",
    "features_with_sub[:]=features\n",
    "removed = ['subject']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "feature=features\n",
    "print(len(feature))\n",
    "len(features_with_sub)\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X, y= sm.fit_sample(df[features_with_sub], df['label'])\n",
    "df_new=pd.concat([pd.DataFrame(X,columns=features_with_sub),pd.DataFrame(y,columns=['label'])],axis=1)\n",
    "df_new\n",
    "\n",
    "for i in range (len(list(df_new['subject']))):\n",
    "    df_new['subject'][i] = min([2,3,4,5,6,7,8,9,10,11,13,14,15,16,17], key=lambda x:abs(x-df_new['subject'][i]))\n",
    "df_new['subject']=df_new['subject'].astype(int)\n",
    "\n",
    "p_d=pd.read_csv('../personal_detail.csv',index_col=0)\n",
    "\n",
    "df_new_1=df_new.merge(p_d,on='subject')\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_fea = ['EDA_tonic_mean','EDA_tonic_max','EDA_phasic_max','ECG_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = [2,3,4,5,6,7,8,9,10,11,13,14,15,16,17]\n",
    "len(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for cp in range (1,len(user_list)):\n",
    "# cp = 5\n",
    "# print ('*'*20)\n",
    "# print (\"15C\"+str(cp))\n",
    "# print ('*'*20)\n",
    "# com = cp                                        # combination number, If any doubt plz call me\n",
    "# combi = combinations(user_list, com) \n",
    "# tot = str(len(list(copy.deepcopy(combi))))\n",
    "\n",
    "# best_random_state_train = user_list[0:com]\n",
    "# best_random_state_test = user_list[com:]\n",
    "\n",
    "# train= df_new_1.loc[df_new_1.subject.isin(best_random_state_train)]\n",
    "# test= df_new_1.loc[df_new_1.subject.isin(best_random_state_test)]\n",
    "\n",
    "# scaler = Normalizer()\n",
    "# scaled_data_train = scaler.fit_transform(train[sel_fea])\n",
    "# scaled_data_test = scaler.transform(test[sel_fea])\n",
    "\n",
    "# index = 1\n",
    "# subjects_in_train = []\n",
    "# subjects_in_test = []\n",
    "# best_acc = []\n",
    "# mean_acc = []\n",
    "# min_acc = []\n",
    "\n",
    "# acc = []\n",
    "\n",
    "# for c in list(combi):\n",
    "#     local_acc = []\n",
    "\n",
    "#     print (str(index)+\" of \"+ tot)\n",
    "#     train_sub = list(c)\n",
    "#     test_sub = list(set(user_list))\n",
    "#     breaker = 0\n",
    "#     for _ in test_sub:\n",
    "#         print (train_sub,_)\n",
    "\n",
    "#         train= df_new_1.loc[df_new_1.subject.isin(train_sub)]\n",
    "#         test= df_new_1.loc[df_new_1.subject.isin([_])]\n",
    "\n",
    "#         scaler = Normalizer()\n",
    "#         scaled_data_train = scaler.fit_transform(train[sel_fea])\n",
    "#         scaled_data_test = scaler.transform(test[sel_fea])\n",
    "\n",
    "#         clf = RandomForestClassifier(n_estimators=100,n_jobs=10)\n",
    "#         clf.fit(scaled_data_train,train['label'])\n",
    "#         y_pred=clf.predict(scaled_data_test)\n",
    "#         #print (classification_report(test['label'],y_pred))\n",
    "\n",
    "#         rpt = classification_report(test['label'],y_pred,output_dict=True)['accuracy']\n",
    "\n",
    "#         acc.append(rpt)\n",
    "#         subjects_in_train.append(str(train_sub))\n",
    "#         subjects_in_test.append(str([_]))\n",
    "\n",
    "#     index += 1\n",
    "        \n",
    "        \n",
    "#     combi_dict = {'subjects_in_train':subjects_in_train,'subjects_in_test':subjects_in_test, 'acc':acc}\n",
    "#     df_plot_combi = pd.DataFrame(combi_dict)\n",
    "\n",
    "#     print(\"****** Writing to File ********\")\n",
    "#     # Plz cross check with the file name before saving to df to csv file\n",
    "#     file_name = 'UI/2_class_combination_UI'+str(index)+'.csv'\n",
    "#     print (file_name)\n",
    "#     df_plot_combi.to_csv(file_name)\n",
    "    \n",
    "# #     print (df_plot_combi)\n",
    "\n",
    "# #     temp = df_plot_combi[df_plot_combi['acc']>=max(df_plot_combi['acc'])]\n",
    "\n",
    "# #     print(\"Max:\",max(df_plot_combi['acc']))\n",
    "# #     print(\"Min:\",min(df_plot_combi['acc']))\n",
    "# #     print(\"Mean:\",mean(df_plot_combi['acc']))\n",
    "# #     print(\"std:\",stdev(df_plot_combi['acc']))\n",
    "\n",
    "# #     exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A faster way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import scipy.stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=['/home/sf/fresh_start','/home/sf/fresh_start/DecisionTreeClassifier','/home/sf/fresh_start/GradientBoostingClassifier','/home/sf/fresh_start/Random_Forest']\n",
    "name=['Extra Trees Classifier','Decision Tree Classifier','Gradient Boosting Classifier','Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(4):\n",
    "    globals()['%s_csv_length_4_class' % name[j]]=[]\n",
    "    globals()['%s_label_4_class' % name[j]]=[]\n",
    "    globals()['%s_min_4_class' % name[j]]=[]\n",
    "    globals()['%s_max_4_class' % name[j]]=[]\n",
    "    globals()['%s_mean_4_class' % name[j]]=[]\n",
    "    globals()['%s_std_4_class' % name[j]]=[]\n",
    "    globals()['%s_var_4_class' % name[j]]=[]\n",
    "    for i in range(1,15):\n",
    "        globals()['csv_train_%s' % i]=pd.read_csv(path[j]+'/4_class_combination_'+str(i)+'-'+str(15-i)+'.csv',index_col=0)\n",
    "        globals()['%s_csv_length_4_class' % name[j]].append(len(list(globals()['csv_train_%s' % i]['acc'])))\n",
    "        #print('csv_train_'+str(i)+\"['acc']\"+\",\")\n",
    "        globals()['%s_min_4_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].min())\n",
    "        globals()['%s_max_4_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].max())\n",
    "        globals()['%s_mean_4_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].mean())\n",
    "        globals()['%s_std_4_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].std())\n",
    "        globals()['%s_var_4_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].var())\n",
    "        globals()['%s_label_4_class' % name[j]].append(str(i)+','+str(15-i)+','+str(globals()['%s_csv_length_4_class' % name[j]][i-1]))\n",
    "        #print ('4_class_combination_'+str(i)+'-'+str(15-i)+'.csv')\n",
    "    globals()['%s_csv_list_4_class' % name[j]]=[csv_train_1['acc'],\n",
    "    csv_train_2['acc'],\n",
    "    csv_train_3['acc'],\n",
    "    csv_train_4['acc'],\n",
    "    csv_train_5['acc'],\n",
    "    csv_train_6['acc'],\n",
    "    csv_train_7['acc'],\n",
    "    csv_train_8['acc'],\n",
    "    csv_train_9['acc'],\n",
    "    csv_train_10['acc'],\n",
    "    csv_train_11['acc'],\n",
    "    csv_train_12['acc'],\n",
    "    csv_train_13['acc'],\n",
    "    csv_train_14['acc'],]\n",
    "    \n",
    "    #for 3 class\n",
    "    \n",
    "    globals()['%s_csv_length_3_class' % name[j]]=[]\n",
    "    globals()['%s_label_3_class' % name[j]]=[]\n",
    "    globals()['%s_min_3_class' % name[j]]=[]\n",
    "    globals()['%s_max_3_class' % name[j]]=[]\n",
    "    globals()['%s_mean_3_class' % name[j]]=[]\n",
    "    globals()['%s_std_3_class' % name[j]]=[]\n",
    "    globals()['%s_var_3_class' % name[j]]=[]\n",
    "    for i in range(1,15):\n",
    "        globals()['csv_train_%s' % i]=pd.read_csv(path[j]+'/3_class_combination_'+str(i)+'-'+str(15-i)+'.csv',index_col=0)\n",
    "        globals()['%s_csv_length_3_class' % name[j]].append(len(list(globals()['csv_train_%s' % i]['acc'])))\n",
    "        #print('csv_train_'+str(i)+\"['acc']\"+\",\")\n",
    "        globals()['%s_min_3_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].min())\n",
    "        globals()['%s_max_3_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].max())\n",
    "        globals()['%s_mean_3_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].mean())\n",
    "        globals()['%s_std_3_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].std())\n",
    "        globals()['%s_var_3_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].var())\n",
    "        globals()['%s_label_3_class' % name[j]].append(str(i)+','+str(15-i)+','+str(globals()['%s_csv_length_3_class' % name[j]][i-1]))\n",
    "        #print ('3_class_combination_'+str(i)+'-'+str(15-i)+'.csv')\n",
    "    globals()['%s_csv_list_3_class' % name[j]]=[csv_train_1['acc'],\n",
    "    csv_train_2['acc'],\n",
    "    csv_train_3['acc'],\n",
    "    csv_train_4['acc'],\n",
    "    csv_train_5['acc'],\n",
    "    csv_train_6['acc'],\n",
    "    csv_train_7['acc'],\n",
    "    csv_train_8['acc'],\n",
    "    csv_train_9['acc'],\n",
    "    csv_train_10['acc'],\n",
    "    csv_train_11['acc'],\n",
    "    csv_train_12['acc'],\n",
    "    csv_train_13['acc'],\n",
    "    csv_train_14['acc'],]\n",
    "    \n",
    "    #for 2 class\n",
    "    \n",
    "    globals()['%s_csv_length_2_class' % name[j]]=[]\n",
    "    globals()['%s_label_2_class' % name[j]]=[]\n",
    "    globals()['%s_min_2_class' % name[j]]=[]\n",
    "    globals()['%s_max_2_class' % name[j]]=[]\n",
    "    globals()['%s_mean_2_class' % name[j]]=[]\n",
    "    globals()['%s_std_2_class' % name[j]]=[]\n",
    "    globals()['%s_var_2_class' % name[j]]=[]\n",
    "    for i in range(1,15):\n",
    "        globals()['csv_train_%s' % i]=pd.read_csv(path[j]+'/2_class_combination_'+str(i)+'-'+str(15-i)+'.csv',index_col=0)\n",
    "        globals()['%s_csv_length_2_class' % name[j]].append(len(list(globals()['csv_train_%s' % i]['acc'])))\n",
    "        #print('csv_train_'+str(i)+\"['acc']\"+\",\")\n",
    "        globals()['%s_min_2_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].min())\n",
    "        globals()['%s_max_2_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].max())\n",
    "        globals()['%s_mean_2_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].mean())\n",
    "        globals()['%s_std_2_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].std())\n",
    "        globals()['%s_var_2_class' % name[j]].append(globals()['csv_train_%s' % i]['acc'].var())\n",
    "        globals()['%s_label_2_class' % name[j]].append(str(i)+','+str(15-i)+','+str(globals()['%s_csv_length_2_class' % name[j]][i-1]))\n",
    "        #print ('2_class_combination_'+str(i)+'-'+str(15-i)+'.csv')\n",
    "    globals()['%s_csv_list_2_class' % name[j]]=[csv_train_1['acc'],\n",
    "    csv_train_2['acc'],\n",
    "    csv_train_3['acc'],\n",
    "    csv_train_4['acc'],\n",
    "    csv_train_5['acc'],\n",
    "    csv_train_6['acc'],\n",
    "    csv_train_7['acc'],\n",
    "    csv_train_8['acc'],\n",
    "    csv_train_9['acc'],\n",
    "    csv_train_10['acc'],\n",
    "    csv_train_11['acc'],\n",
    "    csv_train_12['acc'],\n",
    "    csv_train_12['acc'],\n",
    "    csv_train_14['acc'],]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list_2=[]\n",
    "for i in range(4):\n",
    "#     print(i)\n",
    "    class_split=globals()['%s_csv_list_2_class' % name[i]]\n",
    "    for j in range(len(class_split)):\n",
    "        for k in class_split[j]:\n",
    "            master_list_2.append([k,name[i],globals()['%s_label_2_class' % name[i]][j]])\n",
    "\n",
    "# master_list_2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list_3=[]\n",
    "for i in range(4):\n",
    "    #print(i)\n",
    "    class_split=globals()['%s_csv_list_3_class' % name[i]]\n",
    "    for j in range(len(class_split)):\n",
    "        for k in class_split[j]:\n",
    "            master_list_3.append([k,name[i],globals()['%s_label_3_class' % name[i]][j]])\n",
    "            \n",
    "            \n",
    "df=pd.DataFrame(master_list_3,columns=['Accuracy','Algorithm','split'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list_4=[]\n",
    "for i in range(4):\n",
    "    #print(i)\n",
    "    class_split=globals()['%s_csv_list_4_class' % name[i]]\n",
    "    for j in range(len(class_split)):\n",
    "        for k in class_split[j]:\n",
    "            master_list_4.append([k,name[i],globals()['%s_label_4_class' % name[i]][j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.DataFrame(master_list_2,columns=['Accuracy','Algorithm','split'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rf = df[df['Algorithm'] == 'Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rf_5_split = df_rf[df_rf['split'].isin([\"5,10,3003\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rf_5_split.reset_index(inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rf_5_split_max = df_rf_5_split.nlargest(5, ['Accuracy'])\n",
    "# df_rf_5_split_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp = 5\n",
    "# com = cp                                        # combination number, If any doubt plz call me\n",
    "# combi = combinations(user_list, com) \n",
    "# tot = str(len(list(copy.deepcopy(combi))))\n",
    "\n",
    "# index = 1\n",
    "# subjects_in_train = []\n",
    "# subjects_in_test = []\n",
    "# best_acc = []\n",
    "# mean_acc = []\n",
    "# min_acc = []\n",
    "\n",
    "# acc = []\n",
    "\n",
    "# random = [[3, 10, 11, 16, 17],\n",
    "# [2, 5, 7, 11, 17],\n",
    "# [5, 7, 8, 11, 17],\n",
    "# [8, 7, 10, 11, 17],\n",
    "# [3, 5, 11, 16, 17]]\n",
    "\n",
    "# for _ in df_rf_5_split_max.index:\n",
    "# # for _ in random:\n",
    "#     combi_copy = copy.deepcopy(combi)\n",
    "    \n",
    "    \n",
    "#     train_sub = list(list(combi_copy)[_])\n",
    "#     test_sub = list(user_list)\n",
    "# #     test_sub = list(set(user_list)-set(train_sub))\n",
    "# #     train_sub = _\n",
    "\n",
    "#     print (train_sub)\n",
    "    \n",
    "#     for t in test_sub:\n",
    "    \n",
    "#         train= df_new_1.loc[df_new_1.subject.isin(train_sub)]\n",
    "#         test= df_new_1.loc[df_new_1.subject.isin([t])]\n",
    "\n",
    "#         scaler = Normalizer()\n",
    "#         scaled_data_train = scaler.fit_transform(train[sel_fea])\n",
    "#         scaled_data_test = scaler.transform(test[sel_fea])\n",
    "\n",
    "#         clf = RandomForestClassifier(n_estimators=100,n_jobs=10)\n",
    "#         clf.fit(scaled_data_train,train['label'])\n",
    "#         y_pred=clf.predict(scaled_data_test)\n",
    "#         #print (classification_report(test['label'],y_pred))\n",
    "\n",
    "#         rpt = classification_report(test['label'],y_pred,output_dict=True)['accuracy']\n",
    "\n",
    "#         acc.append(rpt)\n",
    "#         subjects_in_train.append(str(train_sub))\n",
    "#         subjects_in_test.append(str([t]))\n",
    "\n",
    "# combi_dict = {'subjects_in_train':subjects_in_train,'subjects_in_test':subjects_in_test, 'acc':acc}\n",
    "# df_plot_combi = pd.DataFrame(combi_dict)\n",
    "\n",
    "# print(\"****** Writing to File ********\")\n",
    "# # Plz cross check with the file name before saving to df to csv file\n",
    "# file_name = 'UI/2_class_combination_UI'+'.csv'\n",
    "# print (file_name)\n",
    "# df_plot_combi.to_csv(file_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Max:\",max(df_plot_combi['acc']))\n",
    "# print(\"Min:\",min(df_plot_combi['acc']))\n",
    "# print(\"Mean:\",mean(df_plot_combi['acc']))\n",
    "# print (\"std:\",stdev(df_plot_combi['acc']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automate(acc_list,algo,split,no_user_training,filename):\n",
    "    df=pd.DataFrame(acc_list,columns=['Accuracy','Algorithm','split'])\n",
    "    df_rf = df[df['Algorithm'] == algo]\n",
    "    df_rf_5_split = df_rf[df_rf['split'].isin([split])]\n",
    "    df_rf_5_split.reset_index(inplace = True) \n",
    "    df_rf_5_split_max = df_rf_5_split.nlargest(500, ['Accuracy'])\n",
    "    \n",
    "    cp = no_user_training\n",
    "    com = cp                                        # combination number, If any doubt plz call me\n",
    "    combi = combinations(user_list, com) \n",
    "    tot = str(len(list(copy.deepcopy(combi))))\n",
    "\n",
    "    index = 1\n",
    "    subjects_in_train = []\n",
    "    subjects_in_test = []\n",
    "    best_acc = []\n",
    "    mean_acc = []\n",
    "    min_acc = []\n",
    "\n",
    "    acc = []\n",
    "\n",
    "#     random = [[3, 10, 11, 16, 17],\n",
    "#     [2, 5, 7, 11, 17],\n",
    "#     [5, 7, 8, 11, 17],\n",
    "#     [8, 7, 10, 11, 17],\n",
    "#     [3, 5, 11, 16, 17]]\n",
    "    n = 1\n",
    "    for _ in df_rf_5_split_max.index:\n",
    "    # for _ in random:\n",
    "        combi_copy = copy.deepcopy(combi)\n",
    "\n",
    "\n",
    "        train_sub = list(list(combi_copy)[_])\n",
    "#         test_sub = list(user_list)\n",
    "        test_sub = list(set(user_list)-set(train_sub))\n",
    "    #     train_sub = _\n",
    "\n",
    "#         print (train_sub)\n",
    "#         print (n)\n",
    "#         n = n+1\n",
    "\n",
    "        for t in test_sub:\n",
    "            print (train_sub,t)\n",
    "\n",
    "            train= df_new_1.loc[df_new_1.subject.isin(train_sub)]\n",
    "            test= df_new_1.loc[df_new_1.subject.isin([t])]\n",
    "\n",
    "            scaler = Normalizer()\n",
    "            scaled_data_train = scaler.fit_transform(train[sel_fea])\n",
    "            scaled_data_test = scaler.transform(test[sel_fea])\n",
    "\n",
    "            if algo == 'Extra Trees Classifier':\n",
    "                clf = ExtraTreesClassifier(n_estimators=100,n_jobs=10)\n",
    "            else:\n",
    "                clf = RandomForestClassifier(n_estimators=100,n_jobs=10)\n",
    "            clf.fit(scaled_data_train,train['label'])\n",
    "            y_pred=clf.predict(scaled_data_test)\n",
    "            #print (classification_report(test['label'],y_pred))\n",
    "\n",
    "            rpt = classification_report(test['label'],y_pred,output_dict=True)['accuracy']\n",
    "\n",
    "            acc.append(rpt)\n",
    "            subjects_in_train.append(str(train_sub))\n",
    "            subjects_in_test.append(str([t]))\n",
    "\n",
    "    combi_dict = {'subjects_in_train':subjects_in_train,'subjects_in_test':subjects_in_test, 'acc':acc}\n",
    "    df_plot_combi = pd.DataFrame(combi_dict)\n",
    "\n",
    "    print(\"****** Writing to File ********\")\n",
    "    # Plz cross check with the file name before saving to df to csv file\n",
    "    file_name = \"UI_L/500/{}.csv\".format(filename)\n",
    "    print (file_name)\n",
    "    df_plot_combi.to_csv(file_name)\n",
    "\n",
    "    print(\"******************************************\")\n",
    "    \n",
    "    print(\"Max:\",max(df_plot_combi['acc']))\n",
    "    print(\"Min:\",min(df_plot_combi['acc']))\n",
    "    print(\"Mean:\",mean(df_plot_combi['acc']))\n",
    "    print (\"std:\",stdev(df_plot_combi['acc']))\n",
    "    \n",
    "    print (\"\\n\")\n",
    "    print (\"Out of {}\".format(df_plot_combi.shape[0]))\n",
    "    print (\"values Above 90%: {}\".format(df_plot_combi[df_plot_combi['acc']>0.90].shape[0]))\n",
    "    print (\"values between 80% - 90%: {}\".format(df_plot_combi[df_plot_combi['acc'].between(.80, .90, inclusive = True)].shape[0]))\n",
    "    print (\"values less 80%: {}\".format(df_plot_combi[df_plot_combi['acc']<0.80].shape[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "automate(master_list_2,'Random Forest',\"5,10,3003\",5,'2_class_combination_UI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "automate(master_list_3,'Random Forest',\"7,8,6435\",7,'3_class_combination_UI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "automate(master_list_4,'Random Forest',\"7,8,6435\",7,'4_class_combination_UI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automate(master_list_2,'Extra Trees Classifier',\"5,10,3003\",5,'2_class_combination_UI_et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "automate(master_list_3,'Extra Trees Classifier',\"7,8,6435\",7,'3_class_combination_UI_et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "automate(master_list_4,'Extra Trees Classifier',\"7,8,6435\",7,'4_class_combination_UI_et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
