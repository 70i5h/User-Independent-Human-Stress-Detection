{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41 µs, sys: 20 µs, total: 61 µs\n",
      "Wall time: 64.6 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from itertools import combinations \n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn import model_selection\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_acc_mean</th>\n",
       "      <th>net_acc_std</th>\n",
       "      <th>net_acc_min</th>\n",
       "      <th>net_acc_max</th>\n",
       "      <th>ACC_x_mean</th>\n",
       "      <th>ACC_x_std</th>\n",
       "      <th>ACC_x_min</th>\n",
       "      <th>ACC_x_max</th>\n",
       "      <th>ACC_y_mean</th>\n",
       "      <th>ACC_y_std</th>\n",
       "      <th>...</th>\n",
       "      <th>c_ACC_z_min</th>\n",
       "      <th>c_ACC_z_max</th>\n",
       "      <th>c_Temp_mean</th>\n",
       "      <th>c_Temp_std</th>\n",
       "      <th>c_Temp_min</th>\n",
       "      <th>c_Temp_max</th>\n",
       "      <th>BVP_peak_freq</th>\n",
       "      <th>TEMP_slope</th>\n",
       "      <th>subject</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>0.017769</td>\n",
       "      <td>-0.037843</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.222594e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8700</td>\n",
       "      <td>0.6110</td>\n",
       "      <td>29.168923</td>\n",
       "      <td>0.064290</td>\n",
       "      <td>28.994568</td>\n",
       "      <td>29.426208</td>\n",
       "      <td>0.081425</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>7.290999e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7594</td>\n",
       "      <td>-0.6810</td>\n",
       "      <td>28.886605</td>\n",
       "      <td>0.074846</td>\n",
       "      <td>28.730682</td>\n",
       "      <td>29.207275</td>\n",
       "      <td>0.147017</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.028378</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>-0.002752</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>4.805734e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7534</td>\n",
       "      <td>-0.6754</td>\n",
       "      <td>28.799659</td>\n",
       "      <td>0.037924</td>\n",
       "      <td>28.679108</td>\n",
       "      <td>28.988800</td>\n",
       "      <td>0.088210</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.033268</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>-0.030962</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6.126303e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7878</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>28.768865</td>\n",
       "      <td>0.058639</td>\n",
       "      <td>28.584656</td>\n",
       "      <td>29.023285</td>\n",
       "      <td>0.117614</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>8.837530e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7202</td>\n",
       "      <td>-0.6570</td>\n",
       "      <td>28.598514</td>\n",
       "      <td>0.068128</td>\n",
       "      <td>28.447449</td>\n",
       "      <td>28.882599</td>\n",
       "      <td>0.151541</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.036762</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058485</td>\n",
       "      <td>-0.036741</td>\n",
       "      <td>0.008011</td>\n",
       "      <td>-0.058485</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>5.512148e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.9478</td>\n",
       "      <td>-0.7038</td>\n",
       "      <td>33.943786</td>\n",
       "      <td>0.026213</td>\n",
       "      <td>33.808136</td>\n",
       "      <td>34.097076</td>\n",
       "      <td>0.119876</td>\n",
       "      <td>-0.000075</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>781</td>\n",
       "      <td>0.032120</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.055732</td>\n",
       "      <td>-0.032117</td>\n",
       "      <td>0.005343</td>\n",
       "      <td>-0.055732</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>3.676049e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.9446</td>\n",
       "      <td>-0.7414</td>\n",
       "      <td>33.939625</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>33.753479</td>\n",
       "      <td>34.144348</td>\n",
       "      <td>0.065592</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>782</td>\n",
       "      <td>0.026901</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.024770</td>\n",
       "      <td>0.028210</td>\n",
       "      <td>-0.026901</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>-0.028210</td>\n",
       "      <td>-0.024770</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>3.554577e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.9718</td>\n",
       "      <td>-0.7698</td>\n",
       "      <td>34.002778</td>\n",
       "      <td>0.034897</td>\n",
       "      <td>33.864288</td>\n",
       "      <td>34.191650</td>\n",
       "      <td>0.108567</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>783</td>\n",
       "      <td>0.027999</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.025458</td>\n",
       "      <td>0.029586</td>\n",
       "      <td>-0.027999</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>-0.029586</td>\n",
       "      <td>-0.025458</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>2.944295e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.9350</td>\n",
       "      <td>-0.8154</td>\n",
       "      <td>34.024391</td>\n",
       "      <td>0.029791</td>\n",
       "      <td>33.917480</td>\n",
       "      <td>34.188568</td>\n",
       "      <td>0.115352</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>784</td>\n",
       "      <td>0.027407</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.074310</td>\n",
       "      <td>-0.027312</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>-0.074310</td>\n",
       "      <td>0.017201</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>3.927736e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.9224</td>\n",
       "      <td>-0.8070</td>\n",
       "      <td>34.039778</td>\n",
       "      <td>0.025709</td>\n",
       "      <td>33.884033</td>\n",
       "      <td>34.205383</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            net_acc_mean  net_acc_std  net_acc_min  net_acc_max  ACC_x_mean  \\\n",
       "Unnamed: 0                                                                    \n",
       "0               0.025961     0.013811     0.000000     0.087383    0.023431   \n",
       "1               0.027640     0.010597     0.002752     0.054356    0.027640   \n",
       "2               0.028389     0.006937     0.000000     0.066053    0.028378   \n",
       "3               0.033268     0.007670     0.000000     0.074998    0.032960   \n",
       "4               0.037021     0.001284     0.027522     0.043347    0.037021   \n",
       "...                  ...          ...          ...          ...         ...   \n",
       "780             0.036762     0.007911     0.000000     0.058485   -0.036741   \n",
       "781             0.032120     0.005324     0.001376     0.055732   -0.032117   \n",
       "782             0.026901     0.000517     0.024770     0.028210   -0.026901   \n",
       "783             0.027999     0.000428     0.025458     0.029586   -0.027999   \n",
       "784             0.027407     0.005238     0.000688     0.074310   -0.027312   \n",
       "\n",
       "            ACC_x_std  ACC_x_min  ACC_x_max  ACC_y_mean     ACC_y_std  ...  \\\n",
       "Unnamed: 0                                                             ...   \n",
       "0            0.017769  -0.037843   0.087383    0.000016  1.222594e-05  ...   \n",
       "1            0.010597   0.002752   0.054356    0.000019  7.290999e-06  ...   \n",
       "2            0.006985  -0.002752   0.066053    0.000020  4.805734e-06  ...   \n",
       "3            0.008904  -0.030962   0.074998    0.000023  6.126303e-06  ...   \n",
       "4            0.001284   0.027522   0.043347    0.000025  8.837530e-07  ...   \n",
       "...               ...        ...        ...         ...           ...  ...   \n",
       "780          0.008011  -0.058485   0.008257   -0.000025  5.512148e-06  ...   \n",
       "781          0.005343  -0.055732   0.002752   -0.000022  3.676049e-06  ...   \n",
       "782          0.000517  -0.028210  -0.024770   -0.000019  3.554577e-07  ...   \n",
       "783          0.000428  -0.029586  -0.025458   -0.000019  2.944295e-07  ...   \n",
       "784          0.005708  -0.074310   0.017201   -0.000019  3.927736e-06  ...   \n",
       "\n",
       "            c_ACC_z_min  c_ACC_z_max  c_Temp_mean  c_Temp_std  c_Temp_min  \\\n",
       "Unnamed: 0                                                                  \n",
       "0               -0.8700       0.6110    29.168923    0.064290   28.994568   \n",
       "1               -0.7594      -0.6810    28.886605    0.074846   28.730682   \n",
       "2               -0.7534      -0.6754    28.799659    0.037924   28.679108   \n",
       "3               -0.7878       0.1660    28.768865    0.058639   28.584656   \n",
       "4               -0.7202      -0.6570    28.598514    0.068128   28.447449   \n",
       "...                 ...          ...          ...         ...         ...   \n",
       "780             -0.9478      -0.7038    33.943786    0.026213   33.808136   \n",
       "781             -0.9446      -0.7414    33.939625    0.025553   33.753479   \n",
       "782             -0.9718      -0.7698    34.002778    0.034897   33.864288   \n",
       "783             -0.9350      -0.8154    34.024391    0.029791   33.917480   \n",
       "784             -0.9224      -0.8070    34.039778    0.025709   33.884033   \n",
       "\n",
       "            c_Temp_max  BVP_peak_freq  TEMP_slope  subject  label  \n",
       "Unnamed: 0                                                         \n",
       "0            29.426208       0.081425   -0.000253        2      0  \n",
       "1            29.207275       0.147017   -0.000161        2      0  \n",
       "2            28.988800       0.088210    0.000535        2      0  \n",
       "3            29.023285       0.117614   -0.000256        2      0  \n",
       "4            28.882599       0.151541    0.000260        2      0  \n",
       "...                ...            ...         ...      ...    ...  \n",
       "780          34.097076       0.119876   -0.000075       17      3  \n",
       "781          34.144348       0.065592   -0.000117       17      3  \n",
       "782          34.191650       0.108567    0.000454       17      3  \n",
       "783          34.188568       0.115352   -0.000095       17      3  \n",
       "784          34.205383       0.115385   -0.000301       17      3  \n",
       "\n",
       "[785 rows x 72 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('60s_window_wrist_chest.csv',index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 72)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['net_acc_mean', 'net_acc_std', 'net_acc_min', 'net_acc_max',\n",
       "       'ACC_x_mean', 'ACC_x_std', 'ACC_x_min', 'ACC_x_max', 'ACC_y_mean',\n",
       "       'ACC_y_std', 'ACC_y_min', 'ACC_y_max', 'ACC_z_mean', 'ACC_z_std',\n",
       "       'ACC_z_min', 'ACC_z_max', 'BVP_mean', 'BVP_std', 'BVP_min', 'BVP_max',\n",
       "       'ECG_mean', 'ECG_std', 'ECG_min', 'ECG_max', 'EDA_mean', 'EDA_std',\n",
       "       'EDA_min', 'EDA_max', 'EDA_phasic_mean', 'EDA_phasic_std',\n",
       "       'EDA_phasic_min', 'EDA_phasic_max', 'EDA_smna_mean', 'EDA_smna_std',\n",
       "       'EDA_smna_min', 'EDA_smna_max', 'EDA_tonic_mean', 'EDA_tonic_std',\n",
       "       'EDA_tonic_min', 'EDA_tonic_max', 'EMG_mean', 'EMG_std', 'EMG_min',\n",
       "       'EMG_max', 'Resp_mean', 'Resp_std', 'Resp_min', 'Resp_max', 'TEMP_mean',\n",
       "       'TEMP_std', 'TEMP_min', 'TEMP_max', 'c_ACC_x_mean', 'c_ACC_x_std',\n",
       "       'c_ACC_x_min', 'c_ACC_x_max', 'c_ACC_y_mean', 'c_ACC_y_std',\n",
       "       'c_ACC_y_min', 'c_ACC_y_max', 'c_ACC_z_mean', 'c_ACC_z_std',\n",
       "       'c_ACC_z_min', 'c_ACC_z_max', 'c_Temp_mean', 'c_Temp_std', 'c_Temp_min',\n",
       "       'c_Temp_max', 'BVP_peak_freq', 'TEMP_slope', 'subject', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.47 ms, sys: 0 ns, total: 5.47 ms\n",
      "Wall time: 3.94 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df=df[df['target']!=]\n",
    "df=df[df['label']!=2]\n",
    "df=df[df['label']!=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, 72)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_acc_mean</th>\n",
       "      <th>net_acc_std</th>\n",
       "      <th>net_acc_min</th>\n",
       "      <th>net_acc_max</th>\n",
       "      <th>ACC_x_mean</th>\n",
       "      <th>ACC_x_std</th>\n",
       "      <th>ACC_x_min</th>\n",
       "      <th>ACC_x_max</th>\n",
       "      <th>ACC_y_mean</th>\n",
       "      <th>ACC_y_std</th>\n",
       "      <th>...</th>\n",
       "      <th>c_ACC_z_min</th>\n",
       "      <th>c_ACC_z_max</th>\n",
       "      <th>c_Temp_mean</th>\n",
       "      <th>c_Temp_std</th>\n",
       "      <th>c_Temp_min</th>\n",
       "      <th>c_Temp_max</th>\n",
       "      <th>BVP_peak_freq</th>\n",
       "      <th>TEMP_slope</th>\n",
       "      <th>subject</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>0.017769</td>\n",
       "      <td>-0.037843</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.222594e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.8700</td>\n",
       "      <td>0.6110</td>\n",
       "      <td>29.168923</td>\n",
       "      <td>0.064290</td>\n",
       "      <td>28.994568</td>\n",
       "      <td>29.426208</td>\n",
       "      <td>0.081425</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>7.290999e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7594</td>\n",
       "      <td>-0.6810</td>\n",
       "      <td>28.886605</td>\n",
       "      <td>0.074846</td>\n",
       "      <td>28.730682</td>\n",
       "      <td>29.207275</td>\n",
       "      <td>0.147017</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.028378</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>-0.002752</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>4.805734e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7534</td>\n",
       "      <td>-0.6754</td>\n",
       "      <td>28.799659</td>\n",
       "      <td>0.037924</td>\n",
       "      <td>28.679108</td>\n",
       "      <td>28.988800</td>\n",
       "      <td>0.088210</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.033268</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>-0.030962</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6.126303e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7878</td>\n",
       "      <td>0.1660</td>\n",
       "      <td>28.768865</td>\n",
       "      <td>0.058639</td>\n",
       "      <td>28.584656</td>\n",
       "      <td>29.023285</td>\n",
       "      <td>0.117614</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>8.837530e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7202</td>\n",
       "      <td>-0.6570</td>\n",
       "      <td>28.598514</td>\n",
       "      <td>0.068128</td>\n",
       "      <td>28.447449</td>\n",
       "      <td>28.882599</td>\n",
       "      <td>0.151541</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            net_acc_mean  net_acc_std  net_acc_min  net_acc_max  ACC_x_mean  \\\n",
       "Unnamed: 0                                                                    \n",
       "0               0.025961     0.013811     0.000000     0.087383    0.023431   \n",
       "1               0.027640     0.010597     0.002752     0.054356    0.027640   \n",
       "2               0.028389     0.006937     0.000000     0.066053    0.028378   \n",
       "3               0.033268     0.007670     0.000000     0.074998    0.032960   \n",
       "4               0.037021     0.001284     0.027522     0.043347    0.037021   \n",
       "\n",
       "            ACC_x_std  ACC_x_min  ACC_x_max  ACC_y_mean     ACC_y_std  ...  \\\n",
       "Unnamed: 0                                                             ...   \n",
       "0            0.017769  -0.037843   0.087383    0.000016  1.222594e-05  ...   \n",
       "1            0.010597   0.002752   0.054356    0.000019  7.290999e-06  ...   \n",
       "2            0.006985  -0.002752   0.066053    0.000020  4.805734e-06  ...   \n",
       "3            0.008904  -0.030962   0.074998    0.000023  6.126303e-06  ...   \n",
       "4            0.001284   0.027522   0.043347    0.000025  8.837530e-07  ...   \n",
       "\n",
       "            c_ACC_z_min  c_ACC_z_max  c_Temp_mean  c_Temp_std  c_Temp_min  \\\n",
       "Unnamed: 0                                                                  \n",
       "0               -0.8700       0.6110    29.168923    0.064290   28.994568   \n",
       "1               -0.7594      -0.6810    28.886605    0.074846   28.730682   \n",
       "2               -0.7534      -0.6754    28.799659    0.037924   28.679108   \n",
       "3               -0.7878       0.1660    28.768865    0.058639   28.584656   \n",
       "4               -0.7202      -0.6570    28.598514    0.068128   28.447449   \n",
       "\n",
       "            c_Temp_max  BVP_peak_freq  TEMP_slope  subject  label  \n",
       "Unnamed: 0                                                         \n",
       "0            29.426208       0.081425   -0.000253        2      0  \n",
       "1            29.207275       0.147017   -0.000161        2      0  \n",
       "2            28.988800       0.088210    0.000535        2      0  \n",
       "3            29.023285       0.117614   -0.000256        2      0  \n",
       "4            28.882599       0.151541    0.000260        2      0  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=df.columns.tolist()\n",
    "features\n",
    "\n",
    "removed = ['label']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "features_with_sub=[]\n",
    "features_with_sub[:]=features\n",
    "removed = ['subject']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "feature=features\n",
    "print(len(feature))\n",
    "len(features_with_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_acc_mean</th>\n",
       "      <th>net_acc_std</th>\n",
       "      <th>net_acc_min</th>\n",
       "      <th>net_acc_max</th>\n",
       "      <th>ACC_x_mean</th>\n",
       "      <th>ACC_x_std</th>\n",
       "      <th>ACC_x_min</th>\n",
       "      <th>ACC_x_max</th>\n",
       "      <th>ACC_y_mean</th>\n",
       "      <th>ACC_y_std</th>\n",
       "      <th>...</th>\n",
       "      <th>c_ACC_z_min</th>\n",
       "      <th>c_ACC_z_max</th>\n",
       "      <th>c_Temp_mean</th>\n",
       "      <th>c_Temp_std</th>\n",
       "      <th>c_Temp_min</th>\n",
       "      <th>c_Temp_max</th>\n",
       "      <th>BVP_peak_freq</th>\n",
       "      <th>TEMP_slope</th>\n",
       "      <th>subject</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>0.017769</td>\n",
       "      <td>-0.037843</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.222594e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.870000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>29.168923</td>\n",
       "      <td>0.064290</td>\n",
       "      <td>28.994568</td>\n",
       "      <td>29.426208</td>\n",
       "      <td>0.081425</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>7.290999e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.759400</td>\n",
       "      <td>-0.681000</td>\n",
       "      <td>28.886605</td>\n",
       "      <td>0.074846</td>\n",
       "      <td>28.730682</td>\n",
       "      <td>29.207275</td>\n",
       "      <td>0.147017</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.028378</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>-0.002752</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>4.805734e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.753400</td>\n",
       "      <td>-0.675400</td>\n",
       "      <td>28.799659</td>\n",
       "      <td>0.037924</td>\n",
       "      <td>28.679108</td>\n",
       "      <td>28.988800</td>\n",
       "      <td>0.088210</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.033268</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>-0.030962</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6.126303e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.787800</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>28.768865</td>\n",
       "      <td>0.058639</td>\n",
       "      <td>28.584656</td>\n",
       "      <td>29.023285</td>\n",
       "      <td>0.117614</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>8.837530e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.720200</td>\n",
       "      <td>-0.657000</td>\n",
       "      <td>28.598514</td>\n",
       "      <td>0.068128</td>\n",
       "      <td>28.447449</td>\n",
       "      <td>28.882599</td>\n",
       "      <td>0.151541</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>619</td>\n",
       "      <td>0.028499</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>0.009549</td>\n",
       "      <td>0.049915</td>\n",
       "      <td>-0.006100</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>-0.015845</td>\n",
       "      <td>0.024521</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>3.952020e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.540288</td>\n",
       "      <td>0.048413</td>\n",
       "      <td>34.173330</td>\n",
       "      <td>0.037962</td>\n",
       "      <td>34.020692</td>\n",
       "      <td>34.347792</td>\n",
       "      <td>0.150990</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>15.151558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.037179</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.023449</td>\n",
       "      <td>0.050451</td>\n",
       "      <td>-0.001681</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>-0.014134</td>\n",
       "      <td>0.012868</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>7.917207e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.749950</td>\n",
       "      <td>-0.539231</td>\n",
       "      <td>34.179298</td>\n",
       "      <td>0.031306</td>\n",
       "      <td>34.074914</td>\n",
       "      <td>34.339609</td>\n",
       "      <td>0.123940</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>12.392020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>621</td>\n",
       "      <td>0.037896</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>0.056589</td>\n",
       "      <td>0.037896</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>0.056589</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>3.289295e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.374418</td>\n",
       "      <td>0.053229</td>\n",
       "      <td>34.265974</td>\n",
       "      <td>0.034625</td>\n",
       "      <td>34.133383</td>\n",
       "      <td>34.413883</td>\n",
       "      <td>0.085883</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>15.314008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>622</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.019131</td>\n",
       "      <td>0.044707</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.012419</td>\n",
       "      <td>0.037995</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>1.429441e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.328649</td>\n",
       "      <td>0.046121</td>\n",
       "      <td>34.319910</td>\n",
       "      <td>0.027538</td>\n",
       "      <td>34.228198</td>\n",
       "      <td>34.463565</td>\n",
       "      <td>0.122004</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>15.512260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623</td>\n",
       "      <td>0.026818</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.072014</td>\n",
       "      <td>-0.026803</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>-0.072014</td>\n",
       "      <td>0.007377</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>5.140882e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426153</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>34.554872</td>\n",
       "      <td>0.028156</td>\n",
       "      <td>34.452379</td>\n",
       "      <td>34.690336</td>\n",
       "      <td>0.111528</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     net_acc_mean  net_acc_std  net_acc_min  net_acc_max  ACC_x_mean  \\\n",
       "0        0.025961     0.013811     0.000000     0.087383    0.023431   \n",
       "1        0.027640     0.010597     0.002752     0.054356    0.027640   \n",
       "2        0.028389     0.006937     0.000000     0.066053    0.028378   \n",
       "3        0.033268     0.007670     0.000000     0.074998    0.032960   \n",
       "4        0.037021     0.001284     0.027522     0.043347    0.037021   \n",
       "..            ...          ...          ...          ...         ...   \n",
       "619      0.028499     0.005744     0.009549     0.049915   -0.006100   \n",
       "620      0.037179     0.001151     0.023449     0.050451   -0.001681   \n",
       "621      0.037896     0.004781     0.003547     0.056589    0.037896   \n",
       "622      0.028627     0.002078     0.019131     0.044707    0.021569   \n",
       "623      0.026818     0.007420     0.003802     0.072014   -0.026803   \n",
       "\n",
       "     ACC_x_std  ACC_x_min  ACC_x_max  ACC_y_mean     ACC_y_std  ...  \\\n",
       "0     0.017769  -0.037843   0.087383    0.000016  1.222594e-05  ...   \n",
       "1     0.010597   0.002752   0.054356    0.000019  7.290999e-06  ...   \n",
       "2     0.006985  -0.002752   0.066053    0.000020  4.805734e-06  ...   \n",
       "3     0.008904  -0.030962   0.074998    0.000023  6.126303e-06  ...   \n",
       "4     0.001284   0.027522   0.043347    0.000025  8.837530e-07  ...   \n",
       "..         ...        ...        ...         ...           ...  ...   \n",
       "619   0.005744  -0.015845   0.024521   -0.000004  3.952020e-06  ...   \n",
       "620   0.001151  -0.014134   0.012868   -0.000001  7.917207e-07  ...   \n",
       "621   0.004781   0.003547   0.056589    0.000026  3.289295e-06  ...   \n",
       "622   0.002078   0.012419   0.037995    0.000015  1.429441e-06  ...   \n",
       "623   0.007472  -0.072014   0.007377   -0.000018  5.140882e-06  ...   \n",
       "\n",
       "     c_ACC_z_min  c_ACC_z_max  c_Temp_mean  c_Temp_std  c_Temp_min  \\\n",
       "0      -0.870000     0.611000    29.168923    0.064290   28.994568   \n",
       "1      -0.759400    -0.681000    28.886605    0.074846   28.730682   \n",
       "2      -0.753400    -0.675400    28.799659    0.037924   28.679108   \n",
       "3      -0.787800     0.166000    28.768865    0.058639   28.584656   \n",
       "4      -0.720200    -0.657000    28.598514    0.068128   28.447449   \n",
       "..           ...          ...          ...         ...         ...   \n",
       "619    -0.540288     0.048413    34.173330    0.037962   34.020692   \n",
       "620    -0.749950    -0.539231    34.179298    0.031306   34.074914   \n",
       "621    -0.374418     0.053229    34.265974    0.034625   34.133383   \n",
       "622    -0.328649     0.046121    34.319910    0.027538   34.228198   \n",
       "623    -0.426153     0.004268    34.554872    0.028156   34.452379   \n",
       "\n",
       "     c_Temp_max  BVP_peak_freq  TEMP_slope    subject  label  \n",
       "0     29.426208       0.081425   -0.000253   2.000000      0  \n",
       "1     29.207275       0.147017   -0.000161   2.000000      0  \n",
       "2     28.988800       0.088210    0.000535   2.000000      0  \n",
       "3     29.023285       0.117614   -0.000256   2.000000      0  \n",
       "4     28.882599       0.151541    0.000260   2.000000      0  \n",
       "..          ...            ...         ...        ...    ...  \n",
       "619   34.347792       0.150990   -0.000174  15.151558      1  \n",
       "620   34.339609       0.123940    0.000388  12.392020      1  \n",
       "621   34.413883       0.085883    0.000197  15.314008      1  \n",
       "622   34.463565       0.122004   -0.000229  15.512260      1  \n",
       "623   34.690336       0.111528   -0.000408  11.000000      1  \n",
       "\n",
       "[624 rows x 72 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "X, y= sm.fit_sample(df[features_with_sub], df['label'])\n",
    "df_new=pd.concat([pd.DataFrame(X,columns=features_with_sub),pd.DataFrame(y,columns=['label'])],axis=1)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #random oversampling\n",
    "# ros = RandomOverSampler(random_state=0)\n",
    "# X, y= ros.fit_resample(df[features_with_sub], df['label'])\n",
    "# df_new=pd.concat([pd.DataFrame(X,columns=features_with_sub),pd.DataFrame(y,columns=['label'])],axis=1)\n",
    "# df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(list(df_new['subject']))):\n",
    "#         df_new[df_new['subject']][i]=min([2,3,4,5,6,7,8,9,10,11,13,14,15,16,17], key=lambda x:abs(x-list(df_new[df_new['subject']])[i]))\n",
    "\n",
    "\n",
    "for i in range (len(list(df_new['subject']))):\n",
    "    df_new['subject'][i] = min([2,3,4,5,6,7,8,9,10,11,13,14,15,16,17], key=lambda x:abs(x-df_new['subject'][i]))\n",
    "df_new['subject']=df_new['subject'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_d=pd.read_csv('personal_detail.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_acc_mean</th>\n",
       "      <th>net_acc_std</th>\n",
       "      <th>net_acc_min</th>\n",
       "      <th>net_acc_max</th>\n",
       "      <th>ACC_x_mean</th>\n",
       "      <th>ACC_x_std</th>\n",
       "      <th>ACC_x_min</th>\n",
       "      <th>ACC_x_max</th>\n",
       "      <th>ACC_y_mean</th>\n",
       "      <th>ACC_y_std</th>\n",
       "      <th>...</th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>gender_ female</th>\n",
       "      <th>coffee_today_YES</th>\n",
       "      <th>sport_today_YES</th>\n",
       "      <th>smoker_YES</th>\n",
       "      <th>feel_ill_today_YES</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>0.017769</td>\n",
       "      <td>-0.037843</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.222594e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>7.290999e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.028378</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>-0.002752</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>4.805734e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.033268</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>-0.030962</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6.126303e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>8.837530e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>619</td>\n",
       "      <td>0.031629</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.028210</td>\n",
       "      <td>0.039219</td>\n",
       "      <td>-0.031629</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>-0.039219</td>\n",
       "      <td>-0.028210</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>7.864926e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.033437</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>0.051604</td>\n",
       "      <td>-0.033437</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>-0.051604</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>1.059291e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>621</td>\n",
       "      <td>0.031757</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.037155</td>\n",
       "      <td>-0.031757</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>-0.037155</td>\n",
       "      <td>-0.013761</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>1.101023e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>622</td>\n",
       "      <td>0.029441</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.020770</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>-0.004075</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>-0.014956</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.440095e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.020918</td>\n",
       "      <td>0.053804</td>\n",
       "      <td>-0.004624</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>-0.015439</td>\n",
       "      <td>0.017447</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.427082e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     net_acc_mean  net_acc_std  net_acc_min  net_acc_max  ACC_x_mean  \\\n",
       "0        0.025961     0.013811     0.000000     0.087383    0.023431   \n",
       "1        0.027640     0.010597     0.002752     0.054356    0.027640   \n",
       "2        0.028389     0.006937     0.000000     0.066053    0.028378   \n",
       "3        0.033268     0.007670     0.000000     0.074998    0.032960   \n",
       "4        0.037021     0.001284     0.027522     0.043347    0.037021   \n",
       "..            ...          ...          ...          ...         ...   \n",
       "619      0.031629     0.001143     0.028210     0.039219   -0.031629   \n",
       "620      0.033437     0.001540     0.013073     0.051604   -0.033437   \n",
       "621      0.031757     0.001600     0.013761     0.037155   -0.031757   \n",
       "622      0.029441     0.002093     0.020770     0.054100   -0.004075   \n",
       "623      0.029484     0.002074     0.020918     0.053804   -0.004624   \n",
       "\n",
       "     ACC_x_std  ACC_x_min  ACC_x_max  ACC_y_mean     ACC_y_std  ...  label  \\\n",
       "0     0.017769  -0.037843   0.087383    0.000016  1.222594e-05  ...      0   \n",
       "1     0.010597   0.002752   0.054356    0.000019  7.290999e-06  ...      0   \n",
       "2     0.006985  -0.002752   0.066053    0.000020  4.805734e-06  ...      0   \n",
       "3     0.008904  -0.030962   0.074998    0.000023  6.126303e-06  ...      0   \n",
       "4     0.001284   0.027522   0.043347    0.000025  8.837530e-07  ...      0   \n",
       "..         ...        ...        ...         ...           ...  ...    ...   \n",
       "619   0.001143  -0.039219  -0.028210   -0.000022  7.864926e-07  ...      1   \n",
       "620   0.001540  -0.051604  -0.013073   -0.000023  1.059291e-06  ...      1   \n",
       "621   0.001600  -0.037155  -0.013761   -0.000022  1.101023e-06  ...      1   \n",
       "622   0.002093  -0.014956   0.018375   -0.000003  1.440095e-06  ...      1   \n",
       "623   0.002074  -0.015439   0.017447   -0.000003  1.427082e-06  ...      1   \n",
       "\n",
       "     age  height  weight  gender_ female  coffee_today_YES  sport_today_YES  \\\n",
       "0     27     175      80               0                 0                0   \n",
       "1     27     175      80               0                 0                0   \n",
       "2     27     175      80               0                 0                0   \n",
       "3     27     175      80               0                 0                0   \n",
       "4     27     175      80               0                 0                0   \n",
       "..   ...     ...     ...             ...               ...              ...   \n",
       "619   29     165      55               1                 0                0   \n",
       "620   29     165      55               1                 0                0   \n",
       "621   29     165      55               1                 0                0   \n",
       "622   29     165      55               1                 0                0   \n",
       "623   29     165      55               1                 0                0   \n",
       "\n",
       "     smoker_YES  feel_ill_today_YES  bmi  \n",
       "0             0                   0    1  \n",
       "1             0                   0    1  \n",
       "2             0                   0    1  \n",
       "3             0                   0    1  \n",
       "4             0                   0    1  \n",
       "..          ...                 ...  ...  \n",
       "619           0                   0    0  \n",
       "620           0                   0    0  \n",
       "621           0                   0    0  \n",
       "622           0                   0    0  \n",
       "623           0                   0    0  \n",
       "\n",
       "[624 rows x 81 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1=df_new.merge(p_d,on='subject')\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    312\n",
       "0    312\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=df_new_1.columns.tolist()\n",
    "features\n",
    "\n",
    "removed = ['label']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "features_with_sub=[]\n",
    "features_with_sub[:]=features\n",
    "removed = ['subject']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "feature=features\n",
    "print(len(feature))\n",
    "len(features_with_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df_new_1[df_new_1['subject']<=9]\n",
    "test=df_new_1[df_new_1['subject']>9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer()\n",
    "scaled_data_train = scaler.fit_transform(train[feature])\n",
    "scaled_data_test = scaler.transform(test[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range (0,500):\n",
    "    #print (i)\n",
    "    et = ExtraTreesClassifier(n_estimators=50,n_jobs=10,random_state=i ,)\n",
    "    et.fit(scaled_data_train,train['label'])\n",
    "    y_pred=et.predict(scaled_data_test)\n",
    "   \n",
    "    if ((classification_report(test['label'],y_pred,output_dict=True)['accuracy'])>=.96):\n",
    "        print(i)\n",
    "        print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       147\n",
      "           1       0.93      0.90      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87       147\n",
      "           1       0.91      0.84      0.87       161\n",
      "\n",
      "    accuracy                           0.87       308\n",
      "   macro avg       0.87      0.88      0.87       308\n",
      "weighted avg       0.88      0.87      0.87       308\n",
      "\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91       147\n",
      "           1       0.90      0.94      0.92       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89       147\n",
      "           1       0.90      0.90      0.90       161\n",
      "\n",
      "    accuracy                           0.89       308\n",
      "   macro avg       0.89      0.89      0.89       308\n",
      "weighted avg       0.89      0.89      0.89       308\n",
      "\n",
      "4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       147\n",
      "           1       0.93      0.93      0.93       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90       147\n",
      "           1       0.94      0.86      0.90       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.90      0.90      0.90       308\n",
      "weighted avg       0.90      0.90      0.90       308\n",
      "\n",
      "6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       147\n",
      "           1       0.93      0.93      0.93       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       147\n",
      "           1       0.94      0.92      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       147\n",
      "           1       0.96      0.90      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.87       147\n",
      "           1       0.94      0.81      0.87       161\n",
      "\n",
      "    accuracy                           0.87       308\n",
      "   macro avg       0.88      0.87      0.87       308\n",
      "weighted avg       0.88      0.87      0.87       308\n",
      "\n",
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       147\n",
      "           1       0.93      0.93      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       147\n",
      "           1       0.96      0.86      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.93       147\n",
      "           1       0.95      0.91      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       147\n",
      "           1       0.95      0.88      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       147\n",
      "           1       0.95      0.90      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89       147\n",
      "           1       0.94      0.84      0.89       161\n",
      "\n",
      "    accuracy                           0.89       308\n",
      "   macro avg       0.89      0.89      0.89       308\n",
      "weighted avg       0.89      0.89      0.89       308\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       147\n",
      "           1       0.95      0.90      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       147\n",
      "           1       0.94      0.90      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       147\n",
      "           1       0.96      0.91      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       147\n",
      "           1       0.91      0.87      0.89       161\n",
      "\n",
      "    accuracy                           0.89       308\n",
      "   macro avg       0.89      0.89      0.89       308\n",
      "weighted avg       0.89      0.89      0.89       308\n",
      "\n",
      "20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       147\n",
      "           1       0.93      0.94      0.94       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90       147\n",
      "           1       0.91      0.90      0.91       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.90      0.90      0.90       308\n",
      "weighted avg       0.90      0.90      0.90       308\n",
      "\n",
      "22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       147\n",
      "           1       0.96      0.85      0.90       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.91      0.91      0.90       308\n",
      "weighted avg       0.91      0.90      0.90       308\n",
      "\n",
      "23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       147\n",
      "           1       0.95      0.87      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       147\n",
      "           1       0.97      0.88      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90       147\n",
      "           1       0.91      0.91      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       147\n",
      "           1       0.95      0.93      0.94       161\n",
      "\n",
      "    accuracy                           0.94       308\n",
      "   macro avg       0.94      0.94      0.94       308\n",
      "weighted avg       0.94      0.94      0.94       308\n",
      "\n",
      "27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       147\n",
      "           1       0.94      0.89      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88       147\n",
      "           1       0.86      0.94      0.90       161\n",
      "\n",
      "    accuracy                           0.89       308\n",
      "   macro avg       0.90      0.89      0.89       308\n",
      "weighted avg       0.90      0.89      0.89       308\n",
      "\n",
      "29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       147\n",
      "           1       0.96      0.88      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89       147\n",
      "           1       0.91      0.90      0.90       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.90      0.90      0.90       308\n",
      "weighted avg       0.90      0.90      0.90       308\n",
      "\n",
      "31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       147\n",
      "           1       0.94      0.91      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       147\n",
      "           1       0.92      0.88      0.90       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.90      0.90      0.90       308\n",
      "weighted avg       0.90      0.90      0.90       308\n",
      "\n",
      "33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       147\n",
      "           1       0.94      0.91      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93       147\n",
      "           1       0.94      0.92      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.92       147\n",
      "           1       0.95      0.89      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       147\n",
      "           1       0.93      0.91      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92       147\n",
      "           1       0.95      0.88      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       147\n",
      "           1       0.94      0.93      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       147\n",
      "           1       0.97      0.89      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91       147\n",
      "           1       0.96      0.87      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.92      0.91      0.91       308\n",
      "\n",
      "41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       147\n",
      "           1       0.93      0.89      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90       147\n",
      "           1       0.96      0.83      0.89       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.90      0.90      0.90       308\n",
      "weighted avg       0.90      0.90      0.90       308\n",
      "\n",
      "43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       147\n",
      "           1       0.94      0.88      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       147\n",
      "           1       0.95      0.91      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       147\n",
      "           1       0.93      0.88      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       147\n",
      "           1       0.96      0.93      0.94       161\n",
      "\n",
      "    accuracy                           0.94       308\n",
      "   macro avg       0.94      0.94      0.94       308\n",
      "weighted avg       0.94      0.94      0.94       308\n",
      "\n",
      "47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89       147\n",
      "           1       0.92      0.86      0.89       161\n",
      "\n",
      "    accuracy                           0.89       308\n",
      "   macro avg       0.89      0.89      0.89       308\n",
      "weighted avg       0.89      0.89      0.89       308\n",
      "\n",
      "48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       147\n",
      "           1       0.96      0.90      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       147\n",
      "           1       0.95      0.98      0.97       161\n",
      "\n",
      "    accuracy                           0.96       308\n",
      "   macro avg       0.97      0.96      0.96       308\n",
      "weighted avg       0.96      0.96      0.96       308\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       147\n",
      "           1       0.97      0.88      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.93      0.92      0.92       308\n",
      "\n",
      "51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91       147\n",
      "           1       0.94      0.88      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       147\n",
      "           1       0.95      0.88      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       147\n",
      "           1       0.95      0.86      0.90       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.91      0.90      0.90       308\n",
      "weighted avg       0.91      0.90      0.90       308\n",
      "\n",
      "54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       147\n",
      "           1       0.93      0.86      0.89       161\n",
      "\n",
      "    accuracy                           0.89       308\n",
      "   macro avg       0.89      0.89      0.89       308\n",
      "weighted avg       0.89      0.89      0.89       308\n",
      "\n",
      "55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       147\n",
      "           1       0.91      0.92      0.92       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       147\n",
      "           1       0.96      0.85      0.90       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.91      0.91      0.90       308\n",
      "weighted avg       0.91      0.90      0.90       308\n",
      "\n",
      "57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       147\n",
      "           1       0.95      0.92      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91       147\n",
      "           1       0.94      0.89      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       147\n",
      "           1       0.95      0.87      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91       147\n",
      "           1       0.99      0.84      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.92      0.91      0.91       308\n",
      "weighted avg       0.92      0.91      0.91       308\n",
      "\n",
      "61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       147\n",
      "           1       0.97      0.93      0.95       161\n",
      "\n",
      "    accuracy                           0.94       308\n",
      "   macro avg       0.94      0.95      0.94       308\n",
      "weighted avg       0.95      0.94      0.94       308\n",
      "\n",
      "62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93       147\n",
      "           1       0.95      0.92      0.94       161\n",
      "\n",
      "    accuracy                           0.94       308\n",
      "   macro avg       0.93      0.94      0.94       308\n",
      "weighted avg       0.94      0.94      0.94       308\n",
      "\n",
      "63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       147\n",
      "           1       0.96      0.88      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90       147\n",
      "           1       0.94      0.86      0.90       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.90      0.90      0.90       308\n",
      "weighted avg       0.90      0.90      0.90       308\n",
      "\n",
      "65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88       147\n",
      "           1       0.93      0.84      0.88       161\n",
      "\n",
      "    accuracy                           0.88       308\n",
      "   macro avg       0.88      0.88      0.88       308\n",
      "weighted avg       0.89      0.88      0.88       308\n",
      "\n",
      "66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       147\n",
      "           1       0.97      0.89      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       147\n",
      "           1       0.96      0.90      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       147\n",
      "           1       0.97      0.87      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       147\n",
      "           1       0.92      0.89      0.91       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.90      0.90      0.90       308\n",
      "weighted avg       0.90      0.90      0.90       308\n",
      "\n",
      "70\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       147\n",
      "           1       0.96      0.98      0.97       161\n",
      "\n",
      "    accuracy                           0.96       308\n",
      "   macro avg       0.96      0.96      0.96       308\n",
      "weighted avg       0.96      0.96      0.96       308\n",
      "\n",
      "71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91       147\n",
      "           1       0.96      0.86      0.90       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94       147\n",
      "           1       0.96      0.92      0.94       161\n",
      "\n",
      "    accuracy                           0.94       308\n",
      "   macro avg       0.94      0.94      0.94       308\n",
      "weighted avg       0.94      0.94      0.94       308\n",
      "\n",
      "73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       147\n",
      "           1       0.93      0.95      0.94       161\n",
      "\n",
      "    accuracy                           0.94       308\n",
      "   macro avg       0.94      0.93      0.93       308\n",
      "weighted avg       0.94      0.94      0.94       308\n",
      "\n",
      "74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91       147\n",
      "           1       0.91      0.93      0.92       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89       147\n",
      "           1       0.94      0.84      0.89       161\n",
      "\n",
      "    accuracy                           0.89       308\n",
      "   macro avg       0.89      0.89      0.89       308\n",
      "weighted avg       0.89      0.89      0.89       308\n",
      "\n",
      "76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       147\n",
      "           1       0.93      0.89      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       147\n",
      "           1       0.93      0.96      0.94       161\n",
      "\n",
      "    accuracy                           0.94       308\n",
      "   macro avg       0.94      0.94      0.94       308\n",
      "weighted avg       0.94      0.94      0.94       308\n",
      "\n",
      "78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       147\n",
      "           1       0.95      0.87      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       147\n",
      "           1       0.94      0.90      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "80\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90       147\n",
      "           1       0.93      0.88      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       147\n",
      "           1       0.91      0.89      0.90       161\n",
      "\n",
      "    accuracy                           0.89       308\n",
      "   macro avg       0.89      0.89      0.89       308\n",
      "weighted avg       0.89      0.89      0.89       308\n",
      "\n",
      "82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.91       147\n",
      "           1       0.95      0.86      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87       147\n",
      "           1       0.92      0.83      0.87       161\n",
      "\n",
      "    accuracy                           0.87       308\n",
      "   macro avg       0.87      0.87      0.87       308\n",
      "weighted avg       0.87      0.87      0.87       308\n",
      "\n",
      "84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       147\n",
      "           1       0.94      0.90      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       147\n",
      "           1       0.96      0.91      0.94       161\n",
      "\n",
      "    accuracy                           0.94       308\n",
      "   macro avg       0.94      0.94      0.94       308\n",
      "weighted avg       0.94      0.94      0.94       308\n",
      "\n",
      "86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.92       147\n",
      "           1       0.90      0.96      0.93       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       147\n",
      "           1       0.93      0.95      0.94       161\n",
      "\n",
      "    accuracy                           0.94       308\n",
      "   macro avg       0.94      0.93      0.93       308\n",
      "weighted avg       0.94      0.94      0.94       308\n",
      "\n",
      "88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       147\n",
      "           1       0.97      0.90      0.94       161\n",
      "\n",
      "    accuracy                           0.94       308\n",
      "   macro avg       0.94      0.94      0.94       308\n",
      "weighted avg       0.94      0.94      0.94       308\n",
      "\n",
      "89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92       147\n",
      "           1       0.95      0.90      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89       147\n",
      "           1       0.91      0.89      0.90       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.90      0.90      0.90       308\n",
      "weighted avg       0.90      0.90      0.90       308\n",
      "\n",
      "91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90       147\n",
      "           1       0.93      0.88      0.90       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.90      0.90      0.90       308\n",
      "weighted avg       0.90      0.90      0.90       308\n",
      "\n",
      "92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92       147\n",
      "           1       0.93      0.93      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       147\n",
      "           1       0.93      0.94      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n",
      "94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       147\n",
      "           1       0.92      0.88      0.90       161\n",
      "\n",
      "    accuracy                           0.89       308\n",
      "   macro avg       0.89      0.89      0.89       308\n",
      "weighted avg       0.89      0.89      0.89       308\n",
      "\n",
      "95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       147\n",
      "           1       0.93      0.92      0.93       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90       147\n",
      "           1       0.94      0.86      0.90       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.90      0.90      0.90       308\n",
      "weighted avg       0.90      0.90      0.90       308\n",
      "\n",
      "97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       147\n",
      "           1       0.90      0.94      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.92       147\n",
      "           1       0.93      0.92      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n",
      "99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.95      0.91       147\n",
      "           1       0.95      0.89      0.92       161\n",
      "\n",
      "    accuracy                           0.92       308\n",
      "   macro avg       0.92      0.92      0.92       308\n",
      "weighted avg       0.92      0.92      0.92       308\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93       147\n",
      "           1       0.97      0.88      0.93       161\n",
      "\n",
      "    accuracy                           0.93       308\n",
      "   macro avg       0.93      0.93      0.93       308\n",
      "weighted avg       0.93      0.93      0.93       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#c+w\n",
    "#62,70\n",
    "\n",
    "for i in range (101):\n",
    "    #print (i)\n",
    "    et = ExtraTreesClassifier(n_estimators=50,n_jobs=10,random_state=i ,)\n",
    "    et.fit(train[feature],train['label'])\n",
    "    y_pred=et.predict(test[feature])\n",
    "   \n",
    "    if ((classification_report(test['label'],y_pred,output_dict=True)['0']['recall'])>.65):\n",
    "        print(i)\n",
    "        print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of labels=316 does not match number of samples=624",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-295f6a210909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#print (i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0met\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0met\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0met\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print(classification_report(test['label'],y_pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 330\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;31m# We capture the KeyboardInterrupt and reraise it as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             raise ValueError(\"Number of labels=%d does not match \"\n\u001b[0;32m--> 250\u001b[0;31m                              \"number of samples=%d\" % (len(y), n_samples))\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_weight_fraction_leaf\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"min_weight_fraction_leaf must in [0, 0.5]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of labels=316 does not match number of samples=624"
     ]
    }
   ],
   "source": [
    "for i in range (101):\n",
    "    #print (i)\n",
    "    et = ExtraTreesClassifier(n_estimators=100,n_jobs=10,random_state=i)\n",
    "    et.fit(X,train['label'])\n",
    "    y_pred=et.predict(X_test)\n",
    "    #print(classification_report(test['label'],y_pred))\n",
    "    if ((classification_report(test['label'],y_pred,output_dict=True)['0']['recall'])>.60 and (classification_report(test['label'],y_pred,output_dict=True)['2']['recall'])>.60):\n",
    "        print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89       147\n",
      "           1       0.87      0.95      0.91       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.91      0.90      0.90       308\n",
      "weighted avg       0.91      0.90      0.90       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100,n_jobs=10,random_state=56)\n",
    "et.fit(scaled_data_train,train['label'])\n",
    "y_pred=et.predict(scaled_data_test)\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['net_acc_mean',\n",
       " 'net_acc_std',\n",
       " 'net_acc_min',\n",
       " 'net_acc_max',\n",
       " 'ACC_x_mean',\n",
       " 'ACC_x_std',\n",
       " 'ACC_x_min',\n",
       " 'ACC_x_max',\n",
       " 'ACC_y_mean',\n",
       " 'ACC_y_std',\n",
       " 'ACC_y_min',\n",
       " 'ACC_y_max',\n",
       " 'ACC_z_mean',\n",
       " 'ACC_z_std',\n",
       " 'ACC_z_min',\n",
       " 'ACC_z_max',\n",
       " 'BVP_mean',\n",
       " 'BVP_std',\n",
       " 'BVP_min',\n",
       " 'BVP_max',\n",
       " 'ECG_mean',\n",
       " 'ECG_std',\n",
       " 'ECG_min',\n",
       " 'ECG_max',\n",
       " 'EDA_mean',\n",
       " 'EDA_std',\n",
       " 'EDA_min',\n",
       " 'EDA_max',\n",
       " 'EDA_phasic_mean',\n",
       " 'EDA_phasic_std',\n",
       " 'EDA_phasic_min',\n",
       " 'EDA_phasic_max',\n",
       " 'EDA_smna_mean',\n",
       " 'EDA_smna_std',\n",
       " 'EDA_smna_min',\n",
       " 'EDA_smna_max',\n",
       " 'EDA_tonic_mean',\n",
       " 'EDA_tonic_std',\n",
       " 'EDA_tonic_min',\n",
       " 'EDA_tonic_max',\n",
       " 'EMG_mean',\n",
       " 'EMG_std',\n",
       " 'EMG_min',\n",
       " 'EMG_max',\n",
       " 'Resp_mean',\n",
       " 'Resp_std',\n",
       " 'Resp_min',\n",
       " 'Resp_max',\n",
       " 'TEMP_mean',\n",
       " 'TEMP_std',\n",
       " 'TEMP_min',\n",
       " 'TEMP_max',\n",
       " 'c_ACC_x_mean',\n",
       " 'c_ACC_x_std',\n",
       " 'c_ACC_x_min',\n",
       " 'c_ACC_x_max',\n",
       " 'c_ACC_y_mean',\n",
       " 'c_ACC_y_std',\n",
       " 'c_ACC_y_min',\n",
       " 'c_ACC_y_max',\n",
       " 'c_ACC_z_mean',\n",
       " 'c_ACC_z_std',\n",
       " 'c_ACC_z_min',\n",
       " 'c_ACC_z_max',\n",
       " 'c_Temp_mean',\n",
       " 'c_Temp_std',\n",
       " 'c_Temp_min',\n",
       " 'c_Temp_max',\n",
       " 'BVP_peak_freq',\n",
       " 'TEMP_slope',\n",
       " 'age',\n",
       " 'height',\n",
       " 'weight',\n",
       " 'gender_ female',\n",
       " 'coffee_today_YES',\n",
       " 'sport_today_YES',\n",
       " 'smoker_YES',\n",
       " 'feel_ill_today_YES',\n",
       " 'bmi']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       "      estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None,\n",
       "                                     criterion='gini', max_depth=None,\n",
       "                                     max_features='auto', max_leaf_nodes=None,\n",
       "                                     min_impurity_decrease=0.0,\n",
       "                                     min_impurity_split=None,\n",
       "                                     min_samples_leaf=1, min_samples_split=2,\n",
       "                                     min_weight_fraction_leaf=0.0,\n",
       "                                     n_estimators=50, n_jobs=10,\n",
       "                                     oob_score=False, random_state=499,\n",
       "                                     verbose=0, warm_start=False),\n",
       "      min_features_to_select=1, n_jobs=None, scoring='accuracy', step=1,\n",
       "      verbose=0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv = RFECV(estimator=et, step=1, cv=StratifiedKFold(10), scoring='accuracy')\n",
    "rfecv.fit(train[feature],train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 20\n"
     ]
    }
   ],
   "source": [
    "print('Optimal number of features: {}'.format(rfecv.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "plt.title('Recursive Feature Elimination with Cross-Validation', fontsize=18, fontweight='bold', pad=20)\n",
    "plt.xlabel('Number of features selected', fontsize=14, labelpad=20)\n",
    "plt.ylabel('% Correct Classification', fontsize=14, labelpad=20)\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_, color='#303F9F', linewidth=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 17 18 19 20 21 22 23 25\n",
      " 29 30 34 35 37 40 41 42 43 44 46 49 53 54 56 57 58 59 61 62 63 64 65 66\n",
      " 67 68 70 71 72 73 74 75 76 77 78]\n"
     ]
    }
   ],
   "source": [
    "print(np.where(rfecv.support_ == False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "X=train[feature]\n",
    "X.drop(X.columns[np.where(rfecv.support_ == False)[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17, 41, 44, 26,  3, 21, 37, 40, 19, 45, 57, 27,  1, 28, 38, 20, 56,\n",
       "       31, 42, 50, 51,  9, 18, 25,  1, 10,  1,  1,  1,  5,  6,  1,  1,  1,\n",
       "       60,  4,  1, 12,  1,  1, 16, 52, 35, 32, 43,  1, 13,  1,  1, 30,  1,\n",
       "        1,  1, 24, 54,  1,  8, 48, 49, 34,  1, 23, 14,  2,  7, 58, 11, 15,\n",
       "       22,  1, 46, 33, 39, 55, 36, 29, 53, 47, 59])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      "  True False False False False False False False False False False False\n",
      "  True False  True  True  True False False  True  True  True False False\n",
      "  True False  True  True False False False False False  True False  True\n",
      "  True False  True  True  True False False  True False False False False\n",
      "  True False False False False False False False False  True False False\n",
      " False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "print(rfecv.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rfecv.estimator_.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1008 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dset = pd.DataFrame()\n",
    "dset['attr'] = X.columns\n",
    "dset['importance'] = rfecv.estimator_.feature_importances_\n",
    "\n",
    "dset = dset.sort_values(by='importance', ascending=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "plt.barh(y=dset['attr'], width=dset['importance'], color='#1976D2')\n",
    "plt.title('RFECV - Feature Importances', fontsize=20, fontweight='bold', pad=20)\n",
    "plt.xlabel('Importance', fontsize=14, labelpad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10      EDA_tonic_max\n",
       "8      EDA_tonic_mean\n",
       "9       EDA_tonic_min\n",
       "6       EDA_smna_mean\n",
       "12           Resp_max\n",
       "11           Resp_std\n",
       "4     EDA_phasic_mean\n",
       "5      EDA_phasic_max\n",
       "2             EDA_min\n",
       "16       c_ACC_x_mean\n",
       "18       c_ACC_z_mean\n",
       "1            EDA_mean\n",
       "14           TEMP_min\n",
       "3             EDA_max\n",
       "7        EDA_smna_std\n",
       "17        c_ACC_x_max\n",
       "13          TEMP_mean\n",
       "0          ACC_z_mean\n",
       "19         TEMP_slope\n",
       "15           TEMP_max\n",
       "Name: attr, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset['attr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_new=['EDA_tonic_mean','EDA_smna_mean','EDA_tonic_min','EDA_phasic_mean','TEMP_std','BVP_peak_freq','smoker_YES','ACC_y_min','ACC_x_mean','weight','gender_ female','c_Temp_max','ACC_x_max','TEMP_mean',\n",
    "          'c_ACC_y_std','net_acc_max','Resp_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-3e3d520d78ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "feature_new=feature_new.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDA_tonic_max</th>\n",
       "      <th>EDA_tonic_mean</th>\n",
       "      <th>EDA_tonic_min</th>\n",
       "      <th>EDA_smna_mean</th>\n",
       "      <th>Resp_max</th>\n",
       "      <th>Resp_std</th>\n",
       "      <th>EDA_phasic_mean</th>\n",
       "      <th>EDA_phasic_max</th>\n",
       "      <th>EDA_min</th>\n",
       "      <th>c_ACC_x_mean</th>\n",
       "      <th>c_ACC_z_mean</th>\n",
       "      <th>EDA_mean</th>\n",
       "      <th>TEMP_min</th>\n",
       "      <th>EDA_max</th>\n",
       "      <th>EDA_smna_std</th>\n",
       "      <th>c_ACC_x_max</th>\n",
       "      <th>TEMP_mean</th>\n",
       "      <th>ACC_z_mean</th>\n",
       "      <th>TEMP_slope</th>\n",
       "      <th>TEMP_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.554750</td>\n",
       "      <td>0.802956</td>\n",
       "      <td>-1.213173</td>\n",
       "      <td>1.376535</td>\n",
       "      <td>6.742859</td>\n",
       "      <td>2.890267</td>\n",
       "      <td>1.967362</td>\n",
       "      <td>4.459367</td>\n",
       "      <td>1.014138</td>\n",
       "      <td>0.771306</td>\n",
       "      <td>-0.440456</td>\n",
       "      <td>1.303625</td>\n",
       "      <td>35.750000</td>\n",
       "      <td>1.678399</td>\n",
       "      <td>2.448135</td>\n",
       "      <td>1.145400</td>\n",
       "      <td>35.807285</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>35.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.037179</td>\n",
       "      <td>1.356138</td>\n",
       "      <td>0.912441</td>\n",
       "      <td>0.107952</td>\n",
       "      <td>3.730774</td>\n",
       "      <td>1.596604</td>\n",
       "      <td>0.165267</td>\n",
       "      <td>0.544346</td>\n",
       "      <td>0.693996</td>\n",
       "      <td>0.619743</td>\n",
       "      <td>-0.715456</td>\n",
       "      <td>0.892549</td>\n",
       "      <td>35.660000</td>\n",
       "      <td>1.190967</td>\n",
       "      <td>0.223359</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>35.706833</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>35.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.907833</td>\n",
       "      <td>0.594655</td>\n",
       "      <td>0.112270</td>\n",
       "      <td>0.032987</td>\n",
       "      <td>3.450012</td>\n",
       "      <td>1.591127</td>\n",
       "      <td>0.034136</td>\n",
       "      <td>0.195283</td>\n",
       "      <td>0.486494</td>\n",
       "      <td>0.620906</td>\n",
       "      <td>-0.714748</td>\n",
       "      <td>0.598712</td>\n",
       "      <td>35.710000</td>\n",
       "      <td>0.718106</td>\n",
       "      <td>0.113638</td>\n",
       "      <td>0.646000</td>\n",
       "      <td>35.775430</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>35.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.312631</td>\n",
       "      <td>0.119998</td>\n",
       "      <td>-0.202700</td>\n",
       "      <td>0.167003</td>\n",
       "      <td>5.216980</td>\n",
       "      <td>1.879271</td>\n",
       "      <td>0.223355</td>\n",
       "      <td>0.669836</td>\n",
       "      <td>0.470152</td>\n",
       "      <td>0.668722</td>\n",
       "      <td>-0.628923</td>\n",
       "      <td>0.504760</td>\n",
       "      <td>35.770000</td>\n",
       "      <td>0.568963</td>\n",
       "      <td>0.451401</td>\n",
       "      <td>0.935000</td>\n",
       "      <td>35.830724</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>35.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.344243</td>\n",
       "      <td>0.191593</td>\n",
       "      <td>0.008598</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>3.028870</td>\n",
       "      <td>1.414976</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.063415</td>\n",
       "      <td>0.395535</td>\n",
       "      <td>0.641137</td>\n",
       "      <td>-0.695219</td>\n",
       "      <td>0.456286</td>\n",
       "      <td>35.770000</td>\n",
       "      <td>0.517990</td>\n",
       "      <td>0.009980</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>35.798869</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>35.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>311</td>\n",
       "      <td>1.409709</td>\n",
       "      <td>1.183028</td>\n",
       "      <td>0.848915</td>\n",
       "      <td>0.225563</td>\n",
       "      <td>16.876990</td>\n",
       "      <td>4.850359</td>\n",
       "      <td>0.294813</td>\n",
       "      <td>0.553913</td>\n",
       "      <td>3.453431</td>\n",
       "      <td>0.803992</td>\n",
       "      <td>-0.419182</td>\n",
       "      <td>3.639418</td>\n",
       "      <td>33.090106</td>\n",
       "      <td>3.848324</td>\n",
       "      <td>0.399256</td>\n",
       "      <td>0.936026</td>\n",
       "      <td>33.125486</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>33.156808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>1.504566</td>\n",
       "      <td>1.345943</td>\n",
       "      <td>1.209618</td>\n",
       "      <td>0.092824</td>\n",
       "      <td>12.141198</td>\n",
       "      <td>3.689281</td>\n",
       "      <td>0.118530</td>\n",
       "      <td>0.284056</td>\n",
       "      <td>1.186328</td>\n",
       "      <td>0.836427</td>\n",
       "      <td>-0.392351</td>\n",
       "      <td>1.256311</td>\n",
       "      <td>33.527959</td>\n",
       "      <td>1.328788</td>\n",
       "      <td>0.198844</td>\n",
       "      <td>0.906021</td>\n",
       "      <td>33.597790</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000530</td>\n",
       "      <td>33.649278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313</td>\n",
       "      <td>1.999980</td>\n",
       "      <td>1.814833</td>\n",
       "      <td>1.554143</td>\n",
       "      <td>0.107472</td>\n",
       "      <td>25.093782</td>\n",
       "      <td>7.397418</td>\n",
       "      <td>0.146932</td>\n",
       "      <td>0.422515</td>\n",
       "      <td>8.356053</td>\n",
       "      <td>0.895596</td>\n",
       "      <td>-0.168767</td>\n",
       "      <td>9.044468</td>\n",
       "      <td>33.785991</td>\n",
       "      <td>9.446335</td>\n",
       "      <td>0.275369</td>\n",
       "      <td>1.117158</td>\n",
       "      <td>33.875304</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000795</td>\n",
       "      <td>33.954992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>0.883535</td>\n",
       "      <td>-0.326525</td>\n",
       "      <td>-1.492209</td>\n",
       "      <td>1.178049</td>\n",
       "      <td>16.135616</td>\n",
       "      <td>5.565096</td>\n",
       "      <td>1.455426</td>\n",
       "      <td>2.848745</td>\n",
       "      <td>5.316579</td>\n",
       "      <td>0.854544</td>\n",
       "      <td>-0.300843</td>\n",
       "      <td>5.824319</td>\n",
       "      <td>32.804076</td>\n",
       "      <td>6.400912</td>\n",
       "      <td>2.432167</td>\n",
       "      <td>1.059525</td>\n",
       "      <td>32.846921</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>32.874076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>1.380667</td>\n",
       "      <td>1.222096</td>\n",
       "      <td>1.108307</td>\n",
       "      <td>0.111008</td>\n",
       "      <td>13.082665</td>\n",
       "      <td>3.855029</td>\n",
       "      <td>0.142509</td>\n",
       "      <td>0.320927</td>\n",
       "      <td>0.907532</td>\n",
       "      <td>0.856930</td>\n",
       "      <td>-0.351836</td>\n",
       "      <td>0.958621</td>\n",
       "      <td>33.422457</td>\n",
       "      <td>1.015213</td>\n",
       "      <td>0.217635</td>\n",
       "      <td>0.928976</td>\n",
       "      <td>33.501280</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000538</td>\n",
       "      <td>33.560121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>316 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     EDA_tonic_max  EDA_tonic_mean  EDA_tonic_min  EDA_smna_mean   Resp_max  \\\n",
       "0         2.554750        0.802956      -1.213173       1.376535   6.742859   \n",
       "1         2.037179        1.356138       0.912441       0.107952   3.730774   \n",
       "2         0.907833        0.594655       0.112270       0.032987   3.450012   \n",
       "3         0.312631        0.119998      -0.202700       0.167003   5.216980   \n",
       "4         0.344243        0.191593       0.008598       0.001634   3.028870   \n",
       "..             ...             ...            ...            ...        ...   \n",
       "311       1.409709        1.183028       0.848915       0.225563  16.876990   \n",
       "312       1.504566        1.345943       1.209618       0.092824  12.141198   \n",
       "313       1.999980        1.814833       1.554143       0.107472  25.093782   \n",
       "314       0.883535       -0.326525      -1.492209       1.178049  16.135616   \n",
       "315       1.380667        1.222096       1.108307       0.111008  13.082665   \n",
       "\n",
       "     Resp_std  EDA_phasic_mean  EDA_phasic_max   EDA_min  c_ACC_x_mean  \\\n",
       "0    2.890267         1.967362        4.459367  1.014138      0.771306   \n",
       "1    1.596604         0.165267        0.544346  0.693996      0.619743   \n",
       "2    1.591127         0.034136        0.195283  0.486494      0.620906   \n",
       "3    1.879271         0.223355        0.669836  0.470152      0.668722   \n",
       "4    1.414976         0.004533        0.063415  0.395535      0.641137   \n",
       "..        ...              ...             ...       ...           ...   \n",
       "311  4.850359         0.294813        0.553913  3.453431      0.803992   \n",
       "312  3.689281         0.118530        0.284056  1.186328      0.836427   \n",
       "313  7.397418         0.146932        0.422515  8.356053      0.895596   \n",
       "314  5.565096         1.455426        2.848745  5.316579      0.854544   \n",
       "315  3.855029         0.142509        0.320927  0.907532      0.856930   \n",
       "\n",
       "     c_ACC_z_mean  EDA_mean   TEMP_min   EDA_max  EDA_smna_std  c_ACC_x_max  \\\n",
       "0       -0.440456  1.303625  35.750000  1.678399      2.448135     1.145400   \n",
       "1       -0.715456  0.892549  35.660000  1.190967      0.223359     0.644200   \n",
       "2       -0.714748  0.598712  35.710000  0.718106      0.113638     0.646000   \n",
       "3       -0.628923  0.504760  35.770000  0.568963      0.451401     0.935000   \n",
       "4       -0.695219  0.456286  35.770000  0.517990      0.009980     0.665000   \n",
       "..            ...       ...        ...       ...           ...          ...   \n",
       "311     -0.419182  3.639418  33.090106  3.848324      0.399256     0.936026   \n",
       "312     -0.392351  1.256311  33.527959  1.328788      0.198844     0.906021   \n",
       "313     -0.168767  9.044468  33.785991  9.446335      0.275369     1.117158   \n",
       "314     -0.300843  5.824319  32.804076  6.400912      2.432167     1.059525   \n",
       "315     -0.351836  0.958621  33.422457  1.015213      0.217635     0.928976   \n",
       "\n",
       "     TEMP_mean  ACC_z_mean  TEMP_slope   TEMP_max  \n",
       "0    35.807285    0.000016   -0.000253  35.870000  \n",
       "1    35.706833    0.000019   -0.000161  35.750000  \n",
       "2    35.775430    0.000020    0.000535  35.840000  \n",
       "3    35.830724    0.000023   -0.000256  35.890000  \n",
       "4    35.798869    0.000025    0.000260  35.840000  \n",
       "..         ...         ...         ...        ...  \n",
       "311  33.125486    0.000026   -0.000237  33.156808  \n",
       "312  33.597790    0.000028   -0.000530  33.649278  \n",
       "313  33.875304    0.000023   -0.000795  33.954992  \n",
       "314  32.846921    0.000018   -0.000219  32.874076  \n",
       "315  33.501280    0.000028   -0.000538  33.560121  \n",
       "\n",
       "[316 rows x 20 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[feature_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_acc_mean</th>\n",
       "      <th>net_acc_std</th>\n",
       "      <th>net_acc_min</th>\n",
       "      <th>net_acc_max</th>\n",
       "      <th>ACC_x_mean</th>\n",
       "      <th>ACC_x_std</th>\n",
       "      <th>ACC_x_min</th>\n",
       "      <th>ACC_x_max</th>\n",
       "      <th>ACC_y_mean</th>\n",
       "      <th>ACC_y_std</th>\n",
       "      <th>...</th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>gender_ female</th>\n",
       "      <th>coffee_today_YES</th>\n",
       "      <th>sport_today_YES</th>\n",
       "      <th>smoker_YES</th>\n",
       "      <th>feel_ill_today_YES</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>316</td>\n",
       "      <td>0.022275</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.055044</td>\n",
       "      <td>0.022275</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.055044</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>4.598998e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>178</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317</td>\n",
       "      <td>0.021397</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.007569</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>0.021397</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.007569</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.412737e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>178</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>318</td>\n",
       "      <td>0.025337</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.015137</td>\n",
       "      <td>0.053668</td>\n",
       "      <td>0.025337</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.015137</td>\n",
       "      <td>0.053668</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>2.358348e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>178</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>0.025442</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.018577</td>\n",
       "      <td>0.030274</td>\n",
       "      <td>0.025442</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.018577</td>\n",
       "      <td>0.030274</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>9.908448e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>178</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.023126</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.048164</td>\n",
       "      <td>0.023126</td>\n",
       "      <td>0.003274</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.048164</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>2.252830e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>178</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>619</td>\n",
       "      <td>0.031629</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.028210</td>\n",
       "      <td>0.039219</td>\n",
       "      <td>-0.031629</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>-0.039219</td>\n",
       "      <td>-0.028210</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>7.864926e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.033437</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.013073</td>\n",
       "      <td>0.051604</td>\n",
       "      <td>-0.033437</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>-0.051604</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>1.059291e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>621</td>\n",
       "      <td>0.031757</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.013761</td>\n",
       "      <td>0.037155</td>\n",
       "      <td>-0.031757</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>-0.037155</td>\n",
       "      <td>-0.013761</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>1.101023e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>622</td>\n",
       "      <td>0.029441</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.020770</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>-0.004075</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>-0.014956</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.440095e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>623</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.020918</td>\n",
       "      <td>0.053804</td>\n",
       "      <td>-0.004624</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>-0.015439</td>\n",
       "      <td>0.017447</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.427082e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     net_acc_mean  net_acc_std  net_acc_min  net_acc_max  ACC_x_mean  \\\n",
       "316      0.022275     0.006684     0.003440     0.055044    0.022275   \n",
       "317      0.021397     0.003507     0.007569     0.050228    0.021397   \n",
       "318      0.025337     0.003428     0.015137     0.053668    0.025337   \n",
       "319      0.025442     0.001440     0.018577     0.030274    0.025442   \n",
       "320      0.023126     0.003274     0.008257     0.048164    0.023126   \n",
       "..            ...          ...          ...          ...         ...   \n",
       "619      0.031629     0.001143     0.028210     0.039219   -0.031629   \n",
       "620      0.033437     0.001540     0.013073     0.051604   -0.033437   \n",
       "621      0.031757     0.001600     0.013761     0.037155   -0.031757   \n",
       "622      0.029441     0.002093     0.020770     0.054100   -0.004075   \n",
       "623      0.029484     0.002074     0.020918     0.053804   -0.004624   \n",
       "\n",
       "     ACC_x_std  ACC_x_min  ACC_x_max  ACC_y_mean     ACC_y_std  ...  label  \\\n",
       "316   0.006684   0.003440   0.055044    0.000015  4.598998e-06  ...      0   \n",
       "317   0.003507   0.007569   0.050228    0.000015  2.412737e-06  ...      0   \n",
       "318   0.003428   0.015137   0.053668    0.000017  2.358348e-06  ...      0   \n",
       "319   0.001440   0.018577   0.030274    0.000018  9.908448e-07  ...      0   \n",
       "320   0.003274   0.008257   0.048164    0.000016  2.252830e-06  ...      0   \n",
       "..         ...        ...        ...         ...           ...  ...    ...   \n",
       "619   0.001143  -0.039219  -0.028210   -0.000022  7.864926e-07  ...      1   \n",
       "620   0.001540  -0.051604  -0.013073   -0.000023  1.059291e-06  ...      1   \n",
       "621   0.001600  -0.037155  -0.013761   -0.000022  1.101023e-06  ...      1   \n",
       "622   0.002093  -0.014956   0.018375   -0.000003  1.440095e-06  ...      1   \n",
       "623   0.002074  -0.015439   0.017447   -0.000003  1.427082e-06  ...      1   \n",
       "\n",
       "     age  height  weight  gender_ female  coffee_today_YES  sport_today_YES  \\\n",
       "316   28     178      76               0                 0                0   \n",
       "317   28     178      76               0                 0                0   \n",
       "318   28     178      76               0                 0                0   \n",
       "319   28     178      76               0                 0                0   \n",
       "320   28     178      76               0                 0                0   \n",
       "..   ...     ...     ...             ...               ...              ...   \n",
       "619   29     165      55               1                 0                0   \n",
       "620   29     165      55               1                 0                0   \n",
       "621   29     165      55               1                 0                0   \n",
       "622   29     165      55               1                 0                0   \n",
       "623   29     165      55               1                 0                0   \n",
       "\n",
       "     smoker_YES  feel_ill_today_YES  bmi  \n",
       "316           0                   0    0  \n",
       "317           0                   0    0  \n",
       "318           0                   0    0  \n",
       "319           0                   0    0  \n",
       "320           0                   0    0  \n",
       "..          ...                 ...  ...  \n",
       "619           0                   0    0  \n",
       "620           0                   0    0  \n",
       "621           0                   0    0  \n",
       "622           0                   0    0  \n",
       "623           0                   0    0  \n",
       "\n",
       "[308 rows x 81 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       147\n",
      "           1       0.85      0.87      0.86       161\n",
      "\n",
      "    accuracy                           0.85       308\n",
      "   macro avg       0.85      0.85      0.85       308\n",
      "weighted avg       0.85      0.85      0.85       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100,n_jobs=10,random_state=56)\n",
    "et.fit(train[feature_new],train['label'])\n",
    "y_pred=et.predict(test[feature_new])\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.91       147\n",
      "           1       0.92      0.91      0.91       161\n",
      "\n",
      "    accuracy                           0.91       308\n",
      "   macro avg       0.91      0.91      0.91       308\n",
      "weighted avg       0.91      0.91      0.91       308\n",
      "\n",
      "366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90       147\n",
      "           1       0.89      0.93      0.91       161\n",
      "\n",
      "    accuracy                           0.90       308\n",
      "   macro avg       0.90      0.90      0.90       308\n",
      "weighted avg       0.90      0.90      0.90       308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 261 best accuracy\n",
    "for i in range (101,500):\n",
    "    #print (i)\n",
    "    et = ExtraTreesClassifier(n_estimators=50,n_jobs=10,random_state=i ,)\n",
    "    et.fit(train[feature_new],train['label'])\n",
    "    y_pred=et.predict(test[feature_new])\n",
    "   \n",
    "    if ((classification_report(test['label'],y_pred,output_dict=True)['accuracy'])>=.90):\n",
    "        print(i)\n",
    "        print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
