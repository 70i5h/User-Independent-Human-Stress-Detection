{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.51 s, sys: 742 ms, total: 3.25 s\n",
      "Wall time: 6.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from itertools import combinations \n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn import model_selection\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('60s_window_wrist_chest.csv',index_col=0)\n",
    "df=df[df['label']<3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_acc_mean</th>\n",
       "      <th>net_acc_std</th>\n",
       "      <th>net_acc_min</th>\n",
       "      <th>net_acc_max</th>\n",
       "      <th>ACC_x_mean</th>\n",
       "      <th>ACC_x_std</th>\n",
       "      <th>ACC_x_min</th>\n",
       "      <th>ACC_x_max</th>\n",
       "      <th>ACC_y_mean</th>\n",
       "      <th>ACC_y_std</th>\n",
       "      <th>...</th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>gender_ female</th>\n",
       "      <th>coffee_today_YES</th>\n",
       "      <th>sport_today_YES</th>\n",
       "      <th>smoker_YES</th>\n",
       "      <th>feel_ill_today_YES</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>0.017769</td>\n",
       "      <td>-0.037843</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.222594e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>7.290999e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.028378</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>-0.002752</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>4.805734e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.033268</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>-0.030962</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6.126303e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>8.837530e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>931</td>\n",
       "      <td>0.029441</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.020770</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>-0.004075</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>-0.014956</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.440095e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>932</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.020918</td>\n",
       "      <td>0.053804</td>\n",
       "      <td>-0.004624</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>-0.015439</td>\n",
       "      <td>0.017447</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.427082e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>933</td>\n",
       "      <td>0.032744</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.029211</td>\n",
       "      <td>0.034857</td>\n",
       "      <td>-0.029334</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>-0.031478</td>\n",
       "      <td>-0.025832</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>3.552867e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>934</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.070357</td>\n",
       "      <td>-0.027424</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>-0.067796</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>4.851210e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>-0.038575</td>\n",
       "      <td>-0.027188</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>1.055452e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>936 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     net_acc_mean  net_acc_std  net_acc_min  net_acc_max  ACC_x_mean  \\\n",
       "0        0.025961     0.013811     0.000000     0.087383    0.023431   \n",
       "1        0.027640     0.010597     0.002752     0.054356    0.027640   \n",
       "2        0.028389     0.006937     0.000000     0.066053    0.028378   \n",
       "3        0.033268     0.007670     0.000000     0.074998    0.032960   \n",
       "4        0.037021     0.001284     0.027522     0.043347    0.037021   \n",
       "..            ...          ...          ...          ...         ...   \n",
       "931      0.029441     0.002093     0.020770     0.054100   -0.004075   \n",
       "932      0.029484     0.002074     0.020918     0.053804   -0.004624   \n",
       "933      0.032744     0.000516     0.029211     0.034857   -0.029334   \n",
       "934      0.030006     0.007051     0.002966     0.070357   -0.027424   \n",
       "935      0.031250     0.001534     0.027188     0.038575   -0.031250   \n",
       "\n",
       "     ACC_x_std  ACC_x_min  ACC_x_max  ACC_y_mean     ACC_y_std  ...  label  \\\n",
       "0     0.017769  -0.037843   0.087383    0.000016  1.222594e-05  ...      0   \n",
       "1     0.010597   0.002752   0.054356    0.000019  7.290999e-06  ...      0   \n",
       "2     0.006985  -0.002752   0.066053    0.000020  4.805734e-06  ...      0   \n",
       "3     0.008904  -0.030962   0.074998    0.000023  6.126303e-06  ...      0   \n",
       "4     0.001284   0.027522   0.043347    0.000025  8.837530e-07  ...      0   \n",
       "..         ...        ...        ...         ...           ...  ...    ...   \n",
       "931   0.002093  -0.014956   0.018375   -0.000003  1.440095e-06  ...      1   \n",
       "932   0.002074  -0.015439   0.017447   -0.000003  1.427082e-06  ...      1   \n",
       "933   0.000516  -0.031478  -0.025832   -0.000020  3.552867e-07  ...      2   \n",
       "934   0.007051  -0.067796  -0.000404   -0.000019  4.851210e-06  ...      2   \n",
       "935   0.001534  -0.038575  -0.027188   -0.000022  1.055452e-06  ...      2   \n",
       "\n",
       "     age  height  weight  gender_ female  coffee_today_YES  sport_today_YES  \\\n",
       "0     27     175      80               0                 0                0   \n",
       "1     27     175      80               0                 0                0   \n",
       "2     27     175      80               0                 0                0   \n",
       "3     27     175      80               0                 0                0   \n",
       "4     27     175      80               0                 0                0   \n",
       "..   ...     ...     ...             ...               ...              ...   \n",
       "931   29     165      55               1                 0                0   \n",
       "932   29     165      55               1                 0                0   \n",
       "933   29     165      55               1                 0                0   \n",
       "934   29     165      55               1                 0                0   \n",
       "935   29     165      55               1                 0                0   \n",
       "\n",
       "     smoker_YES  feel_ill_today_YES  bmi  \n",
       "0             0                   0    1  \n",
       "1             0                   0    1  \n",
       "2             0                   0    1  \n",
       "3             0                   0    1  \n",
       "4             0                   0    1  \n",
       "..          ...                 ...  ...  \n",
       "931           0                   0    0  \n",
       "932           0                   0    0  \n",
       "933           0                   0    0  \n",
       "934           0                   0    0  \n",
       "935           0                   0    0  \n",
       "\n",
       "[936 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=df.columns.tolist()\n",
    "features\n",
    "\n",
    "removed = ['label']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "features_with_sub=[]\n",
    "features_with_sub[:]=features\n",
    "removed = ['subject']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "feature=features\n",
    "print(len(feature))\n",
    "len(features_with_sub)\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X, y= sm.fit_sample(df[features_with_sub], df['label'])\n",
    "df_new=pd.concat([pd.DataFrame(X,columns=features_with_sub),pd.DataFrame(y,columns=['label'])],axis=1)\n",
    "df_new\n",
    "\n",
    "for i in range (len(list(df_new['subject']))):\n",
    "    df_new['subject'][i] = min([2,3,4,5,6,7,8,9,10,11,13,14,15,16,17], key=lambda x:abs(x-df_new['subject'][i]))\n",
    "df_new['subject']=df_new['subject'].astype(int)\n",
    "\n",
    "p_d=pd.read_csv('personal_detail.csv',index_col=0)\n",
    "\n",
    "df_new_1=df_new.merge(p_d,on='subject')\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_fea=['EDA_tonic_mean',\n",
    " 'EDA_tonic_max',\n",
    " 'EDA_tonic_min',\n",
    " 'EDA_phasic_mean',\n",
    " 'EDA_smna_mean',\n",
    " 'EDA_phasic_min',\n",
    " 'EMG_std',\n",
    " 'c_ACC_y_min',\n",
    " 'sport_today_YES',\n",
    " 'ECG_std',\n",
    " 'c_ACC_x_std',\n",
    " 'c_ACC_y_std']\n",
    "\n",
    "len(sel_fea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df_new_1[df_new_1['subject']<=9]\n",
    "test=df_new_1[df_new_1['subject']>9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84       147\n",
      "           1       0.92      0.89      0.91       161\n",
      "           2       0.81      0.92      0.86       146\n",
      "\n",
      "    accuracy                           0.87       454\n",
      "   macro avg       0.87      0.87      0.87       454\n",
      "weighted avg       0.87      0.87      0.87       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=50,n_jobs=10,random_state=39)\n",
    "et.fit(train[sel_fea],train['label'])\n",
    "y_pred=et.predict(test[sel_fea])\n",
    "\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sport_today_YES', 2.396418275963685],\n",
       " ['c_ACC_y_std', 3.253514957385321],\n",
       " ['c_ACC_x_std', 3.2674245328856455],\n",
       " ['EDA_phasic_min', 3.270767056076939],\n",
       " ['EDA_smna_mean', 4.987500254554531],\n",
       " ['EDA_phasic_mean', 5.2645178966884565],\n",
       " ['ECG_std', 5.65609330837797],\n",
       " ['EMG_std', 8.210370175453424],\n",
       " ['c_ACC_y_min', 8.760812619931722],\n",
       " ['EDA_tonic_min', 12.586199296883818],\n",
       " ['EDA_tonic_mean', 20.44767629919284],\n",
       " ['EDA_tonic_max', 21.89870532660564]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=[]\n",
    "for i in range(len(sel_fea)):\n",
    "     d.append([sel_fea[i],list(et.feature_importances_)[i]*100])\n",
    "d.sort(key=lambda x: x[1])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current size: [15.0, 10.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 360x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = []\n",
    "values = []\n",
    "for i in d:\n",
    "    names.append(i[0])\n",
    "    values.append(i[1])\n",
    "plt.bar(names, values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.figure(figsize=(5,15))\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "print (\"Current size:\", fig_size)\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 10\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92        21\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       0.91      1.00      0.95        30\n",
      "\n",
      "    accuracy                           0.96        79\n",
      "   macro avg       0.97      0.95      0.96        79\n",
      "weighted avg       0.97      0.96      0.96        79\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.43      0.56        21\n",
      "           1       0.83      0.80      0.82        25\n",
      "           2       0.69      1.00      0.81        24\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.78      0.74      0.73        70\n",
      "weighted avg       0.78      0.76      0.74        70\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74        21\n",
      "           1       1.00      1.00      1.00        30\n",
      "           2       0.86      0.76      0.81        33\n",
      "\n",
      "    accuracy                           0.86        84\n",
      "   macro avg       0.85      0.86      0.85        84\n",
      "weighted avg       0.87      0.86      0.86        84\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88        21\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.91        56\n",
      "   macro avg       0.91      0.91      0.91        56\n",
      "weighted avg       0.91      0.91      0.91        56\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        21\n",
      "           1       1.00      1.00      1.00        19\n",
      "           2       1.00      0.90      0.95        21\n",
      "\n",
      "    accuracy                           0.97        61\n",
      "   macro avg       0.97      0.97      0.97        61\n",
      "weighted avg       0.97      0.97      0.97        61\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        21\n",
      "           1       1.00      0.92      0.96        26\n",
      "           2       0.85      0.92      0.88        12\n",
      "\n",
      "    accuracy                           0.95        59\n",
      "   macro avg       0.93      0.95      0.94        59\n",
      "weighted avg       0.95      0.95      0.95        59\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.62      0.74        21\n",
      "           1       0.38      0.33      0.36        15\n",
      "           2       0.50      1.00      0.67         9\n",
      "\n",
      "    accuracy                           0.60        45\n",
      "   macro avg       0.60      0.65      0.59        45\n",
      "weighted avg       0.66      0.60      0.60        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sub=[10,11,13,14,15,16,17]\n",
    "for i in test_sub:\n",
    "    print(i)\n",
    "    train=df_new_1[df_new_1['subject']<=9]\n",
    "    test=df_new_1[df_new_1['subject']==i]\n",
    "\n",
    "    et.fit(train[sel_fea],train['label'])\n",
    "    y_pred=et.predict(test[sel_fea])\n",
    "    print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67        21\n",
      "           1       0.27      0.20      0.23        15\n",
      "           2       0.56      1.00      0.72         9\n",
      "\n",
      "    accuracy                           0.56        45\n",
      "   macro avg       0.52      0.61      0.54        45\n",
      "weighted avg       0.54      0.56      0.53        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=50,n_jobs=10,random_state=0)\n",
    "clf.fit(train[sel_fea],train['label'])\n",
    "y_pred=clf.predict(test[sel_fea])\n",
    "print(classification_report(test['label'],y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75        21\n",
      "           1       1.00      0.89      0.94        28\n",
      "           2       0.83      0.97      0.89        30\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.87      0.86      0.86        79\n",
      "weighted avg       0.88      0.87      0.87        79\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.43      0.46        21\n",
      "           1       0.80      0.64      0.71        25\n",
      "           2       0.66      0.88      0.75        24\n",
      "\n",
      "    accuracy                           0.66        70\n",
      "   macro avg       0.65      0.65      0.64        70\n",
      "weighted avg       0.66      0.66      0.65        70\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.90      0.67        21\n",
      "           1       1.00      0.97      0.98        30\n",
      "           2       0.89      0.52      0.65        33\n",
      "\n",
      "    accuracy                           0.77        84\n",
      "   macro avg       0.81      0.80      0.77        84\n",
      "weighted avg       0.84      0.77      0.77        84\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.71      0.81        21\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.68      1.00      0.81        17\n",
      "\n",
      "    accuracy                           0.84        56\n",
      "   macro avg       0.87      0.85      0.84        56\n",
      "weighted avg       0.88      0.84      0.84        56\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        21\n",
      "           1       1.00      1.00      1.00        19\n",
      "           2       1.00      0.81      0.89        21\n",
      "\n",
      "    accuracy                           0.93        61\n",
      "   macro avg       0.95      0.94      0.94        61\n",
      "weighted avg       0.94      0.93      0.93        61\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87        21\n",
      "           1       1.00      0.88      0.94        26\n",
      "           2       0.67      1.00      0.80        12\n",
      "\n",
      "    accuracy                           0.88        59\n",
      "   macro avg       0.87      0.90      0.87        59\n",
      "weighted avg       0.91      0.88      0.89        59\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67        21\n",
      "           1       0.27      0.20      0.23        15\n",
      "           2       0.56      1.00      0.72         9\n",
      "\n",
      "    accuracy                           0.56        45\n",
      "   macro avg       0.52      0.61      0.54        45\n",
      "weighted avg       0.54      0.56      0.53        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sub=[10,11,13,14,15,16,17]\n",
    "for i in test_sub:\n",
    "    print(i)\n",
    "    train=df_new_1[df_new_1['subject']<=9]\n",
    "    test=df_new_1[df_new_1['subject']==i]\n",
    "\n",
    "    clf.fit(train[sel_fea],train['label'])\n",
    "    y_pred=clf.predict(test[sel_fea])\n",
    "    print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.43      0.43        21\n",
      "           1       0.25      0.27      0.26        15\n",
      "           2       0.88      0.78      0.82         9\n",
      "\n",
      "    accuracy                           0.44        45\n",
      "   macro avg       0.52      0.49      0.50        45\n",
      "weighted avg       0.46      0.44      0.45        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf=GaussianNB()\n",
    "clf.fit(train[sel_fea],train['label'])\n",
    "y_pred=clf.predict(test[sel_fea])\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.24      0.33        21\n",
      "           1       1.00      0.86      0.92        28\n",
      "           2       0.65      1.00      0.79        30\n",
      "\n",
      "    accuracy                           0.75        79\n",
      "   macro avg       0.74      0.70      0.68        79\n",
      "weighted avg       0.75      0.75      0.72        79\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.43      0.41        21\n",
      "           1       0.73      0.64      0.68        25\n",
      "           2       0.68      0.71      0.69        24\n",
      "\n",
      "    accuracy                           0.60        70\n",
      "   macro avg       0.60      0.59      0.59        70\n",
      "weighted avg       0.61      0.60      0.60        70\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.95      0.66        21\n",
      "           1       0.89      0.83      0.86        30\n",
      "           2       0.94      0.45      0.61        33\n",
      "\n",
      "    accuracy                           0.71        84\n",
      "   macro avg       0.78      0.75      0.71        84\n",
      "weighted avg       0.81      0.71      0.71        84\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.52      0.67        21\n",
      "           1       0.47      1.00      0.64        18\n",
      "           2       1.00      0.35      0.52        17\n",
      "\n",
      "    accuracy                           0.62        56\n",
      "   macro avg       0.80      0.63      0.61        56\n",
      "weighted avg       0.80      0.62      0.62        56\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85        21\n",
      "           1       0.95      1.00      0.97        19\n",
      "           2       0.93      0.67      0.78        21\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.88      0.87      0.87        61\n",
      "weighted avg       0.88      0.87      0.86        61\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.33      0.44        21\n",
      "           1       1.00      0.88      0.94        26\n",
      "           2       0.44      0.92      0.59        12\n",
      "\n",
      "    accuracy                           0.69        59\n",
      "   macro avg       0.69      0.71      0.66        59\n",
      "weighted avg       0.76      0.69      0.69        59\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.43      0.43        21\n",
      "           1       0.25      0.27      0.26        15\n",
      "           2       0.88      0.78      0.82         9\n",
      "\n",
      "    accuracy                           0.44        45\n",
      "   macro avg       0.52      0.49      0.50        45\n",
      "weighted avg       0.46      0.44      0.45        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sub=[10,11,13,14,15,16,17]\n",
    "for i in test_sub:\n",
    "    print(i)\n",
    "    train=df_new_1[df_new_1['subject']<=9]\n",
    "    test=df_new_1[df_new_1['subject']==i]\n",
    "\n",
    "    clf.fit(train[sel_fea],train['label'])\n",
    "    y_pred=clf.predict(test[sel_fea])\n",
    "    print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76        21\n",
      "           1       0.56      0.60      0.58        15\n",
      "           2       0.54      0.78      0.64         9\n",
      "\n",
      "    accuracy                           0.67        45\n",
      "   macro avg       0.66      0.68      0.66        45\n",
      "weighted avg       0.70      0.67      0.67        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=50)\n",
    "clf.fit(train[sel_fea],train['label'])\n",
    "y_pred=clf.predict(test[sel_fea])\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.79        21\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       0.82      0.93      0.87        30\n",
      "\n",
      "    accuracy                           0.90        79\n",
      "   macro avg       0.90      0.88      0.89        79\n",
      "weighted avg       0.90      0.90      0.90        79\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.48      0.57        21\n",
      "           1       0.85      0.92      0.88        25\n",
      "           2       0.72      0.88      0.79        24\n",
      "\n",
      "    accuracy                           0.77        70\n",
      "   macro avg       0.76      0.76      0.75        70\n",
      "weighted avg       0.77      0.77      0.76        70\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.90      0.76        21\n",
      "           1       1.00      1.00      1.00        30\n",
      "           2       0.92      0.70      0.79        33\n",
      "\n",
      "    accuracy                           0.86        84\n",
      "   macro avg       0.86      0.87      0.85        84\n",
      "weighted avg       0.88      0.86      0.86        84\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.19      0.32        21\n",
      "           1       0.84      0.89      0.86        18\n",
      "           2       0.42      0.82      0.56        17\n",
      "\n",
      "    accuracy                           0.61        56\n",
      "   macro avg       0.76      0.63      0.58        56\n",
      "weighted avg       0.77      0.61      0.57        56\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       0.95      1.00      0.97        19\n",
      "           2       1.00      0.81      0.89        21\n",
      "\n",
      "    accuracy                           0.93        61\n",
      "   macro avg       0.94      0.94      0.93        61\n",
      "weighted avg       0.94      0.93      0.93        61\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        21\n",
      "           1       0.96      0.92      0.94        26\n",
      "           2       0.77      0.83      0.80        12\n",
      "\n",
      "    accuracy                           0.92        59\n",
      "   macro avg       0.89      0.90      0.90        59\n",
      "weighted avg       0.92      0.92      0.92        59\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76        21\n",
      "           1       0.53      0.53      0.53        15\n",
      "           2       0.50      0.78      0.61         9\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.64      0.66      0.63        45\n",
      "weighted avg       0.69      0.64      0.65        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sub=[10,11,13,14,15,16,17]\n",
    "for i in test_sub:\n",
    "    print(i)\n",
    "    train=df_new_1[df_new_1['subject']<=9]\n",
    "    test=df_new_1[df_new_1['subject']==i]\n",
    "\n",
    "    clf.fit(train[sel_fea],train['label'])\n",
    "    y_pred=clf.predict(test[sel_fea])\n",
    "    print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.14      0.15        21\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.58      0.78      0.67         9\n",
      "\n",
      "    accuracy                           0.22        45\n",
      "   macro avg       0.25      0.31      0.27        45\n",
      "weighted avg       0.19      0.22      0.21        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train[sel_fea],train['label'])\n",
    "y_pred=clf.predict(test[sel_fea])\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.38      0.44        21\n",
      "           1       1.00      0.86      0.92        28\n",
      "           2       0.68      0.90      0.77        30\n",
      "\n",
      "    accuracy                           0.75        79\n",
      "   macro avg       0.74      0.71      0.71        79\n",
      "weighted avg       0.75      0.75      0.74        79\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.48      0.39        21\n",
      "           1       0.71      0.48      0.57        25\n",
      "           2       0.74      0.71      0.72        24\n",
      "\n",
      "    accuracy                           0.56        70\n",
      "   macro avg       0.59      0.55      0.56        70\n",
      "weighted avg       0.61      0.56      0.57        70\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.76      0.55        21\n",
      "           1       0.94      0.97      0.95        30\n",
      "           2       0.81      0.39      0.53        33\n",
      "\n",
      "    accuracy                           0.69        84\n",
      "   macro avg       0.73      0.71      0.68        84\n",
      "weighted avg       0.76      0.69      0.69        84\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        21\n",
      "           1       1.00      0.78      0.88        18\n",
      "           2       1.00      0.88      0.94        17\n",
      "\n",
      "    accuracy                           0.89        56\n",
      "   macro avg       0.93      0.89      0.90        56\n",
      "weighted avg       0.92      0.89      0.89        56\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80        21\n",
      "           1       1.00      1.00      1.00        19\n",
      "           2       0.78      0.86      0.82        21\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.52      0.56        21\n",
      "           1       1.00      0.85      0.92        26\n",
      "           2       0.47      0.75      0.58        12\n",
      "\n",
      "    accuracy                           0.71        59\n",
      "   macro avg       0.69      0.71      0.69        59\n",
      "weighted avg       0.75      0.71      0.72        59\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.14      0.15        21\n",
      "           1       0.00      0.00      0.00        15\n",
      "           2       0.58      0.78      0.67         9\n",
      "\n",
      "    accuracy                           0.22        45\n",
      "   macro avg       0.25      0.31      0.27        45\n",
      "weighted avg       0.19      0.22      0.21        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test_sub=[10,11,13,14,15,16,17]\n",
    "for i in test_sub:\n",
    "    print(i)\n",
    "    train=df_new_1[df_new_1['subject']<=9]\n",
    "    test=df_new_1[df_new_1['subject']==i]\n",
    "\n",
    "    clf.fit(train[sel_fea],train['label'])\n",
    "    y_pred=clf.predict(test[sel_fea])\n",
    "    print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76        21\n",
      "           1       0.46      0.40      0.43        15\n",
      "           2       0.56      1.00      0.72         9\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.63      0.69      0.64        45\n",
      "weighted avg       0.67      0.64      0.64        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier(n_estimators = 10)\n",
    "clf.fit(train[sel_fea],train['label'])\n",
    "y_pred=clf.predict(test[sel_fea])\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.62      0.72        21\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       0.78      0.93      0.85        30\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.88      0.85      0.86        79\n",
      "weighted avg       0.88      0.87      0.87        79\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.29      0.39        21\n",
      "           1       0.78      0.84      0.81        25\n",
      "           2       0.67      0.92      0.77        24\n",
      "\n",
      "    accuracy                           0.70        70\n",
      "   macro avg       0.68      0.68      0.66        70\n",
      "weighted avg       0.69      0.70      0.67        70\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.76      0.63        21\n",
      "           1       0.94      1.00      0.97        30\n",
      "           2       0.86      0.58      0.69        33\n",
      "\n",
      "    accuracy                           0.77        84\n",
      "   macro avg       0.78      0.78      0.76        84\n",
      "weighted avg       0.81      0.77      0.77        84\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.19      0.32        21\n",
      "           1       1.00      0.89      0.94        18\n",
      "           2       0.47      1.00      0.64        17\n",
      "\n",
      "    accuracy                           0.66        56\n",
      "   macro avg       0.82      0.69      0.63        56\n",
      "weighted avg       0.84      0.66      0.62        56\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       1.00      1.00      1.00        19\n",
      "           2       1.00      0.86      0.92        21\n",
      "\n",
      "    accuracy                           0.95        61\n",
      "   macro avg       0.96      0.95      0.95        61\n",
      "weighted avg       0.96      0.95      0.95        61\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.62      0.74        21\n",
      "           1       1.00      0.88      0.94        26\n",
      "           2       0.55      1.00      0.71        12\n",
      "\n",
      "    accuracy                           0.81        59\n",
      "   macro avg       0.82      0.83      0.80        59\n",
      "weighted avg       0.88      0.81      0.82        59\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76        21\n",
      "           1       0.46      0.40      0.43        15\n",
      "           2       0.56      1.00      0.72         9\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.63      0.69      0.64        45\n",
      "weighted avg       0.67      0.64      0.64        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sub=[10,11,13,14,15,16,17]\n",
    "for i in test_sub:\n",
    "    print(i)\n",
    "    train=df_new_1[df_new_1['subject']<=9]\n",
    "    test=df_new_1[df_new_1['subject']==i]\n",
    "\n",
    "    clf.fit(train[sel_fea],train['label'])\n",
    "    y_pred=clf.predict(test[sel_fea])\n",
    "    print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76        21\n",
      "           1       0.46      0.40      0.43        15\n",
      "           2       0.56      1.00      0.72         9\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.63      0.69      0.64        45\n",
      "weighted avg       0.67      0.64      0.64        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = xgb.XGBClassifier(n_estimators = 10)\n",
    "clf.fit(train[sel_fea],train['label'])\n",
    "y_pred=clf.predict(test[sel_fea])\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.62      0.72        21\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       0.78      0.93      0.85        30\n",
      "\n",
      "    accuracy                           0.87        79\n",
      "   macro avg       0.88      0.85      0.86        79\n",
      "weighted avg       0.88      0.87      0.87        79\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.29      0.39        21\n",
      "           1       0.78      0.84      0.81        25\n",
      "           2       0.67      0.92      0.77        24\n",
      "\n",
      "    accuracy                           0.70        70\n",
      "   macro avg       0.68      0.68      0.66        70\n",
      "weighted avg       0.69      0.70      0.67        70\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.76      0.63        21\n",
      "           1       0.94      1.00      0.97        30\n",
      "           2       0.86      0.58      0.69        33\n",
      "\n",
      "    accuracy                           0.77        84\n",
      "   macro avg       0.78      0.78      0.76        84\n",
      "weighted avg       0.81      0.77      0.77        84\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.19      0.32        21\n",
      "           1       1.00      0.89      0.94        18\n",
      "           2       0.47      1.00      0.64        17\n",
      "\n",
      "    accuracy                           0.66        56\n",
      "   macro avg       0.82      0.69      0.63        56\n",
      "weighted avg       0.84      0.66      0.62        56\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       1.00      1.00      1.00        19\n",
      "           2       1.00      0.86      0.92        21\n",
      "\n",
      "    accuracy                           0.95        61\n",
      "   macro avg       0.96      0.95      0.95        61\n",
      "weighted avg       0.96      0.95      0.95        61\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.62      0.74        21\n",
      "           1       1.00      0.88      0.94        26\n",
      "           2       0.55      1.00      0.71        12\n",
      "\n",
      "    accuracy                           0.81        59\n",
      "   macro avg       0.82      0.83      0.80        59\n",
      "weighted avg       0.88      0.81      0.82        59\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76        21\n",
      "           1       0.46      0.40      0.43        15\n",
      "           2       0.56      1.00      0.72         9\n",
      "\n",
      "    accuracy                           0.64        45\n",
      "   macro avg       0.63      0.69      0.64        45\n",
      "weighted avg       0.67      0.64      0.64        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sub=[10,11,13,14,15,16,17]\n",
    "for i in test_sub:\n",
    "    print(i)\n",
    "    train=df_new_1[df_new_1['subject']<=9]\n",
    "    test=df_new_1[df_new_1['subject']==i]\n",
    "\n",
    "    clf.fit(train[sel_fea],train['label'])\n",
    "    y_pred=clf.predict(test[sel_fea])\n",
    "    print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.14      0.17        21\n",
      "           1       0.12      0.13      0.12        15\n",
      "           2       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.31        45\n",
      "   macro avg       0.32      0.43      0.36        45\n",
      "weighted avg       0.27      0.31      0.28        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear') \n",
    "clf.fit(train[sel_fea],train['label'])\n",
    "y_pred=clf.predict(test[sel_fea])\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.10      0.16        21\n",
      "           1       1.00      0.96      0.98        28\n",
      "           2       0.60      0.97      0.74        30\n",
      "\n",
      "    accuracy                           0.73        79\n",
      "   macro avg       0.70      0.68      0.63        79\n",
      "weighted avg       0.72      0.73      0.67        79\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.38      0.36        21\n",
      "           1       0.72      0.52      0.60        25\n",
      "           2       0.71      0.83      0.77        24\n",
      "\n",
      "    accuracy                           0.59        70\n",
      "   macro avg       0.59      0.58      0.58        70\n",
      "weighted avg       0.60      0.59      0.59        70\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.67      0.61        21\n",
      "           1       1.00      1.00      1.00        30\n",
      "           2       0.76      0.67      0.71        33\n",
      "\n",
      "    accuracy                           0.79        84\n",
      "   macro avg       0.77      0.78      0.77        84\n",
      "weighted avg       0.80      0.79      0.79        84\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       1.00      0.89      0.94        18\n",
      "           2       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.95        56\n",
      "   macro avg       0.96      0.94      0.95        56\n",
      "weighted avg       0.95      0.95      0.95        56\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83        21\n",
      "           1       1.00      1.00      1.00        19\n",
      "           2       0.78      1.00      0.88        21\n",
      "\n",
      "    accuracy                           0.90        61\n",
      "   macro avg       0.93      0.90      0.90        61\n",
      "weighted avg       0.92      0.90      0.90        61\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.33      0.45        21\n",
      "           1       1.00      0.88      0.94        26\n",
      "           2       0.46      1.00      0.63        12\n",
      "\n",
      "    accuracy                           0.71        59\n",
      "   macro avg       0.72      0.74      0.67        59\n",
      "weighted avg       0.78      0.71      0.70        59\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.14      0.17        21\n",
      "           1       0.12      0.13      0.12        15\n",
      "           2       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.31        45\n",
      "   macro avg       0.32      0.43      0.36        45\n",
      "weighted avg       0.27      0.31      0.28        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sub=[10,11,13,14,15,16,17]\n",
    "for i in test_sub:\n",
    "    print(i)\n",
    "    train=df_new_1[df_new_1['subject']<=9]\n",
    "    test=df_new_1[df_new_1['subject']==i]\n",
    "\n",
    "    clf.fit(train[sel_fea],train['label'])\n",
    "    y_pred=clf.predict(test[sel_fea])\n",
    "    print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.10      0.07      0.08        15\n",
      "           2       0.27      1.00      0.43         9\n",
      "\n",
      "    accuracy                           0.22        45\n",
      "   macro avg       0.12      0.36      0.17        45\n",
      "weighted avg       0.09      0.22      0.11        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='poly') \n",
    "clf.fit(train[sel_fea],train['label'])\n",
    "y_pred=clf.predict(test[sel_fea])\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       1.00      0.61      0.76        28\n",
      "           2       0.49      1.00      0.66        30\n",
      "\n",
      "    accuracy                           0.59        79\n",
      "   macro avg       0.50      0.54      0.47        79\n",
      "weighted avg       0.54      0.59      0.52        79\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.22        21\n",
      "           1       0.73      0.32      0.44        25\n",
      "           2       0.45      1.00      0.62        24\n",
      "\n",
      "    accuracy                           0.50        70\n",
      "   macro avg       0.56      0.49      0.43        70\n",
      "weighted avg       0.56      0.50      0.44        70\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       1.00      0.63      0.78        30\n",
      "           2       0.52      1.00      0.69        33\n",
      "\n",
      "    accuracy                           0.62        84\n",
      "   macro avg       0.51      0.54      0.49        84\n",
      "weighted avg       0.56      0.62      0.55        84\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90        21\n",
      "           1       1.00      0.22      0.36        18\n",
      "           2       0.52      1.00      0.68        17\n",
      "\n",
      "    accuracy                           0.70        56\n",
      "   macro avg       0.82      0.69      0.65        56\n",
      "weighted avg       0.83      0.70      0.66        56\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       1.00      0.79      0.88        19\n",
      "           2       0.47      1.00      0.64        21\n",
      "\n",
      "    accuracy                           0.59        61\n",
      "   macro avg       0.49      0.60      0.51        61\n",
      "weighted avg       0.47      0.59      0.49        61\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       1.00      0.85      0.92        26\n",
      "           2       0.33      1.00      0.50        12\n",
      "\n",
      "    accuracy                           0.58        59\n",
      "   macro avg       0.44      0.62      0.47        59\n",
      "weighted avg       0.51      0.58      0.51        59\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.10      0.07      0.08        15\n",
      "           2       0.27      1.00      0.43         9\n",
      "\n",
      "    accuracy                           0.22        45\n",
      "   macro avg       0.12      0.36      0.17        45\n",
      "weighted avg       0.09      0.22      0.11        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test_sub=[10,11,13,14,15,16,17]\n",
    "for i in test_sub:\n",
    "    print(i)\n",
    "    train=df_new_1[df_new_1['subject']<=9]\n",
    "    test=df_new_1[df_new_1['subject']==i]\n",
    "\n",
    "    clf.fit(train[sel_fea],train['label'])\n",
    "    y_pred=clf.predict(test[sel_fea])\n",
    "    print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.05      0.07        21\n",
      "           1       0.21      0.27      0.24        15\n",
      "           2       0.47      1.00      0.64         9\n",
      "\n",
      "    accuracy                           0.31        45\n",
      "   macro avg       0.28      0.44      0.32        45\n",
      "weighted avg       0.23      0.31      0.24        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='rbf') \n",
    "clf.fit(train[sel_fea],train['label'])\n",
    "y_pred=clf.predict(test[sel_fea])\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       1.00      0.93      0.96        28\n",
      "           2       0.57      1.00      0.72        30\n",
      "\n",
      "    accuracy                           0.71        79\n",
      "   macro avg       0.52      0.64      0.56        79\n",
      "weighted avg       0.57      0.71      0.62        79\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.29      0.34        21\n",
      "           1       0.71      0.48      0.57        25\n",
      "           2       0.62      1.00      0.76        24\n",
      "\n",
      "    accuracy                           0.60        70\n",
      "   macro avg       0.58      0.59      0.56        70\n",
      "weighted avg       0.59      0.60      0.57        70\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.62      0.74        21\n",
      "           1       0.97      1.00      0.98        30\n",
      "           2       0.82      0.97      0.89        33\n",
      "\n",
      "    accuracy                           0.89        84\n",
      "   macro avg       0.91      0.86      0.87        84\n",
      "weighted avg       0.90      0.89      0.89        84\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.67      0.78        21\n",
      "           1       0.79      0.83      0.81        18\n",
      "           2       0.77      1.00      0.87        17\n",
      "\n",
      "    accuracy                           0.82        56\n",
      "   macro avg       0.83      0.83      0.82        56\n",
      "weighted avg       0.84      0.82      0.82        56\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      1.00      1.00        19\n",
      "           2       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00        61\n",
      "   macro avg       1.00      1.00      1.00        61\n",
      "weighted avg       1.00      1.00      1.00        61\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       1.00      0.92      0.96        26\n",
      "           2       0.36      1.00      0.53        12\n",
      "\n",
      "    accuracy                           0.61        59\n",
      "   macro avg       0.45      0.64      0.50        59\n",
      "weighted avg       0.51      0.61      0.53        59\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.05      0.07        21\n",
      "           1       0.21      0.27      0.24        15\n",
      "           2       0.47      1.00      0.64         9\n",
      "\n",
      "    accuracy                           0.31        45\n",
      "   macro avg       0.28      0.44      0.32        45\n",
      "weighted avg       0.23      0.31      0.24        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test_sub=[10,11,13,14,15,16,17]\n",
    "for i in test_sub:\n",
    "    print(i)\n",
    "    train=df_new_1[df_new_1['subject']<=9]\n",
    "    test=df_new_1[df_new_1['subject']==i]\n",
    "\n",
    "    clf.fit(train[sel_fea],train['label'])\n",
    "    y_pred=clf.predict(test[sel_fea])\n",
    "    print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.89        21\n",
      "           1       1.00      0.93      0.97        15\n",
      "           2       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.89        45\n",
      "   macro avg       0.88      0.91      0.88        45\n",
      "weighted avg       0.93      0.89      0.90        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=50,learning_rate=1)\n",
    "clf.fit(train[sel_fea],train['label'])\n",
    "y_pred=clf.predict(test[sel_fea])\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.80      0.14      0.24        28\n",
      "           2       0.58      0.97      0.72        30\n",
      "\n",
      "    accuracy                           0.42        79\n",
      "   macro avg       0.46      0.37      0.32        79\n",
      "weighted avg       0.50      0.42      0.36        79\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.29      0.34        21\n",
      "           1       0.94      0.68      0.79        25\n",
      "           2       0.61      0.96      0.74        24\n",
      "\n",
      "    accuracy                           0.66        70\n",
      "   macro avg       0.66      0.64      0.63        70\n",
      "weighted avg       0.67      0.66      0.64        70\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.14      0.13        21\n",
      "           1       0.73      0.27      0.39        30\n",
      "           2       0.62      0.91      0.74        33\n",
      "\n",
      "    accuracy                           0.49        84\n",
      "   macro avg       0.49      0.44      0.42        84\n",
      "weighted avg       0.54      0.49      0.46        84\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.94      0.83      0.88        18\n",
      "           2       0.43      0.94      0.59        17\n",
      "\n",
      "    accuracy                           0.55        56\n",
      "   macro avg       0.46      0.59      0.49        56\n",
      "weighted avg       0.43      0.55      0.46        56\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       1.00      0.32      0.48        19\n",
      "           2       0.50      1.00      0.67        21\n",
      "\n",
      "    accuracy                           0.44        61\n",
      "   macro avg       0.50      0.44      0.38        61\n",
      "weighted avg       0.48      0.44      0.38        61\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.71      0.96      0.82        26\n",
      "           2       0.17      0.33      0.22        12\n",
      "\n",
      "    accuracy                           0.49        59\n",
      "   macro avg       0.29      0.43      0.35        59\n",
      "weighted avg       0.35      0.49      0.41        59\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.89        21\n",
      "           1       1.00      0.93      0.97        15\n",
      "           2       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.89        45\n",
      "   macro avg       0.88      0.91      0.88        45\n",
      "weighted avg       0.93      0.89      0.90        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "test_sub=[10,11,13,14,15,16,17]\n",
    "for i in test_sub:\n",
    "    print(i)\n",
    "    train=df_new_1[df_new_1['subject']<=9]\n",
    "    test=df_new_1[df_new_1['subject']==i]\n",
    "\n",
    "    clf.fit(train[sel_fea],train['label'])\n",
    "    y_pred=clf.predict(test[sel_fea])\n",
    "    print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
