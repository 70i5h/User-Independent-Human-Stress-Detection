{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from itertools import combinations \n",
    "from sklearn import model_selection\n",
    "import copy \n",
    "from statistics import mean,mode \n",
    "from itertools import combinations  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = [2,3,4,5,6,7,8,9,10,11,13,14,15,16,17]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('60s_window_wrist_chest.csv',index_col=0)\n",
    "df=df[df['label']<2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_d=pd.read_csv('personal_detail.csv',index_col=0)\n",
    "\n",
    "df=df.merge(p_d,on='subject')\n",
    "\n",
    "features=df.columns.tolist()\n",
    "features\n",
    "\n",
    "removed = ['label']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "features_with_sub=[]\n",
    "features_with_sub[:]=features\n",
    "removed = ['subject']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "feature=features\n",
    "print(len(feature))\n",
    "len(features_with_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9577039274924471\n",
      "0.7393767705382436\n",
      "0.21832715695420357\n",
      "[3, 5, 10, 11, 14, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "df_=pd.read_csv('2_class_combination_7-8.csv')\n",
    "max_=df_['acc'].max()\n",
    "min_=df_['acc'].min()\n",
    "\n",
    "print(max_)\n",
    "print(min_)\n",
    "print(max_-min_)\n",
    "sub=(eval(df_['subjects_in_train'][df_[df_['acc']==max_].index[0]]))\n",
    "print(sub)\n",
    "train= df.loc[df.subject.isin(eval(df_['subjects_in_train'][df_[df_['acc']==max_].index[0]]))]\n",
    "test= df.loc[df.subject.isin(eval(df_['subjects_in_test'][df_[df_['acc']==max_].index[0]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(7):\n",
    "    s=sub[i]\n",
    "    globals()['sub_%s' % i]=df.loc[df.subject.isin([s])]\n",
    "    #eval(\"'sub'+str(i)= df.loc[df.subject.isin([s])]\")\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X, y= sm.fit_sample(globals()['sub_%s' % i][features_with_sub], globals()['sub_%s' % i]['label'])\n",
    "    globals()['sub_%s' % i]=pd.concat([pd.DataFrame(X,columns=features_with_sub),pd.DataFrame(y,columns=['label'])],axis=1)\n",
    "df_new=pd.concat([sub_1,sub_2,sub_3,sub_4,sub_5,sub_6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=pd.concat([sub_1,sub_2,sub_3,sub_4,sub_5,sub_6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_fea = ['EDA_tonic_mean','EDA_tonic_max','EDA_phasic_max','ECG_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer()\n",
    "scaled_data_train = scaler.fit_transform(df_new[sel_fea])\n",
    "scaled_data_test = scaler.transform(test[sel_fea])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 11 2_class\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       166\n",
      "           1       0.92      0.90      0.91        91\n",
      "\n",
      "    accuracy                           0.94       257\n",
      "   macro avg       0.93      0.93      0.93       257\n",
      "weighted avg       0.94      0.94      0.94       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=100,n_jobs=10)\n",
    "clf.fit(scaled_data_train,df_new['label'])\n",
    "y_pred=clf.predict(scaled_data_test)\n",
    "#print (classification_report(test['label'],y_pred))\n",
    "print(4,11,'2_class')\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "0.8383233532934131\n",
      "0.5641421947449768\n",
      "0.2741811585484363\n",
      "[4, 5, 7, 8, 9, 11, 17]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('60s_window_wrist_chest.csv',index_col=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "p_d=pd.read_csv('personal_detail.csv',index_col=0)\n",
    "\n",
    "df=df.merge(p_d,on='subject')\n",
    "\n",
    "features=df.columns.tolist()\n",
    "features\n",
    "\n",
    "removed = ['label']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "features_with_sub=[]\n",
    "features_with_sub[:]=features\n",
    "removed = ['subject']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "feature=features\n",
    "print(len(feature))\n",
    "len(features_with_sub)\n",
    "\n",
    "df_=pd.read_csv('4_class_combination_7-8.csv')\n",
    "max_=df_['acc'].max()\n",
    "min_=df_['acc'].min()\n",
    "\n",
    "print(max_)\n",
    "print(min_)\n",
    "print(max_-min_)\n",
    "sub=(eval(df_['subjects_in_train'][df_[df_['acc']==max_].index[0]]))\n",
    "print(sub)\n",
    "train= df.loc[df.subject.isin(eval(df_['subjects_in_train'][df_[df_['acc']==max_].index[0]]))]\n",
    "test= df.loc[df.subject.isin(eval(df_['subjects_in_test'][df_[df_['acc']==max_].index[0]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_fea = ['EDA_tonic_mean','EDA_smna_mean','EDA_tonic_min','EDA_phasic_mean','TEMP_std','BVP_peak_freq','smoker_YES','ACC_y_min','ACC_x_mean','weight','gender_ female','c_Temp_max','ACC_x_max','TEMP_mean',\n",
    "          'c_ACC_y_std','net_acc_max','Resp_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 8 3_class\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.93      0.81       166\n",
      "           1       0.91      0.89      0.90        94\n",
      "           2       0.50      0.06      0.11        48\n",
      "           3       0.80      0.77      0.78       111\n",
      "\n",
      "    accuracy                           0.78       419\n",
      "   macro avg       0.73      0.66      0.65       419\n",
      "weighted avg       0.76      0.78      0.74       419\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(7):\n",
    "    s=sub[i]\n",
    "    globals()['sub_%s' % i]=df.loc[df.subject.isin([s])]\n",
    "    #eval(\"'sub'+str(i)= df.loc[df.subject.isin([s])]\")\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X, y= sm.fit_sample(globals()['sub_%s' % i][features_with_sub], globals()['sub_%s' % i]['label'])\n",
    "    globals()['sub_%s' % i]=pd.concat([pd.DataFrame(X,columns=features_with_sub),pd.DataFrame(y,columns=['label'])],axis=1)\n",
    "df_new=pd.concat([sub_1,sub_2,sub_3,sub_4,sub_5,sub_6])\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaled_data_train = scaler.fit_transform(df_new[sel_fea])\n",
    "scaled_data_test = scaler.transform(test[sel_fea])\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=100,n_jobs=10)\n",
    "clf.fit(scaled_data_train,df_new['label'])\n",
    "y_pred=clf.predict(scaled_data_test)\n",
    "#print (classification_report(test['label'],y_pred))\n",
    "print(7,8,'3_class')\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_fea=['EDA_tonic_mean',\n",
    " 'EDA_tonic_max',\n",
    " 'EDA_tonic_min',\n",
    " 'EDA_phasic_mean',\n",
    " 'EDA_smna_mean',\n",
    " 'EDA_phasic_min',\n",
    " 'EMG_std',\n",
    " 'c_ACC_y_min',\n",
    " 'sport_today_YES',\n",
    " 'ECG_std',\n",
    " 'c_ACC_x_std',\n",
    " 'c_ACC_y_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "0.8551587301587301\n",
      "0.5975103734439834\n",
      "[2, 3, 8, 10, 11, 15, 16]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('60s_window_wrist_chest.csv',index_col=0)\n",
    "df=df[df['label']<3]\n",
    "\n",
    "\n",
    "\n",
    "p_d=pd.read_csv('personal_detail.csv',index_col=0)\n",
    "\n",
    "df=df.merge(p_d,on='subject')\n",
    "\n",
    "features=df.columns.tolist()\n",
    "features\n",
    "\n",
    "removed = ['label']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "features_with_sub=[]\n",
    "features_with_sub[:]=features\n",
    "removed = ['subject']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "feature=features\n",
    "print(len(feature))\n",
    "len(features_with_sub)\n",
    "\n",
    "df_=pd.read_csv('3_class_combination_7-8.csv')\n",
    "max_=df_['acc'].max()\n",
    "min_=df_['acc'].min()\n",
    "\n",
    "print(max_)\n",
    "print(min_)\n",
    "sub=(eval(df_['subjects_in_train'][df_[df_['acc']==max_].index[0]]))\n",
    "print(sub)\n",
    "train= df.loc[df.subject.isin(eval(df_['subjects_in_train'][df_[df_['acc']==max_].index[0]]))]\n",
    "test= df.loc[df.subject.isin(eval(df_['subjects_in_test'][df_[df_['acc']==max_].index[0]]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 8 3_class\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       167\n",
      "           1       0.70      0.86      0.77        92\n",
      "           2       0.73      0.33      0.46        48\n",
      "\n",
      "    accuracy                           0.76       307\n",
      "   macro avg       0.74      0.67      0.68       307\n",
      "weighted avg       0.76      0.76      0.74       307\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    s=sub[i]\n",
    "    globals()['sub_%s' % i]=df.loc[df.subject.isin([s])]\n",
    "    #eval(\"'sub'+str(i)= df.loc[df.subject.isin([s])]\")\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X, y= sm.fit_sample(globals()['sub_%s' % i][features_with_sub], globals()['sub_%s' % i]['label'])\n",
    "    globals()['sub_%s' % i]=pd.concat([pd.DataFrame(X,columns=features_with_sub),pd.DataFrame(y,columns=['label'])],axis=1)\n",
    "df_new=pd.concat([sub_1,sub_2,sub_3,sub_4,sub_5,sub_6])\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaled_data_train = scaler.fit_transform(df_new[sel_fea])\n",
    "scaled_data_test = scaler.transform(test[sel_fea])\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=100,n_jobs=10)\n",
    "clf.fit(scaled_data_train,df_new['label'])\n",
    "y_pred=clf.predict(scaled_data_test)\n",
    "#print (classification_report(test['label'],y_pred))\n",
    "print(7,8,'3_class')\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
