{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.3 s, sys: 681 ms, total: 2.98 s\n",
      "Wall time: 2.17 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from itertools import combinations \n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn import model_selection\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('60s_window_wrist_chest.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    312\n",
       "1    175\n",
       "2     90\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[df['label']<3]\n",
    "df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=df.columns.tolist()\n",
    "features\n",
    "\n",
    "removed = ['label']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "features_with_sub=[]\n",
    "features_with_sub[:]=features\n",
    "removed = ['subject']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "feature=features\n",
    "print(len(feature))\n",
    "len(features_with_sub)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_acc_mean</th>\n",
       "      <th>net_acc_std</th>\n",
       "      <th>net_acc_min</th>\n",
       "      <th>net_acc_max</th>\n",
       "      <th>ACC_x_mean</th>\n",
       "      <th>ACC_x_std</th>\n",
       "      <th>ACC_x_min</th>\n",
       "      <th>ACC_x_max</th>\n",
       "      <th>ACC_y_mean</th>\n",
       "      <th>ACC_y_std</th>\n",
       "      <th>...</th>\n",
       "      <th>c_ACC_z_min</th>\n",
       "      <th>c_ACC_z_max</th>\n",
       "      <th>c_Temp_mean</th>\n",
       "      <th>c_Temp_std</th>\n",
       "      <th>c_Temp_min</th>\n",
       "      <th>c_Temp_max</th>\n",
       "      <th>BVP_peak_freq</th>\n",
       "      <th>TEMP_slope</th>\n",
       "      <th>subject</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>0.017769</td>\n",
       "      <td>-0.037843</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.222594e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.870000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>29.168923</td>\n",
       "      <td>0.064290</td>\n",
       "      <td>28.994568</td>\n",
       "      <td>29.426208</td>\n",
       "      <td>0.081425</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>7.290999e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.759400</td>\n",
       "      <td>-0.681000</td>\n",
       "      <td>28.886605</td>\n",
       "      <td>0.074846</td>\n",
       "      <td>28.730682</td>\n",
       "      <td>29.207275</td>\n",
       "      <td>0.147017</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.028378</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>-0.002752</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>4.805734e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.753400</td>\n",
       "      <td>-0.675400</td>\n",
       "      <td>28.799659</td>\n",
       "      <td>0.037924</td>\n",
       "      <td>28.679108</td>\n",
       "      <td>28.988800</td>\n",
       "      <td>0.088210</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.033268</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>-0.030962</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6.126303e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.787800</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>28.768865</td>\n",
       "      <td>0.058639</td>\n",
       "      <td>28.584656</td>\n",
       "      <td>29.023285</td>\n",
       "      <td>0.117614</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>8.837530e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.720200</td>\n",
       "      <td>-0.657000</td>\n",
       "      <td>28.598514</td>\n",
       "      <td>0.068128</td>\n",
       "      <td>28.447449</td>\n",
       "      <td>28.882599</td>\n",
       "      <td>0.151541</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>931</td>\n",
       "      <td>0.031530</td>\n",
       "      <td>0.004007</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.050228</td>\n",
       "      <td>-0.022808</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>-0.040138</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>2.931165e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113076</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>33.297833</td>\n",
       "      <td>0.024254</td>\n",
       "      <td>33.168722</td>\n",
       "      <td>33.447496</td>\n",
       "      <td>0.107634</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>4.868999</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>932</td>\n",
       "      <td>0.042665</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.041987</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.042665</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.041987</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>4.434421e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.522529</td>\n",
       "      <td>-0.424331</td>\n",
       "      <td>33.967632</td>\n",
       "      <td>0.023645</td>\n",
       "      <td>33.814856</td>\n",
       "      <td>34.178782</td>\n",
       "      <td>0.156119</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>933</td>\n",
       "      <td>0.029987</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.038699</td>\n",
       "      <td>0.029987</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.038699</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>4.893909e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.629739</td>\n",
       "      <td>-0.476673</td>\n",
       "      <td>34.612781</td>\n",
       "      <td>0.029946</td>\n",
       "      <td>34.511846</td>\n",
       "      <td>34.753920</td>\n",
       "      <td>0.138129</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>7.012184</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>934</td>\n",
       "      <td>0.042228</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.042228</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.041533</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>5.652578e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.518388</td>\n",
       "      <td>-0.382084</td>\n",
       "      <td>34.120904</td>\n",
       "      <td>0.026747</td>\n",
       "      <td>33.979167</td>\n",
       "      <td>34.313393</td>\n",
       "      <td>0.145269</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>12.451795</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935</td>\n",
       "      <td>0.011288</td>\n",
       "      <td>0.007559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038614</td>\n",
       "      <td>-0.004731</td>\n",
       "      <td>0.012529</td>\n",
       "      <td>-0.038614</td>\n",
       "      <td>0.017076</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>8.620611e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360768</td>\n",
       "      <td>-0.047806</td>\n",
       "      <td>34.385357</td>\n",
       "      <td>0.027981</td>\n",
       "      <td>34.259638</td>\n",
       "      <td>34.532003</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>8.211951</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>936 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     net_acc_mean  net_acc_std  net_acc_min  net_acc_max  ACC_x_mean  \\\n",
       "0        0.025961     0.013811     0.000000     0.087383    0.023431   \n",
       "1        0.027640     0.010597     0.002752     0.054356    0.027640   \n",
       "2        0.028389     0.006937     0.000000     0.066053    0.028378   \n",
       "3        0.033268     0.007670     0.000000     0.074998    0.032960   \n",
       "4        0.037021     0.001284     0.027522     0.043347    0.037021   \n",
       "..            ...          ...          ...          ...         ...   \n",
       "931      0.031530     0.004007     0.002869     0.050228   -0.022808   \n",
       "932      0.042665     0.000064     0.041987     0.043347    0.042665   \n",
       "933      0.029987     0.000711     0.019358     0.038699    0.029987   \n",
       "934      0.042228     0.000082     0.041533     0.043567    0.042228   \n",
       "935      0.011288     0.007559     0.000000     0.038614   -0.004731   \n",
       "\n",
       "     ACC_x_std  ACC_x_min  ACC_x_max  ACC_y_mean     ACC_y_std  ...  \\\n",
       "0     0.017769  -0.037843   0.087383    0.000016  1.222594e-05  ...   \n",
       "1     0.010597   0.002752   0.054356    0.000019  7.290999e-06  ...   \n",
       "2     0.006985  -0.002752   0.066053    0.000020  4.805734e-06  ...   \n",
       "3     0.008904  -0.030962   0.074998    0.000023  6.126303e-06  ...   \n",
       "4     0.001284   0.027522   0.043347    0.000025  8.837530e-07  ...   \n",
       "..         ...        ...        ...         ...           ...  ...   \n",
       "931   0.004260  -0.040138   0.015469   -0.000016  2.931165e-06  ...   \n",
       "932   0.000064   0.041987   0.043347    0.000029  4.434421e-08  ...   \n",
       "933   0.000711   0.019358   0.038699    0.000021  4.893909e-07  ...   \n",
       "934   0.000082   0.041533   0.043567    0.000029  5.652578e-08  ...   \n",
       "935   0.012529  -0.038614   0.017076   -0.000003  8.620611e-06  ...   \n",
       "\n",
       "     c_ACC_z_min  c_ACC_z_max  c_Temp_mean  c_Temp_std  c_Temp_min  \\\n",
       "0      -0.870000     0.611000    29.168923    0.064290   28.994568   \n",
       "1      -0.759400    -0.681000    28.886605    0.074846   28.730682   \n",
       "2      -0.753400    -0.675400    28.799659    0.037924   28.679108   \n",
       "3      -0.787800     0.166000    28.768865    0.058639   28.584656   \n",
       "4      -0.720200    -0.657000    28.598514    0.068128   28.447449   \n",
       "..           ...          ...          ...         ...         ...   \n",
       "931    -0.113076     0.309000    33.297833    0.024254   33.168722   \n",
       "932    -0.522529    -0.424331    33.967632    0.023645   33.814856   \n",
       "933    -0.629739    -0.476673    34.612781    0.029946   34.511846   \n",
       "934    -0.518388    -0.382084    34.120904    0.026747   33.979167   \n",
       "935    -0.360768    -0.047806    34.385357    0.027981   34.259638   \n",
       "\n",
       "     c_Temp_max  BVP_peak_freq  TEMP_slope    subject  label  \n",
       "0     29.426208       0.081425   -0.000253   2.000000      0  \n",
       "1     29.207275       0.147017   -0.000161   2.000000      0  \n",
       "2     28.988800       0.088210    0.000535   2.000000      0  \n",
       "3     29.023285       0.117614   -0.000256   2.000000      0  \n",
       "4     28.882599       0.151541    0.000260   2.000000      0  \n",
       "..          ...            ...         ...        ...    ...  \n",
       "931   33.447496       0.107634    0.000058   4.868999      2  \n",
       "932   34.178782       0.156119   -0.000094  15.000000      2  \n",
       "933   34.753920       0.138129   -0.000011   7.012184      2  \n",
       "934   34.313393       0.145269   -0.000121  12.451795      2  \n",
       "935   34.532003       0.140000    0.000030   8.211951      2  \n",
       "\n",
       "[936 rows x 72 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state=2)\n",
    "X, y= sm.fit_sample(df[features_with_sub], df['label'])\n",
    "df_new=pd.concat([pd.DataFrame(X,columns=features_with_sub),pd.DataFrame(y,columns=['label'])],axis=1)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range (len(list(df_new['subject']))):\n",
    "    df_new['subject'][i] = min([2,3,4,5,6,7,8,9,10,11,13,14,15,16,17], key=lambda x:abs(x-df_new['subject'][i]))\n",
    "df_new['subject']=df_new['subject'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_d=pd.read_csv('personal_detail.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>net_acc_mean</th>\n",
       "      <th>net_acc_std</th>\n",
       "      <th>net_acc_min</th>\n",
       "      <th>net_acc_max</th>\n",
       "      <th>ACC_x_mean</th>\n",
       "      <th>ACC_x_std</th>\n",
       "      <th>ACC_x_min</th>\n",
       "      <th>ACC_x_max</th>\n",
       "      <th>ACC_y_mean</th>\n",
       "      <th>ACC_y_std</th>\n",
       "      <th>...</th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>gender_ female</th>\n",
       "      <th>coffee_today_YES</th>\n",
       "      <th>sport_today_YES</th>\n",
       "      <th>smoker_YES</th>\n",
       "      <th>feel_ill_today_YES</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.023431</td>\n",
       "      <td>0.017769</td>\n",
       "      <td>-0.037843</td>\n",
       "      <td>0.087383</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>1.222594e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.027640</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.054356</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>7.290999e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.028378</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>-0.002752</td>\n",
       "      <td>0.066053</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>4.805734e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.033268</td>\n",
       "      <td>0.007670</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>-0.030962</td>\n",
       "      <td>0.074998</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>6.126303e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.037021</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.027522</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>8.837530e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>175</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>931</td>\n",
       "      <td>0.029441</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.020770</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>-0.004075</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>-0.014956</td>\n",
       "      <td>0.018375</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.440095e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>932</td>\n",
       "      <td>0.029484</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.020918</td>\n",
       "      <td>0.053804</td>\n",
       "      <td>-0.004624</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>-0.015439</td>\n",
       "      <td>0.017447</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>1.427082e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>933</td>\n",
       "      <td>0.032744</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.029211</td>\n",
       "      <td>0.034857</td>\n",
       "      <td>-0.029334</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>-0.031478</td>\n",
       "      <td>-0.025832</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>3.552867e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>934</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>0.002966</td>\n",
       "      <td>0.070357</td>\n",
       "      <td>-0.027424</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>-0.067796</td>\n",
       "      <td>-0.000404</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>4.851210e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>-0.038575</td>\n",
       "      <td>-0.027188</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>1.055452e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>165</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>936 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     net_acc_mean  net_acc_std  net_acc_min  net_acc_max  ACC_x_mean  \\\n",
       "0        0.025961     0.013811     0.000000     0.087383    0.023431   \n",
       "1        0.027640     0.010597     0.002752     0.054356    0.027640   \n",
       "2        0.028389     0.006937     0.000000     0.066053    0.028378   \n",
       "3        0.033268     0.007670     0.000000     0.074998    0.032960   \n",
       "4        0.037021     0.001284     0.027522     0.043347    0.037021   \n",
       "..            ...          ...          ...          ...         ...   \n",
       "931      0.029441     0.002093     0.020770     0.054100   -0.004075   \n",
       "932      0.029484     0.002074     0.020918     0.053804   -0.004624   \n",
       "933      0.032744     0.000516     0.029211     0.034857   -0.029334   \n",
       "934      0.030006     0.007051     0.002966     0.070357   -0.027424   \n",
       "935      0.031250     0.001534     0.027188     0.038575   -0.031250   \n",
       "\n",
       "     ACC_x_std  ACC_x_min  ACC_x_max  ACC_y_mean     ACC_y_std  ...  label  \\\n",
       "0     0.017769  -0.037843   0.087383    0.000016  1.222594e-05  ...      0   \n",
       "1     0.010597   0.002752   0.054356    0.000019  7.290999e-06  ...      0   \n",
       "2     0.006985  -0.002752   0.066053    0.000020  4.805734e-06  ...      0   \n",
       "3     0.008904  -0.030962   0.074998    0.000023  6.126303e-06  ...      0   \n",
       "4     0.001284   0.027522   0.043347    0.000025  8.837530e-07  ...      0   \n",
       "..         ...        ...        ...         ...           ...  ...    ...   \n",
       "931   0.002093  -0.014956   0.018375   -0.000003  1.440095e-06  ...      1   \n",
       "932   0.002074  -0.015439   0.017447   -0.000003  1.427082e-06  ...      1   \n",
       "933   0.000516  -0.031478  -0.025832   -0.000020  3.552867e-07  ...      2   \n",
       "934   0.007051  -0.067796  -0.000404   -0.000019  4.851210e-06  ...      2   \n",
       "935   0.001534  -0.038575  -0.027188   -0.000022  1.055452e-06  ...      2   \n",
       "\n",
       "     age  height  weight  gender_ female  coffee_today_YES  sport_today_YES  \\\n",
       "0     27     175      80               0                 0                0   \n",
       "1     27     175      80               0                 0                0   \n",
       "2     27     175      80               0                 0                0   \n",
       "3     27     175      80               0                 0                0   \n",
       "4     27     175      80               0                 0                0   \n",
       "..   ...     ...     ...             ...               ...              ...   \n",
       "931   29     165      55               1                 0                0   \n",
       "932   29     165      55               1                 0                0   \n",
       "933   29     165      55               1                 0                0   \n",
       "934   29     165      55               1                 0                0   \n",
       "935   29     165      55               1                 0                0   \n",
       "\n",
       "     smoker_YES  feel_ill_today_YES  bmi  \n",
       "0             0                   0    1  \n",
       "1             0                   0    1  \n",
       "2             0                   0    1  \n",
       "3             0                   0    1  \n",
       "4             0                   0    1  \n",
       "..          ...                 ...  ...  \n",
       "931           0                   0    0  \n",
       "932           0                   0    0  \n",
       "933           0                   0    0  \n",
       "934           0                   0    0  \n",
       "935           0                   0    0  \n",
       "\n",
       "[936 rows x 81 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1=df_new.merge(p_d,on='subject')\n",
    "df_new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    312\n",
       "1    312\n",
       "0    312\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=df_new_1.columns.tolist()\n",
    "features\n",
    "\n",
    "removed = ['label']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "features_with_sub=[]\n",
    "features_with_sub[:]=features\n",
    "removed = ['subject']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "feature=features\n",
    "print(len(feature))\n",
    "len(features_with_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df_new_1[df_new_1['subject']<=9]\n",
    "test=df_new_1[df_new_1['subject']>9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = Normalizer()\n",
    "# scaled_data_train = scaler.fit_transform(train[feature])\n",
    "# scaled_data_test = scaler.transform(test[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer()\n",
    "scaled_data_train = scaler.fit_transform(train[feature])\n",
    "scaled_data_test = scaler.transform(test[feature])\n",
    "et = ExtraTreesClassifier(n_estimators=50,n_jobs=10,random_state=237)\n",
    "et.fit(scaled_data_train,train['label'])\n",
    "y_pred=et.predict(scaled_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# et = ExtraTreesClassifier(n_estimators=50,n_jobs=10,random_state=237)\n",
    "# et.fit(train[feature],train['label'])\n",
    "# y_pred=et.predict(test[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.71      0.79       147\n",
      "           1       0.87      0.93      0.90       161\n",
      "           2       0.82      0.95      0.88       146\n",
      "\n",
      "    accuracy                           0.86       454\n",
      "   macro avg       0.87      0.86      0.86       454\n",
      "weighted avg       0.87      0.86      0.86       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(et.feature_importances_,index = feature,columns=['importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>EDA_tonic_mean</td>\n",
       "      <td>0.066175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EDA_tonic_max</td>\n",
       "      <td>0.055329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EDA_tonic_min</td>\n",
       "      <td>0.050033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EDA_phasic_mean</td>\n",
       "      <td>0.032197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>c_ACC_z_mean</td>\n",
       "      <td>0.027899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BVP_mean</td>\n",
       "      <td>0.002918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gender_ female</td>\n",
       "      <td>0.002533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ACC_y_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ACC_z_std</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EDA_smna_min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 importance\n",
       "EDA_tonic_mean     0.066175\n",
       "EDA_tonic_max      0.055329\n",
       "EDA_tonic_min      0.050033\n",
       "EDA_phasic_mean    0.032197\n",
       "c_ACC_z_mean       0.027899\n",
       "...                     ...\n",
       "BVP_mean           0.002918\n",
       "gender_ female     0.002533\n",
       "ACC_y_std          0.000000\n",
       "ACC_z_std          0.000000\n",
       "EDA_smna_min       0.000000\n",
       "\n",
       "[79 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection with feature_importances using forward Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean',\n",
       "       'c_ACC_z_mean', 'EDA_smna_std', 'EDA_smna_mean', 'EDA_phasic_min',\n",
       "       'EDA_min', 'EDA_phasic_max', 'EDA_max', 'EDA_smna_max', 'EMG_std',\n",
       "       'EDA_tonic_std', 'c_ACC_y_mean', 'EDA_phasic_std', 'Resp_std',\n",
       "       'EDA_mean', 'c_ACC_z_max', 'BVP_std', 'c_ACC_y_min', 'TEMP_slope',\n",
       "       'Resp_max', 'ACC_x_max', 'net_acc_std', 'TEMP_std', 'Resp_min',\n",
       "       'ACC_x_std', 'EDA_std', 'c_ACC_x_max', 'sport_today_YES', 'c_Temp_mean',\n",
       "       'EMG_mean', 'c_ACC_x_mean', 'ECG_max', 'net_acc_mean', 'EMG_max',\n",
       "       'ECG_min', 'EMG_min', 'ACC_x_mean', 'ECG_std', 'c_Temp_max',\n",
       "       'BVP_peak_freq', 'weight', 'TEMP_max', 'c_ACC_y_max', 'net_acc_max',\n",
       "       'net_acc_min', 'c_ACC_z_min', 'TEMP_min', 'c_ACC_x_std',\n",
       "       'feel_ill_today_YES', 'TEMP_mean', 'c_Temp_min', 'age', 'c_ACC_z_std',\n",
       "       'c_ACC_y_std', 'BVP_min', 'c_ACC_x_min', 'BVP_max', 'height',\n",
       "       'ACC_y_max', 'ACC_z_max', 'ECG_mean', 'ACC_z_min', 'ACC_z_mean',\n",
       "       'ACC_x_min', 'c_Temp_std', 'Resp_mean', 'coffee_today_YES', 'ACC_y_min',\n",
       "       'ACC_y_mean', 'bmi', 'smoker_YES', 'BVP_mean', 'gender_ female',\n",
       "       'ACC_y_std', 'ACC_z_std', 'EDA_smna_min'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "13\n",
      "14\n",
      "14\n",
      "14\n",
      "15\n",
      "15\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "18\n",
      "18\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "19\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "# sel_fea = ['EDA_tonic_mean','EDA_tonic_max','EDA_phasic_max','TEMP_mean','EDA_max']\n",
    "sel_fea = []\n",
    "pas_acc = 0.0\n",
    "\n",
    "for i in feature_importances.index:\n",
    "    sel_fea.append(i)\n",
    "    print (len(sel_fea))\n",
    "    et = ExtraTreesClassifier(n_estimators=50,n_jobs=10,random_state=70)\n",
    "    et.fit(train[sel_fea],train['label'])\n",
    "    y_pred=et.predict(test[sel_fea])\n",
    "\n",
    "    rpt = classification_report(test['label'],y_pred,output_dict=True)['accuracy']\n",
    "    \n",
    "    if rpt< pas_acc:\n",
    "        sel_fea.pop()\n",
    "    else:\n",
    "        pas_acc = rpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EDA_tonic_mean',\n",
       " 'EDA_tonic_max',\n",
       " 'EDA_tonic_min',\n",
       " 'EDA_phasic_mean',\n",
       " 'EDA_smna_std',\n",
       " 'EDA_smna_mean',\n",
       " 'EDA_phasic_min',\n",
       " 'EDA_min',\n",
       " 'EMG_std',\n",
       " 'c_ACC_y_mean',\n",
       " 'c_ACC_y_min',\n",
       " 'net_acc_std',\n",
       " 'TEMP_std',\n",
       " 'EDA_std',\n",
       " 'sport_today_YES',\n",
       " 'net_acc_mean',\n",
       " 'ECG_std',\n",
       " 'BVP_peak_freq',\n",
       " 'c_ACC_x_std',\n",
       " 'c_ACC_y_std',\n",
       " 'ACC_z_min']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84       147\n",
      "           1       0.92      0.89      0.91       161\n",
      "           2       0.81      0.92      0.86       146\n",
      "\n",
      "    accuracy                           0.87       454\n",
      "   macro avg       0.87      0.87      0.87       454\n",
      "weighted avg       0.87      0.87      0.87       454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sel_fea_tuned = ['EDA_tonic_mean','EDA_tonic_max','EDA_phasic_max','ECG_std']\n",
    "# sel_fea_tuned_0 =['EDA_tonic_mean',\n",
    "#  'EDA_tonic_max',\n",
    "#  'EDA_tonic_min',\n",
    "#  'EDA_phasic_mean',\n",
    "#  'EDA_smna_std',\n",
    "#  'EDA_smna_mean',\n",
    "#  'EDA_phasic_min',\n",
    "#  'EDA_min',\n",
    "#  'EMG_std',\n",
    "#  'c_ACC_y_mean',\n",
    "#  'c_ACC_y_min',\n",
    "#  'net_acc_std',\n",
    "#  'TEMP_std',\n",
    "#  'EDA_std',\n",
    "#  'sport_today_YES',\n",
    "#  'net_acc_mean',\n",
    "#  'ECG_std',\n",
    "#  'BVP_peak_freq',\n",
    "#  'c_ACC_x_std',\n",
    "#  'c_ACC_y_std',\n",
    "#  'ACC_z_min']\n",
    "sel_fea_tuned=['EDA_tonic_mean',\n",
    " 'EDA_tonic_max',\n",
    " 'EDA_tonic_min',\n",
    " 'EDA_phasic_mean',\n",
    " 'EDA_smna_mean',\n",
    " 'EDA_phasic_min',\n",
    " 'EMG_std',\n",
    " 'c_ACC_y_min',\n",
    " 'sport_today_YES',\n",
    " 'ECG_std',\n",
    " 'c_ACC_x_std',\n",
    " 'c_ACC_y_std']\n",
    "print(len(sel_fea_tuned))\n",
    "et = ExtraTreesClassifier(n_estimators=50,n_jobs=10,random_state=39)\n",
    "et.fit(train[sel_fea_tuned],train['label'])\n",
    "y_pred=et.predict(test[sel_fea_tuned])\n",
    "\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-58888c205bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0met\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0met\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel_fea_tuned\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0met\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel_fea_tuned\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    315\u001b[0m             trees = [self._make_estimator(append=False,\n\u001b[1;32m    316\u001b[0m                                           random_state=random_state)\n\u001b[0;32m--> 317\u001b[0;31m                      for i in range(n_more_estimators)]\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# Parallel loop: we prefer the threading backend as the Cython code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    315\u001b[0m             trees = [self._make_estimator(append=False,\n\u001b[1;32m    316\u001b[0m                                           random_state=random_state)\n\u001b[0;32m--> 317\u001b[0;31m                      for i in range(n_more_estimators)]\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;31m# Parallel loop: we prefer the threading backend as the Cython code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0m_set_random_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m_set_random_states\u001b[0;34m(estimator, random_state)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mto_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mto_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;31m# Simple optimization to gain speed (inspect is slow)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mvalid_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mnested_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# grouped by prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \"\"\"\n\u001b[1;32m    191\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'get_params'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# to represent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[0;32m/usr/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3063\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     \u001b[0;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3065\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2813\u001b[0m         \u001b[0;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[0;32m-> 2815\u001b[0;31m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0m\u001b[1;32m   2816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         \u001b[0;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2268\u001b[0m         \u001b[0;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_signature_from_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_signature_is_builtin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[0;34m(cls, func)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[1;32m   2145\u001b[0m                                     \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_POSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m                                     default=defaults[offset]))\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m     \u001b[0;31m# *args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, kind, default, annotation)\u001b[0m\n\u001b[1;32m   2452\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2453\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2454\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ParameterKind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2455\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'value {kind!r} is not a valid Parameter.kind'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/enum.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \"\"\"\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# simple value lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# otherwise, functional API: we're creating a new Enum type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqualname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range (0,101):\n",
    "    et = ExtraTreesClassifier(n_estimators=50,n_jobs=10,random_state=i)\n",
    "    et.fit(train[sel_fea_tuned],train['label'])\n",
    "    y_pred=et.predict(test[sel_fea_tuned])\n",
    "\n",
    "    rpt = classification_report(test['label'],y_pred,output_dict=True)['accuracy']\n",
    "    \n",
    "    if rpt >= 0.88:\n",
    "        print (i)\n",
    "        print (classification_report(test['label'],y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing with  ['EDA_tonic_mean']\n",
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.65      0.57       147\n",
      "           1       0.73      0.66      0.69       161\n",
      "           2       0.63      0.50      0.56       146\n",
      "\n",
      "    accuracy                           0.61       454\n",
      "   macro avg       0.62      0.61      0.61       454\n",
      "weighted avg       0.62      0.61      0.61       454\n",
      "\n",
      "do you want to add this featurey\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max']\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.63      0.56       147\n",
      "           1       0.86      0.74      0.79       161\n",
      "           2       0.64      0.58      0.61       146\n",
      "\n",
      "    accuracy                           0.65       454\n",
      "   macro avg       0.67      0.65      0.66       454\n",
      "weighted avg       0.68      0.65      0.66       454\n",
      "\n",
      "do you want to add this featurey\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min']\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.65      0.58       147\n",
      "           1       0.87      0.76      0.81       161\n",
      "           2       0.68      0.61      0.64       146\n",
      "\n",
      "    accuracy                           0.68       454\n",
      "   macro avg       0.69      0.67      0.68       454\n",
      "weighted avg       0.70      0.68      0.68       454\n",
      "\n",
      "do you want to add this featurey\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean']\n",
      "4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.69      0.63       147\n",
      "           1       0.88      0.80      0.83       161\n",
      "           2       0.70      0.63      0.66       146\n",
      "\n",
      "    accuracy                           0.71       454\n",
      "   macro avg       0.72      0.71      0.71       454\n",
      "weighted avg       0.72      0.71      0.71       454\n",
      "\n",
      "do you want to add this featurey\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_std']\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.67      0.61       147\n",
      "           1       0.88      0.80      0.84       161\n",
      "           2       0.70      0.63      0.66       146\n",
      "\n",
      "    accuracy                           0.70       454\n",
      "   macro avg       0.71      0.70      0.70       454\n",
      "weighted avg       0.72      0.70      0.71       454\n",
      "\n",
      "do you want to add this featuren\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean']\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.72      0.63       147\n",
      "           1       0.89      0.79      0.84       161\n",
      "           2       0.73      0.60      0.66       146\n",
      "\n",
      "    accuracy                           0.71       454\n",
      "   macro avg       0.73      0.70      0.71       454\n",
      "weighted avg       0.73      0.71      0.71       454\n",
      "\n",
      "do you want to add this featurey\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min']\n",
      "6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.75      0.68       147\n",
      "           1       0.84      0.79      0.81       161\n",
      "           2       0.73      0.62      0.67       146\n",
      "\n",
      "    accuracy                           0.72       454\n",
      "   macro avg       0.73      0.72      0.72       454\n",
      "weighted avg       0.73      0.72      0.72       454\n",
      "\n",
      "do you want to add this featurey\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EDA_min']\n",
      "7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.73      0.65       147\n",
      "           1       0.89      0.79      0.84       161\n",
      "           2       0.73      0.63      0.68       146\n",
      "\n",
      "    accuracy                           0.72       454\n",
      "   macro avg       0.73      0.72      0.72       454\n",
      "weighted avg       0.74      0.72      0.72       454\n",
      "\n",
      "do you want to add this featuren\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EMG_std']\n",
      "7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72       147\n",
      "           1       0.89      0.79      0.84       161\n",
      "           2       0.79      0.82      0.81       146\n",
      "\n",
      "    accuracy                           0.79       454\n",
      "   macro avg       0.79      0.79      0.79       454\n",
      "weighted avg       0.80      0.79      0.79       454\n",
      "\n",
      "do you want to add this featurey\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EMG_std', 'c_ACC_y_mean']\n",
      "8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.67      0.72       147\n",
      "           1       0.88      0.82      0.85       161\n",
      "           2       0.73      0.89      0.80       146\n",
      "\n",
      "    accuracy                           0.79       454\n",
      "   macro avg       0.80      0.79      0.79       454\n",
      "weighted avg       0.80      0.79      0.79       454\n",
      "\n",
      "do you want to add this featuren\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EMG_std', 'c_ACC_y_min']\n",
      "8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.76       147\n",
      "           1       0.90      0.80      0.84       161\n",
      "           2       0.80      0.87      0.83       146\n",
      "\n",
      "    accuracy                           0.81       454\n",
      "   macro avg       0.82      0.81      0.81       454\n",
      "weighted avg       0.82      0.81      0.81       454\n",
      "\n",
      "do you want to add this featurey\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EMG_std', 'c_ACC_y_min', 'net_acc_std']\n",
      "9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.75       147\n",
      "           1       0.90      0.80      0.84       161\n",
      "           2       0.84      0.82      0.83       146\n",
      "\n",
      "    accuracy                           0.80       454\n",
      "   macro avg       0.81      0.80      0.81       454\n",
      "weighted avg       0.81      0.80      0.81       454\n",
      "\n",
      "do you want to add this featuren\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EMG_std', 'c_ACC_y_min', 'TEMP_std']\n",
      "9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       147\n",
      "           1       0.87      0.80      0.83       161\n",
      "           2       0.79      0.84      0.81       146\n",
      "\n",
      "    accuracy                           0.80       454\n",
      "   macro avg       0.80      0.80      0.80       454\n",
      "weighted avg       0.80      0.80      0.80       454\n",
      "\n",
      "do you want to add this featuren\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EMG_std', 'c_ACC_y_min', 'EDA_std']\n",
      "9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75       147\n",
      "           1       0.90      0.79      0.84       161\n",
      "           2       0.81      0.86      0.83       146\n",
      "\n",
      "    accuracy                           0.81       454\n",
      "   macro avg       0.81      0.81      0.81       454\n",
      "weighted avg       0.81      0.81      0.81       454\n",
      "\n",
      "do you want to add this featuren\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EMG_std', 'c_ACC_y_min', 'sport_today_YES']\n",
      "9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78       147\n",
      "           1       0.90      0.81      0.85       161\n",
      "           2       0.81      0.87      0.84       146\n",
      "\n",
      "    accuracy                           0.82       454\n",
      "   macro avg       0.83      0.82      0.82       454\n",
      "weighted avg       0.83      0.82      0.82       454\n",
      "\n",
      "do you want to add this featurey\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EMG_std', 'c_ACC_y_min', 'sport_today_YES', 'net_acc_mean']\n",
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74       147\n",
      "           1       0.83      0.76      0.79       161\n",
      "           2       0.81      0.83      0.82       146\n",
      "\n",
      "    accuracy                           0.78       454\n",
      "   macro avg       0.78      0.78      0.78       454\n",
      "weighted avg       0.78      0.78      0.78       454\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you want to add this featuren\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EMG_std', 'c_ACC_y_min', 'sport_today_YES', 'ECG_std']\n",
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.76      0.80       147\n",
      "           1       0.86      0.87      0.87       161\n",
      "           2       0.81      0.88      0.84       146\n",
      "\n",
      "    accuracy                           0.84       454\n",
      "   macro avg       0.84      0.84      0.84       454\n",
      "weighted avg       0.84      0.84      0.84       454\n",
      "\n",
      "do you want to add this featurey\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EMG_std', 'c_ACC_y_min', 'sport_today_YES', 'ECG_std', 'BVP_peak_freq']\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79       147\n",
      "           1       0.91      0.84      0.87       161\n",
      "           2       0.80      0.88      0.84       146\n",
      "\n",
      "    accuracy                           0.83       454\n",
      "   macro avg       0.84      0.83      0.83       454\n",
      "weighted avg       0.84      0.83      0.84       454\n",
      "\n",
      "do you want to add this featuren\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EMG_std', 'c_ACC_y_min', 'sport_today_YES', 'ECG_std', 'c_ACC_x_std']\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.81       147\n",
      "           1       0.90      0.87      0.88       161\n",
      "           2       0.79      0.92      0.85       146\n",
      "\n",
      "    accuracy                           0.85       454\n",
      "   macro avg       0.85      0.85      0.85       454\n",
      "weighted avg       0.86      0.85      0.85       454\n",
      "\n",
      "do you want to add this featurey\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EMG_std', 'c_ACC_y_min', 'sport_today_YES', 'ECG_std', 'c_ACC_x_std', 'c_ACC_y_std']\n",
      "12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84       147\n",
      "           1       0.92      0.89      0.91       161\n",
      "           2       0.81      0.92      0.86       146\n",
      "\n",
      "    accuracy                           0.87       454\n",
      "   macro avg       0.87      0.87      0.87       454\n",
      "weighted avg       0.87      0.87      0.87       454\n",
      "\n",
      "do you want to add this featurey\n",
      "testing with  ['EDA_tonic_mean', 'EDA_tonic_max', 'EDA_tonic_min', 'EDA_phasic_mean', 'EDA_smna_mean', 'EDA_phasic_min', 'EMG_std', 'c_ACC_y_min', 'sport_today_YES', 'ECG_std', 'c_ACC_x_std', 'c_ACC_y_std', 'ACC_z_min']\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       147\n",
      "           1       0.85      0.86      0.86       161\n",
      "           2       0.82      0.79      0.80       146\n",
      "\n",
      "    accuracy                           0.83       454\n",
      "   macro avg       0.83      0.83      0.83       454\n",
      "weighted avg       0.83      0.83      0.83       454\n",
      "\n",
      "do you want to add this featuren\n"
     ]
    }
   ],
   "source": [
    "imp=[]\n",
    "for i in sel_fea_tuned:\n",
    "    test_=[]\n",
    "    test_[:]=imp\n",
    "    test_.append(i)\n",
    "    print('testing with ',test_)\n",
    "    print(len(test_))\n",
    "    \n",
    "    et = ExtraTreesClassifier(n_estimators=50,n_jobs=10,random_state=39)\n",
    "    et.fit(train[test_],train['label'])\n",
    "    y_pred=et.predict(test[test_])\n",
    "    print(classification_report(test['label'],y_pred))\n",
    "    add=input('do you want to add this feature')\n",
    "    if add=='y':\n",
    "        imp.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EDA_tonic_mean',\n",
       " 'EDA_tonic_max',\n",
       " 'EDA_tonic_min',\n",
       " 'EDA_phasic_mean',\n",
       " 'EDA_smna_mean',\n",
       " 'EDA_phasic_min',\n",
       " 'EMG_std',\n",
       " 'c_ACC_y_min',\n",
       " 'sport_today_YES',\n",
       " 'ECG_std',\n",
       " 'c_ACC_x_std',\n",
       " 'c_ACC_y_std']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
