{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 812 ms, sys: 274 ms, total: 1.09 s\n",
      "Wall time: 913 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.46 s, sys: 371 ms, total: 1.83 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from itertools import combinations \n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('60s_window_wrist_chest.csv',index_col=0)\n",
    "df['label'].value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2229299363057325\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].value_counts()[1]/(len(list(df['label']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('60s_window_wrist_chest.csv',index_col=0)\n",
    "features=df.columns.tolist()\n",
    "\n",
    "removed = ['label']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "features_with_sub=[]\n",
    "features_with_sub[:]=features\n",
    "removed = ['subject']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "feature=features\n",
    "print(len(feature))\n",
    "len(features_with_sub)\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X, y= sm.fit_sample(df[features_with_sub], df['label'])\n",
    "df_new=pd.concat([pd.DataFrame(X,columns=features_with_sub),pd.DataFrame(y,columns=['label'])],axis=1)\n",
    "\n",
    "\n",
    "for i in range (len(list(df_new['subject']))):\n",
    "    df_new['subject'][i] = min([2,3,4,5,6,7,8,9,10,11,13,14,15,16,17], key=lambda x:abs(x-df_new['subject'][i]))\n",
    "df_new['subject']=df_new['subject'].astype(int)\n",
    "\n",
    "\n",
    "p_d=pd.read_csv('personal_detail.csv',index_col=0)\n",
    "\n",
    "\n",
    "df_new_1=df_new.merge(p_d,on='subject')\n",
    "\n",
    "\n",
    "features=df_new_1.columns.tolist()\n",
    "features\n",
    "\n",
    "removed = ['label']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "features_with_sub=[]\n",
    "features_with_sub[:]=features\n",
    "removed = ['subject']\n",
    "for rem in removed:\n",
    "    features.remove(rem)\n",
    "\n",
    "feature=features\n",
    "print(len(feature))\n",
    "len(features_with_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df_new_1[df_new_1['subject']<=9]\n",
    "test=df_new_1[df_new_1['subject']>9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.62      0.69       147\n",
      "           1       0.90      0.92      0.91       161\n",
      "           2       0.65      0.79      0.71       146\n",
      "           3       0.76      0.74      0.75       149\n",
      "\n",
      "    accuracy                           0.77       603\n",
      "   macro avg       0.77      0.77      0.77       603\n",
      "weighted avg       0.77      0.77      0.77       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100,n_jobs=10,random_state=56 ,)\n",
    "scaler = Normalizer()\n",
    "scaled_data_train = scaler.fit_transform(train[feature])\n",
    "scaled_data_test = scaler.transform(test[feature])\n",
    "et.fit(scaled_data_train,train['label'])\n",
    "y_pred=et.predict(scaled_data_test)\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.0001, batch_size='auto',\n",
       "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(500, 200), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#activation : {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}\n",
    "#solver : {‘lbfgs’, ‘sgd’, ‘adam’}\n",
    "model = MLPClassifier(verbose=2,max_iter=1000,hidden_layer_sizes=(500,200),activation='identity',solver='lbfgs')\n",
    "model.fit(scaled_data_train,train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.44      0.49       147\n",
      "           1       0.68      0.76      0.72       161\n",
      "           2       0.39      0.42      0.41       146\n",
      "           3       0.64      0.64      0.64       149\n",
      "\n",
      "    accuracy                           0.57       603\n",
      "   macro avg       0.57      0.57      0.57       603\n",
      "weighted avg       0.57      0.57      0.57       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(scaled_data_test)\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
