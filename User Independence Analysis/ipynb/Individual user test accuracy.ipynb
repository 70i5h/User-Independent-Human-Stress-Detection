{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.63 s, sys: 620 ms, total: 3.25 s\n",
      "Wall time: 2.72 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sf/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from itertools import combinations \n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sub=[10,11,13,14,15,16,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('60s_window_wrist_chest_with_smote_all_subject_balenced_class.csv',index_col=0)\n",
    "\n",
    "\n",
    "# features=df.columns.tolist()\n",
    "# features\n",
    "\n",
    "# removed = ['label']\n",
    "# for rem in removed:\n",
    "#     features.remove(rem)\n",
    "\n",
    "# features_with_sub=[]\n",
    "# features_with_sub[:]=features\n",
    "# removed = ['subject']\n",
    "# for rem in removed:\n",
    "#     features.remove(rem)\n",
    "\n",
    "# feature=features\n",
    "# print(len(feature))\n",
    "# len(features_with_sub)\n",
    "\n",
    "\n",
    "# sm = SMOTE(random_state=2)\n",
    "# X, y= sm.fit_sample(df[features_with_sub], df['label'])\n",
    "# df_new=pd.concat([pd.DataFrame(X,columns=features_with_sub),pd.DataFrame(y,columns=['label'])],axis=1)\n",
    "# df_new\n",
    "\n",
    "# for i in range (len(list(df_new['subject']))):\n",
    "#     df_new['subject'][i] = min([2,3,4,5,6,7,8,9,10,11,13,14,15,16,17], key=lambda x:abs(x-df_new['subject'][i]))\n",
    "# df_new['subject']=df_new['subject'].astype(int)\n",
    "\n",
    "# p_d=pd.read_csv('personal_detail.csv',index_col=0)\n",
    "\n",
    "# df_new_1=df_new.merge(p_d,on='subject')\n",
    "# df_new_1\n",
    "\n",
    "# features=df_new_1.columns.tolist()\n",
    "# features\n",
    "\n",
    "# removed = ['label']\n",
    "# for rem in removed:\n",
    "#     features.remove(rem)\n",
    "# features_with_sub=[]\n",
    "# features_with_sub[:]=features\n",
    "# removed = ['subject']\n",
    "# for rem in removed:\n",
    "#     features.remove(rem)\n",
    "\n",
    "# feature=features\n",
    "# print(len(feature))\n",
    "# len(features_with_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.78       147\n",
      "           1       0.84      0.93      0.88       161\n",
      "           2       0.68      0.74      0.71       146\n",
      "           3       0.79      0.77      0.78       149\n",
      "\n",
      "    accuracy                           0.79       603\n",
      "   macro avg       0.80      0.79      0.79       603\n",
      "weighted avg       0.80      0.79      0.79       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train=df_new_1[df_new_1['subject']<=9]\n",
    "test=df_new_1[df_new_1['subject']>9]\n",
    "\n",
    "sel_fea = ['EDA_tonic_mean','EDA_smna_mean','EDA_tonic_min','EDA_phasic_mean','TEMP_std','BVP_peak_freq','smoker_YES','ACC_y_min','ACC_x_mean','weight','gender_ female','c_Temp_max','ACC_x_max','TEMP_mean',\n",
    "          'c_ACC_y_std','net_acc_max','Resp_std']\n",
    "\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaled_data_train = scaler.fit_transform(train[sel_fea])\n",
    "scaled_data_test = scaler.transform(test[sel_fea])\n",
    "\n",
    "et = ExtraTreesClassifier(n_estimators=100,n_jobs=10,random_state=61)\n",
    "et.fit(scaled_data_train,train['label'])\n",
    "y_pred=et.predict(scaled_data_test)\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77       181\n",
      "           1       0.77      0.90      0.83       181\n",
      "           2       0.62      0.73      0.67       181\n",
      "           3       0.83      0.71      0.76       181\n",
      "\n",
      "    accuracy                           0.76       724\n",
      "   macro avg       0.77      0.76      0.76       724\n",
      "weighted avg       0.77      0.76      0.76       724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train=df[df['subject']<=9]\n",
    "test=df[df['subject']>9]\n",
    "\n",
    "sel_fea = ['EDA_tonic_mean','EDA_smna_mean','EDA_tonic_min','EDA_phasic_mean','TEMP_std','BVP_peak_freq','smoker_YES','ACC_y_min','ACC_x_mean','weight','gender_ female','c_Temp_max','ACC_x_max','TEMP_mean',\n",
    "          'c_ACC_y_std','net_acc_max','Resp_std']\n",
    "\n",
    "\n",
    "scaler = Normalizer()\n",
    "scaled_data_train = scaler.fit_transform(train[sel_fea])\n",
    "scaled_data_test = scaler.transform(test[sel_fea])\n",
    "\n",
    "et = ExtraTreesClassifier(n_estimators=100,n_jobs=10,random_state=61)\n",
    "et.fit(scaled_data_train,train['label'])\n",
    "y_pred=et.predict(scaled_data_test)\n",
    "print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        21\n",
      "           1       1.00      0.96      0.98        28\n",
      "           2       0.86      0.83      0.85        30\n",
      "           3       0.79      0.86      0.83        22\n",
      "\n",
      "    accuracy                           0.90       101\n",
      "   macro avg       0.90      0.90      0.90       101\n",
      "weighted avg       0.90      0.90      0.90       101\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.33      0.47        21\n",
      "           1       0.78      0.84      0.81        25\n",
      "           2       0.50      0.62      0.56        24\n",
      "           3       0.77      0.88      0.82        26\n",
      "\n",
      "    accuracy                           0.69        96\n",
      "   macro avg       0.71      0.67      0.66        96\n",
      "weighted avg       0.71      0.69      0.67        96\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71        21\n",
      "           1       0.91      1.00      0.95        30\n",
      "           2       0.82      0.82      0.82        33\n",
      "           3       0.95      0.83      0.88        23\n",
      "\n",
      "    accuracy                           0.85       107\n",
      "   macro avg       0.85      0.84      0.84       107\n",
      "weighted avg       0.85      0.85      0.85       107\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85        21\n",
      "           1       0.76      0.89      0.82        18\n",
      "           2       0.62      0.59      0.61        17\n",
      "           3       0.87      0.87      0.87        23\n",
      "\n",
      "    accuracy                           0.80        79\n",
      "   macro avg       0.79      0.79      0.79        79\n",
      "weighted avg       0.80      0.80      0.80        79\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      1.00      1.00        19\n",
      "           2       0.65      0.71      0.68        21\n",
      "           3       0.70      0.64      0.67        22\n",
      "\n",
      "    accuracy                           0.83        83\n",
      "   macro avg       0.84      0.84      0.84        83\n",
      "weighted avg       0.83      0.83      0.83        83\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.85        21\n",
      "           1       1.00      1.00      1.00        26\n",
      "           2       0.65      0.92      0.76        12\n",
      "           3       0.94      0.79      0.86        19\n",
      "\n",
      "    accuracy                           0.88        78\n",
      "   macro avg       0.87      0.88      0.87        78\n",
      "weighted avg       0.90      0.88      0.89        78\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.33      0.48        21\n",
      "           1       0.42      0.73      0.54        15\n",
      "           2       0.42      0.56      0.48         9\n",
      "           3       0.38      0.36      0.37        14\n",
      "\n",
      "    accuracy                           0.47        59\n",
      "   macro avg       0.52      0.49      0.47        59\n",
      "weighted avg       0.57      0.47      0.47        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in test_sub:\n",
    "    print(i)\n",
    "    train=df_new_1[df_new_1['subject']<=9]\n",
    "    test=df_new_1[df_new_1['subject']==i]\n",
    "\n",
    "    scaler = Normalizer()\n",
    "    scaled_data_train = scaler.fit_transform(train[sel_fea])\n",
    "    scaled_data_test = scaler.transform(test[sel_fea])\n",
    "    \n",
    "    et = ExtraTreesClassifier(n_estimators=100,n_jobs=10,random_state=61)\n",
    "    et.fit(scaled_data_train,train['label'])\n",
    "    y_pred=et.predict(scaled_data_test)\n",
    "    print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        30\n",
      "           1       1.00      0.97      0.98        30\n",
      "           2       0.83      0.67      0.74        30\n",
      "           3       0.73      0.90      0.81        30\n",
      "\n",
      "    accuracy                           0.88       120\n",
      "   macro avg       0.88      0.88      0.87       120\n",
      "weighted avg       0.88      0.88      0.87       120\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.31      0.46        26\n",
      "           1       0.72      0.88      0.79        26\n",
      "           2       0.49      0.65      0.56        26\n",
      "           3       0.75      0.81      0.78        26\n",
      "\n",
      "    accuracy                           0.66       104\n",
      "   macro avg       0.71      0.66      0.65       104\n",
      "weighted avg       0.71      0.66      0.65       104\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.58      0.62        33\n",
      "           1       0.86      0.94      0.90        33\n",
      "           2       0.63      0.73      0.68        33\n",
      "           3       0.97      0.88      0.92        33\n",
      "\n",
      "    accuracy                           0.78       132\n",
      "   macro avg       0.78      0.78      0.78       132\n",
      "weighted avg       0.78      0.78      0.78       132\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.78      0.77        23\n",
      "           1       0.51      0.78      0.62        23\n",
      "           2       0.38      0.35      0.36        23\n",
      "           3       1.00      0.52      0.69        23\n",
      "\n",
      "    accuracy                           0.61        92\n",
      "   macro avg       0.66      0.61      0.61        92\n",
      "weighted avg       0.66      0.61      0.61        92\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        22\n",
      "           1       1.00      1.00      1.00        22\n",
      "           2       0.69      0.82      0.75        22\n",
      "           3       0.78      0.64      0.70        22\n",
      "\n",
      "    accuracy                           0.86        88\n",
      "   macro avg       0.87      0.86      0.86        88\n",
      "weighted avg       0.87      0.86      0.86        88\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.77      0.82        26\n",
      "           1       1.00      1.00      1.00        26\n",
      "           2       0.75      0.92      0.83        26\n",
      "           3       0.87      0.77      0.82        26\n",
      "\n",
      "    accuracy                           0.87       104\n",
      "   macro avg       0.87      0.87      0.87       104\n",
      "weighted avg       0.87      0.87      0.87       104\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60        21\n",
      "           1       0.45      0.67      0.54        21\n",
      "           2       0.55      1.00      0.71        21\n",
      "           3       0.83      0.24      0.37        21\n",
      "\n",
      "    accuracy                           0.58        84\n",
      "   macro avg       0.71      0.58      0.56        84\n",
      "weighted avg       0.71      0.58      0.56        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in test_sub:\n",
    "    print(i)\n",
    "    train=df[df['subject']<=9]\n",
    "    test=df[df['subject']==i]\n",
    "\n",
    "    scaler = Normalizer()\n",
    "    scaled_data_train = scaler.fit_transform(train[sel_fea])\n",
    "    scaled_data_test = scaler.transform(test[sel_fea])\n",
    "    \n",
    "    et = ExtraTreesClassifier(n_estimators=100,n_jobs=10,random_state=61)\n",
    "    et.fit(scaled_data_train,train['label'])\n",
    "    y_pred=et.predict(scaled_data_test)\n",
    "    print(classification_report(test['label'],y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
