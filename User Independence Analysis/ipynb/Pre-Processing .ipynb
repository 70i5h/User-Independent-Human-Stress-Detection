{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS CODE WAS INSIPIRED FROM https://github.com/WJMatthew/WESAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cvxEDA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1f6b25e27634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscisig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcvxEDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cvxEDA'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats \n",
    "import scipy.signal as scisig\n",
    "import scipy.stats\n",
    "import cvxEDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(cvxEDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_dict = {'ACC': 32, 'BVP': 64, 'EDA': 4, 'TEMP': 4, 'label': 700, 'Resp': 700, 'ECG':700}\n",
    "WINDOW_IN_SECONDS = 1\n",
    "label_dict = {'baseline': 0, 'stress': 1, 'amusement': 2, 'meditation':3}\n",
    "int_to_label = {0: 'baseline', 1: 'stress', 2: 'amusement', 3:'meditation'}\n",
    "feat_names = None\n",
    "savePath = 'fresh_start'\n",
    "subject_feature_path = '/subject_feats'\n",
    "\n",
    "if not os.path.exists(savePath):\n",
    "    os.makedirs(savePath)\n",
    "if not os.path.exists(savePath + subject_feature_path):\n",
    "    os.makedirs(savePath + subject_feature_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvxEDA\n",
    "def eda_stats(y):\n",
    "    Fs = fs_dict['EDA']\n",
    "    yn = (y - y.mean()) / y.std()\n",
    "    [r, p, t, l, d, e, obj] = cvxEDA.cvxEDA(yn, 1. / Fs)\n",
    "    return [r, p, t, l, d, e, obj]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubjectData:\n",
    "\n",
    "    def __init__(self, main_path, subject_number):\n",
    "        self.name = f'S{subject_number}'\n",
    "        self.subject_keys = ['signal', 'label', 'subject']\n",
    "        self.signal_keys = ['chest', 'wrist']\n",
    "        self.chest_keys = ['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp']\n",
    "        self.wrist_keys = ['ACC', 'BVP', 'EDA', 'TEMP']\n",
    "        with open(os.path.join(main_path, self.name) + '/' + self.name + '.pkl', 'rb') as file:\n",
    "            self.data = pickle.load(file, encoding='latin1')\n",
    "        self.labels = self.data['label']\n",
    "\n",
    "    def get_wrist_data(self):\n",
    "        data = self.data['signal']['wrist']\n",
    "        data.update({'Resp': self.data['signal']['chest']['Resp']})\n",
    "        data.update({'ECG': self.data['signal']['chest']['ECG']})\n",
    "        data.update({'EMG': self.data['signal']['chest']['EMG']})\n",
    "        data.update({'c_EDA': self.data['signal']['chest']['EDA']})\n",
    "        data.update({'c_Temp': self.data['signal']['chest']['Temp']})\n",
    "        data.update({'c_ACC': self.data['signal']['chest']['ACC']})\n",
    "        return data\n",
    "\n",
    "    def get_chest_data(self):\n",
    "        return self.data['signal']['chest']\n",
    "\n",
    "    def extract_features(self):  # only wrist\n",
    "        results = \\\n",
    "            {\n",
    "                key: get_statistics(self.get_wrist_data()[key].flatten(), self.labels, key)\n",
    "                for key in self.wrist_keys\n",
    "            }\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    # Filtering Helper functions\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = scisig.butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    # Filtering Helper functions\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = scisig.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def get_slope(series):\n",
    "    linreg = scipy.stats.linregress(np.arange(len(series)), series )\n",
    "    slope = linreg[0]\n",
    "    return slope\n",
    "\n",
    "def get_window_stats(data, label=-1):\n",
    "    mean_features = np.mean(data)\n",
    "    std_features = np.std(data)\n",
    "    min_features = np.amin(data)\n",
    "    max_features = np.amax(data)\n",
    "\n",
    "    features = {'mean': mean_features, 'std': std_features, 'min': min_features, 'max': max_features,\n",
    "                'label': label}\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_net_accel(data):\n",
    "    return (data['ACC_x'] ** 2 + data['ACC_y'] ** 2 + data['ACC_z'] ** 2).apply(lambda x: np.sqrt(x))\n",
    "\n",
    "\n",
    "def get_peak_freq(x):\n",
    "    f, Pxx = scisig.periodogram(x, fs=8)\n",
    "    psd_dict = {amp: freq for amp, freq in zip(Pxx, f)}\n",
    "    peak_freq = psd_dict[max(psd_dict.keys())]\n",
    "    return peak_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/MITMediaLabAffectiveComputing/eda-explorer/blob/master/AccelerometerFeatureExtractionScript.py\n",
    "def filterSignalFIR(eda, cutoff=0.4, numtaps=64):\n",
    "    f = cutoff / (fs_dict['ACC'] / 2.0)\n",
    "    FIR_coeff = scisig.firwin(numtaps, f)\n",
    "\n",
    "    return scisig.lfilter(FIR_coeff, 1, eda)\n",
    "\n",
    "\n",
    "def compute_features(e4_data_dict, labels, norm_type=None):\n",
    "    # Dataframes for each sensor type\n",
    "    eda_df = pd.DataFrame(e4_data_dict['EDA'], columns=['EDA'])\n",
    "    bvp_df = pd.DataFrame(e4_data_dict['BVP'], columns=['BVP'])\n",
    "    acc_df = pd.DataFrame(e4_data_dict['ACC'], columns=['ACC_x', 'ACC_y', 'ACC_z'])\n",
    "    temp_df = pd.DataFrame(e4_data_dict['TEMP'], columns=['TEMP'])\n",
    "    label_df = pd.DataFrame(labels, columns=['label'])\n",
    "    resp_df = pd.DataFrame(e4_data_dict['Resp'], columns=['Resp'])\n",
    "    \n",
    "    ecg_df = pd.DataFrame(e4_data_dict['ECG'], columns=['ECG'])\n",
    "    emg_df = pd.DataFrame(e4_data_dict['EMG'], columns=['EMG'])\n",
    "    c_temp_df = pd.DataFrame(e4_data_dict['c_Temp'], columns=['c_Temp'])\n",
    "    c_acc_df = pd.DataFrame(e4_data_dict['c_ACC'], columns=['c_ACC_x', 'c_ACC_y', 'c_ACC_z'])\n",
    "    \n",
    "    # Filter EDA\n",
    "    eda_df['EDA'] = butter_lowpass_filter(eda_df['EDA'], 1.0, fs_dict['EDA'], 6)\n",
    "    \n",
    "    # Filter ACM\n",
    "    for _ in acc_df.columns:\n",
    "        acc_df[_] = filterSignalFIR(acc_df.values)\n",
    "\n",
    "    # Adding indices for combination due to differing sampling frequencies\n",
    "    eda_df.index = [(1 / fs_dict['EDA']) * i for i in range(len(eda_df))]\n",
    "    bvp_df.index = [(1 / fs_dict['BVP']) * i for i in range(len(bvp_df))]\n",
    "    acc_df.index = [(1 / fs_dict['ACC']) * i for i in range(len(acc_df))]\n",
    "    temp_df.index = [(1 / fs_dict['TEMP']) * i for i in range(len(temp_df))]\n",
    "    label_df.index = [(1 / fs_dict['label']) * i for i in range(len(label_df))]\n",
    "    resp_df.index = [(1 / fs_dict['Resp']) * i for i in range(len(resp_df))]\n",
    "    \n",
    "    ecg_df.index = [(1 / fs_dict['ECG']) * i for i in range(len(ecg_df))]\n",
    "    emg_df.index = [(1 / fs_dict['ECG']) * i for i in range(len(emg_df))]          #ECG fz = EMG fz\n",
    "    c_temp_df.index = [(1 / fs_dict['ECG']) * i for i in range(len(c_temp_df))]\n",
    "    c_acc_df.index = [(1 / fs_dict['ECG']) * i for i in range(len(c_acc_df))]\n",
    "    \n",
    "    # Change indices to datetime\n",
    "    eda_df.index = pd.to_datetime(eda_df.index, unit='s')\n",
    "    bvp_df.index = pd.to_datetime(bvp_df.index, unit='s')\n",
    "    temp_df.index = pd.to_datetime(temp_df.index, unit='s')\n",
    "    acc_df.index = pd.to_datetime(acc_df.index, unit='s')\n",
    "    label_df.index = pd.to_datetime(label_df.index, unit='s')\n",
    "    resp_df.index = pd.to_datetime(resp_df.index, unit='s')\n",
    "    \n",
    "    ecg_df.index  = pd.to_datetime(ecg_df.index , unit='s')\n",
    "    emg_df.index  = pd.to_datetime(emg_df.index , unit='s')\n",
    "    c_temp_df.index  = pd.to_datetime(c_temp_df.index , unit='s')\n",
    "    c_acc_df.index = pd.to_datetime(c_acc_df.index, unit='s')\n",
    "    \n",
    "    # New EDA features\n",
    "    r, p, t, l, d, e, obj = eda_stats(eda_df['EDA'])\n",
    "    eda_df['EDA_phasic'] = r\n",
    "    eda_df['EDA_smna'] = p\n",
    "    eda_df['EDA_tonic'] = t\n",
    "    \n",
    "   \n",
    "        \n",
    "    # Combined dataframe - not used yet\n",
    "    df = eda_df.join(bvp_df, how='outer')\n",
    "    df = df.join(temp_df, how='outer')\n",
    "    df = df.join(acc_df, how='outer')\n",
    "    df = df.join(resp_df, how='outer')\n",
    "    df = df.join(label_df, how='outer')\n",
    "    df = df.join(ecg_df, how='outer')\n",
    "    df = df.join(emg_df, how='outer')\n",
    "    df = df.join(c_temp_df, how='outer')\n",
    "    df = df.join(c_acc_df, how='outer')\n",
    "    df['label'] = df['label'].fillna(method='bfill')\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if norm_type is 'std':\n",
    "        # std norm\n",
    "        df = (df - df.mean()) / df.std()\n",
    "    elif norm_type is 'minmax':\n",
    "        # minmax norm\n",
    "        df = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "    # Groupby\n",
    "    grouped = df.groupby('label')\n",
    "    baseline = grouped.get_group(1)\n",
    "    stress = grouped.get_group(2)\n",
    "    amusement = grouped.get_group(3)\n",
    "    meditation = grouped.get_group(4)\n",
    "    \n",
    "#     print (\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "#     print (df)\n",
    "#     print (grouped.groups.keys())\n",
    "#     print (\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "    \n",
    "    return grouped, baseline, stress, amusement, meditation\n",
    "\n",
    "\n",
    "def get_samples(data, n_windows, label):\n",
    "    global feat_names\n",
    "    global WINDOW_IN_SECONDS\n",
    "\n",
    "    samples = []\n",
    "    # Using label freq (700 Hz) as our reference frequency due to it being the largest\n",
    "    # and thus encompassing the lesser ones in its resolution.\n",
    "    window_len = fs_dict['label'] * WINDOW_IN_SECONDS\n",
    "\n",
    "    for i in range(n_windows):\n",
    "        # Get window of data\n",
    "        w = data[window_len * i: window_len * (i + 1)]\n",
    "\n",
    "        # Add/Calc rms acc\n",
    "        # w['net_acc'] = get_net_accel(w)\n",
    "        w = pd.concat([w, get_net_accel(w)])\n",
    "        #w.columns = ['net_acc', 'ACC_x', 'ACC_y', 'ACC_z', 'BVP',\n",
    "          #           'EDA', 'EDA_phasic', 'EDA_smna', 'EDA_tonic', 'TEMP',\n",
    "            #         'label']\n",
    "        cols = list(w.columns)\n",
    "        cols[0] = 'net_acc'\n",
    "        w.columns = cols\n",
    "        \n",
    "        # Calculate stats for window\n",
    "        wstats = get_window_stats(data=w, label=label)\n",
    "\n",
    "        # Seperating sample and label\n",
    "        x = pd.DataFrame(wstats).drop('label', axis=0)\n",
    "        y = x['label'][0]\n",
    "        x.drop('label', axis=1, inplace=True)\n",
    "\n",
    "        if feat_names is None:\n",
    "            feat_names = []\n",
    "            for row in x.index:\n",
    "                for col in x.columns:\n",
    "                    feat_names.append('_'.join([row, col]))\n",
    "\n",
    "        # sample df\n",
    "        wdf = pd.DataFrame(x.values.flatten()).T\n",
    "        wdf.columns = feat_names\n",
    "        wdf = pd.concat([wdf, pd.DataFrame({'label': y}, index=[0])], axis=1)\n",
    "        \n",
    "        # More feats\n",
    "        wdf['BVP_peak_freq'] = get_peak_freq(w['BVP'].dropna())\n",
    "        wdf['TEMP_slope'] = get_slope(w['TEMP'].dropna())\n",
    "        samples.append(wdf)\n",
    "\n",
    "    return pd.concat(samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_patient_data(subject_id):\n",
    "    global savePath\n",
    "    global WINDOW_IN_SECONDS\n",
    "\n",
    "    # Make subject data object for Sx\n",
    "    subject = SubjectData(main_path='WESAD', subject_number=subject_id)\n",
    "\n",
    "    # Empatica E4 data - now with resp\n",
    "    e4_data_dict = subject.get_wrist_data()\n",
    "#     e4_data_dict = subject.get_chest_data()\n",
    "\n",
    "    # norm type\n",
    "    norm_type = None\n",
    "\n",
    "    # The 3 classes we are classifying\n",
    "    grouped, baseline, stress, amusement, meditation = compute_features(e4_data_dict, subject.labels, norm_type)\n",
    "\n",
    "    # print(f'Available windows for {subject.name}:')\n",
    "    n_baseline_wdws = int(len(baseline) / (fs_dict['label'] * WINDOW_IN_SECONDS))\n",
    "    n_stress_wdws = int(len(stress) / (fs_dict['label'] * WINDOW_IN_SECONDS))\n",
    "    n_amusement_wdws = int(len(amusement) / (fs_dict['label'] * WINDOW_IN_SECONDS))\n",
    "    n_meditation_wdws = int(len(meditation) / (fs_dict['label'] * WINDOW_IN_SECONDS))\n",
    "    # print(f'Baseline: {n_baseline_wdws}\\nStress: {n_stress_wdws}\\nAmusement: {n_amusement_wdws}\\n')\n",
    "\n",
    "    #\n",
    "    baseline_samples = get_samples(baseline, n_baseline_wdws, 0)\n",
    "    # Downsampling\n",
    "    # baseline_samples = baseline_samples[::2]\n",
    "    stress_samples = get_samples(stress, n_stress_wdws, 1)\n",
    "    amusement_samples = get_samples(amusement, n_amusement_wdws, 2)\n",
    "    meditation_samples = get_samples(meditation, n_meditation_wdws, 3)\n",
    "\n",
    "    all_samples = pd.concat([baseline_samples, stress_samples, amusement_samples,meditation_samples])\n",
    "    all_samples = pd.concat([all_samples.drop('label', axis=1), pd.get_dummies(all_samples['label'])], axis=1)\n",
    "    \n",
    "    # Selected Features\n",
    "    # all_samples = all_samples[['EDA_mean', 'EDA_std', 'EDA_min', 'EDA_max',\n",
    "    #                          'BVP_mean', 'BVP_std', 'BVP_min', 'BVP_max',\n",
    "    #                        'TEMP_mean', 'TEMP_std', 'TEMP_min', 'TEMP_max',\n",
    "    #                        'net_acc_mean', 'net_acc_std', 'net_acc_min', 'net_acc_max',\n",
    "    #                        0, 1, 2]]\n",
    "    # Save file as csv (for now)\n",
    "    all_samples.to_csv(f'{savePath}{subject_feature_path}/S{subject_id}_feats_4.csv')\n",
    "\n",
    "    # Does this save any space?\n",
    "    subject = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_files(subjects):\n",
    "    df_list = []\n",
    "    for s in subjects:\n",
    "        df = pd.read_csv(f'{savePath}{subject_feature_path}/S{s}_feats_4.csv', index_col=0)\n",
    "        df['subject'] = s\n",
    "        df_list.append(df)\n",
    "\n",
    "    df = pd.concat(df_list)\n",
    "    \n",
    "#     df.info()\n",
    "    \n",
    "    df['label'] = (df['0'].astype(str) + df['1'].astype(str) + df['2'].astype(str)+ df['3'].astype(str)).apply(lambda x: x.index('1'))\n",
    "    \n",
    "#     print (df)\n",
    "    \n",
    "#     print (\"***************************8\")\n",
    "#     df['label']\n",
    "#     print (\"***************************8\")\n",
    "\n",
    "    df.drop(['0', '1', '2','3'], axis=1, inplace=True)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df.to_csv(f'{savePath}/may14_feats4_chest.csv')\n",
    "\n",
    "    counts = df['label'].value_counts()\n",
    "    print('Number of samples per class:')\n",
    "    print (counts)\n",
    "    for label, number in zip(counts.index, counts.values):\n",
    "        print(f'{int_to_label[label]}: {number}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for S2...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'WESAD/S2/S2.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c4bcfc73afd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpatient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubject_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Processing data for S{patient}...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmake_patient_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcombine_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-edc4954f180a>\u001b[0m in \u001b[0;36mmake_patient_data\u001b[0;34m(subject_id)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Make subject data object for Sx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msubject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSubjectData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'WESAD'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_number\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Empatica E4 data - now with resp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-606137fb8c1f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, main_path, subject_number)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchest_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ACC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ECG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EMG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EDA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Temp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Resp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrist_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ACC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BVP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'EDA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TEMP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'WESAD/S2/S2.pkl'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "#     subject_ids = [2]\n",
    "    for patient in subject_ids:\n",
    "        print(f'Processing data for S{patient}...')\n",
    "        make_patient_data(patient)\n",
    "\n",
    "    combine_files(subject_ids)\n",
    "    print('Processing complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = pd.read_csv(\"fresh_start/may14_feats4_chest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    54\n",
       "17    53\n",
       "16    53\n",
       "15    53\n",
       "14    53\n",
       "13    53\n",
       "11    53\n",
       "8     53\n",
       "9     52\n",
       "7     52\n",
       "6     52\n",
       "5     52\n",
       "4     51\n",
       "3     51\n",
       "2     50\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    312\n",
       "3    208\n",
       "1    175\n",
       "2     90\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785 entries, 0 to 784\n",
      "Data columns (total 73 columns):\n",
      "Unnamed: 0         785 non-null int64\n",
      "net_acc_mean       785 non-null float64\n",
      "net_acc_std        785 non-null float64\n",
      "net_acc_min        785 non-null float64\n",
      "net_acc_max        785 non-null float64\n",
      "ACC_x_mean         785 non-null float64\n",
      "ACC_x_std          785 non-null float64\n",
      "ACC_x_min          785 non-null float64\n",
      "ACC_x_max          785 non-null float64\n",
      "ACC_y_mean         785 non-null float64\n",
      "ACC_y_std          785 non-null float64\n",
      "ACC_y_min          785 non-null float64\n",
      "ACC_y_max          785 non-null float64\n",
      "ACC_z_mean         785 non-null float64\n",
      "ACC_z_std          785 non-null float64\n",
      "ACC_z_min          785 non-null float64\n",
      "ACC_z_max          785 non-null float64\n",
      "BVP_mean           785 non-null float64\n",
      "BVP_std            785 non-null float64\n",
      "BVP_min            785 non-null float64\n",
      "BVP_max            785 non-null float64\n",
      "ECG_mean           785 non-null float64\n",
      "ECG_std            785 non-null float64\n",
      "ECG_min            785 non-null float64\n",
      "ECG_max            785 non-null float64\n",
      "EDA_mean           785 non-null float64\n",
      "EDA_std            785 non-null float64\n",
      "EDA_min            785 non-null float64\n",
      "EDA_max            785 non-null float64\n",
      "EDA_phasic_mean    785 non-null float64\n",
      "EDA_phasic_std     785 non-null float64\n",
      "EDA_phasic_min     785 non-null float64\n",
      "EDA_phasic_max     785 non-null float64\n",
      "EDA_smna_mean      785 non-null float64\n",
      "EDA_smna_std       785 non-null float64\n",
      "EDA_smna_min       785 non-null float64\n",
      "EDA_smna_max       785 non-null float64\n",
      "EDA_tonic_mean     785 non-null float64\n",
      "EDA_tonic_std      785 non-null float64\n",
      "EDA_tonic_min      785 non-null float64\n",
      "EDA_tonic_max      785 non-null float64\n",
      "EMG_mean           785 non-null float64\n",
      "EMG_std            785 non-null float64\n",
      "EMG_min            785 non-null float64\n",
      "EMG_max            785 non-null float64\n",
      "Resp_mean          785 non-null float64\n",
      "Resp_std           785 non-null float64\n",
      "Resp_min           785 non-null float64\n",
      "Resp_max           785 non-null float64\n",
      "TEMP_mean          785 non-null float64\n",
      "TEMP_std           785 non-null float64\n",
      "TEMP_min           785 non-null float64\n",
      "TEMP_max           785 non-null float64\n",
      "c_ACC_x_mean       785 non-null float64\n",
      "c_ACC_x_std        785 non-null float64\n",
      "c_ACC_x_min        785 non-null float64\n",
      "c_ACC_x_max        785 non-null float64\n",
      "c_ACC_y_mean       785 non-null float64\n",
      "c_ACC_y_std        785 non-null float64\n",
      "c_ACC_y_min        785 non-null float64\n",
      "c_ACC_y_max        785 non-null float64\n",
      "c_ACC_z_mean       785 non-null float64\n",
      "c_ACC_z_std        785 non-null float64\n",
      "c_ACC_z_min        785 non-null float64\n",
      "c_ACC_z_max        785 non-null float64\n",
      "c_Temp_mean        785 non-null float64\n",
      "c_Temp_std         785 non-null float64\n",
      "c_Temp_min         785 non-null float64\n",
      "c_Temp_max         785 non-null float64\n",
      "BVP_peak_freq      785 non-null float64\n",
      "TEMP_slope         785 non-null float64\n",
      "subject            785 non-null int64\n",
      "label              785 non-null int64\n",
      "dtypes: float64(70), int64(3)\n",
      "memory usage: 447.8 KB\n"
     ]
    }
   ],
   "source": [
    "pre.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.to_csv('fresh_start/60s_window_wrist_chest.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
